"ID","Process ID","Process Name","Host Name","thread Domain:Push/Pop_Range:PL_Type:PL_Value:CLR_Type:Color:Msg_Type:Msg","Id:Domain:Start/Stop_Range:PL_Type:PL_Value:CLR_Type:Color:Msg_Type:Msg","Kernel Name","Context","Stream","Block Size","Grid Size","Device","CC","Section Name","Metric Name","Metric Unit","Metric Value","Rule Name","Rule Type","Rule Description","Estimated Speedup Type","Estimated Speedup"
"0","1202056","python3.10","127.0.0.1","1202056  ""<default domain>:custom_kernel:none:none:none:none:none:none"" ","","gemv_nvfp4_kernel(const signed char *, const signed char *, const signed char *, const signed char *, __half *, int, int, int, int)","1","7","(64, 1, 1)","(2048, 8, 1)","0","10.0","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"0","1202056","python3.10","127.0.0.1","1202056  ""<default domain>:custom_kernel:none:none:none:none:none:none"" ","","gemv_nvfp4_kernel(const signed char *, const signed char *, const signed char *, const signed char *, __half *, int, int, int, int)","1","7","(64, 1, 1)","(2048, 8, 1)","0","10.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 2:1. The workload achieved 3% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"0","1202056","python3.10","127.0.0.1","1202056  ""<default domain>:custom_kernel:none:none:none:none:none:none"" ","","gemv_nvfp4_kernel(const signed char *, const signed char *, const signed char *, const signed char *, __half *, int, int, int, int)","1","7","(64, 1, 1)","(2048, 8, 1)","0","10.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (55.8%) based on elapsed cycles in the workload, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck.","",""
"0","1202056","python3.10","127.0.0.1","1202056  ""<default domain>:custom_kernel:none:none:none:none:none:none"" ","","gemv_nvfp4_kernel(const signed char *, const signed char *, const signed char *, const signed char *, __half *, int, int, int, int)","1","7","(64, 1, 1)","(2048, 8, 1)","0","10.0","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 1054944.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","26.67"
"0","1202056","python3.10","127.0.0.1","1202056  ""<default domain>:custom_kernel:none:none:none:none:none:none"" ","","gemv_nvfp4_kernel(const signed char *, const signed char *, const signed char *, const signed char *, __half *, int, int, int, int)","1","7","(64, 1, 1)","(2048, 8, 1)","0","10.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","OPT","The memory access pattern for global loads from L1TEX might not be optimal. On average, only 8.5 of the 32 bytes transmitted per sector are utilized by each thread. This could possibly be caused by a stride between threads. Check the Source Counters section for uncoalesced global loads.","global","60.45"
"0","1202056","python3.10","127.0.0.1","1202056  ""<default domain>:custom_kernel:none:none:none:none:none:none"" ","","gemv_nvfp4_kernel(const signed char *, const signed char *, const signed char *, const signed char *, __half *, int, int, int, int)","1","7","(64, 1, 1)","(2048, 8, 1)","0","10.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","OPT","The memory access pattern for global stores to L1TEX might not be optimal. On average, only 2.0 of the 32 bytes transmitted per sector are utilized by each thread. This could possibly be caused by a stride between threads. Check the Source Counters section for uncoalesced global stores.","global","77.08"
"0","1202056","python3.10","127.0.0.1","1202056  ""<default domain>:custom_kernel:none:none:none:none:none:none"" ","","gemv_nvfp4_kernel(const signed char *, const signed char *, const signed char *, const signed char *, __half *, int, int, int, int)","1","7","(64, 1, 1)","(2048, 8, 1)","0","10.0","InstructionStats","","","","FPInstructions","OPT","This kernel executes 0 fused and 2490368 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance).","global","27.08"
"0","1202056","python3.10","127.0.0.1","1202056  ""<default domain>:custom_kernel:none:none:none:none:none:none"" ","","gemv_nvfp4_kernel(const signed char *, const signed char *, const signed char *, const signed char *, __half *, int, int, int, int)","1","7","(64, 1, 1)","(2048, 8, 1)","0","10.0","Occupancy","Theoretical Occupancy","%","62.50",
"0","1202056","python3.10","127.0.0.1","1202056  ""<default domain>:custom_kernel:none:none:none:none:none:none"" ","","gemv_nvfp4_kernel(const signed char *, const signed char *, const signed char *, const signed char *, __half *, int, int, int, int)","1","7","(64, 1, 1)","(2048, 8, 1)","0","10.0","Occupancy","","","","TheoreticalOccupancy","OPT","The 10.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 16. This kernel's theoretical occupancy (62.5%) is limited by the number of required registers.","local","37.5"
"0","1202056","python3.10","127.0.0.1","1202056  ""<default domain>:custom_kernel:none:none:none:none:none:none"" ","","gemv_nvfp4_kernel(const signed char *, const signed char *, const signed char *, const signed char *, __half *, int, int, int, int)","1","7","(64, 1, 1)","(2048, 8, 1)","0","10.0","SourceCounters","","","","UncoalescedGlobalAccess","OPT","This kernel has uncoalesced global accesses resulting in a total of 22937600 excessive sectors (73% of the total 31227904 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.","global","66.36"
