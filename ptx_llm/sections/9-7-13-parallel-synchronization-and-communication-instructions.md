### 9.7.13. Parallel Synchronization and Communication Instructions 

These instructions are:

* `bar{.cta}`, `barrier{.cta}`
* `bar.warp.sync`
* `barrier.cluster`
* `membar`
* `atom`
* `red`
* `red.async`
* `vote`
* `match.sync`
* `activemask`
* `redux.sync`
* `griddepcontrol`
* `elect.sync`
* `mbarrier.init`
* `mbarrier.inval`
* `mbarrier.arrive`
* `mbarrier.arrive_drop`
* `mbarrier.test_wait`
* `mbarrier.try_wait`
* `mbarrier.pending_count`
* `cp.async.mbarrier.arrive`
* `tensormap.cp_fenceproxy`
* `clusterlaunchcontrol.try_cancel`
* `clusterlaunchcontrol.query_cancel`

#### 9.7.13.1. [Parallel Synchronization and Communication Instructions: `bar`, `barrier`](#parallel-synchronization-and-communication-instructions-bar)[](#parallel-synchronization-and-communication-instructions-bar "Permalink to this headline")

`bar`, `bar.cta`, `barrier`, `barrier.cta`

Barrier synchronization.

Syntax

```
barrier{.cta}.sync{.aligned}      a{, b};

barrier{.cta}.arrive{.aligned}    a, b;



barrier{.cta}.red.popc{.aligned}.u32  d, a{, b}, {!}c;

barrier{.cta}.red.op{.aligned}.pred   p, a{, b}, {!}c;



bar{.cta}.sync      a{, b};

bar{.cta}.arrive    a, b;



bar{.cta}.red.popc.u32  d, a{, b}, {!}c;

bar{.cta}.red.op.pred   p, a{, b}, {!}c;



.op = { .and, .or };
```

Description

Performs barrier synchronization and communication within a CTA. Each CTA instance has sixteen
barriers numbered `0..15`.

`barrier{.cta}` instructions can be used by the threads within the CTA for synchronization and
communication.

Operands `a`, `b`, and `d` have type `.u32`; operands `p` and `c` are predicates. Source
operand `a` specifies a logical barrier resource as an immediate constant or register with value
`0` through `15`. Operand `b` specifies the number of threads participating in the barrier. If
no thread count is specified, all threads in the CTA participate in the barrier. When specifying a
thread count, the value must be a multiple of the warp size. Note that a non-zero thread count is
required for `barrier{.cta}.arrive`.

Depending on operand `b`, either specified number of threads (in multiple of warp size) or all
threads in the CTA participate in `barrier{.cta}` instruction. The `barrier{.cta}` instructions
signal the arrival of the executing threads at the named barrier.

`barrier{.cta}` instruction causes executing thread to wait for all non-exited threads from its
warp and marks warps’ arrival at barrier. In addition to signaling its arrival at the barrier, the
`barrier{.cta}.red` and `barrier{.cta}.sync` instructions causes executing thread to wait for
non-exited threads of all other warps participating in the barrier to
arrive. `barrier{.cta}.arrive` does not cause executing thread to wait for threads of other
participating warps.

When a barrier completes, the waiting threads are restarted without delay, and the barrier is
reinitialized so that it can be immediately reused.

The `barrier{.cta}.sync` or `barrier{.cta}.red` or `barrier{.cta}.arrive` instruction
guarantees that when the barrier completes, prior memory accesses requested by this thread are
performed relative to all threads participating in the barrier. The `barrier{.cta}.sync` and
`barrier{.cta}.red` instruction further guarantees that no new memory access is requested by this
thread before the barrier completes.

A memory read (e.g., by `ld` or `atom`) has been performed when the value read has been
transmitted from memory and cannot be modified by another thread participating in the barrier. A
memory write (e.g., by `st`, `red` or `atom`) has been performed when the value written has
become visible to other threads participating in the barrier, that is, when the previous value can
no longer be read.

`barrier{.cta}.red` performs a reduction operation across threads. The `c` predicate (or its
complement) from all threads in the CTA are combined using the specified reduction operator. Once
the barrier count is reached, the final value is written to the destination register in all threads
waiting at the barrier.

The reduction operations for `barrier{.cta}.red` are population-count (`.popc`),
all-threads-True (`.and`), and any-thread-True (`.or`). The result of `.popc` is the number of
threads with a `True` predicate, while `.and` and `.or` indicate if all the threads had a
`True` predicate or if any of the threads had a `True` predicate.

Instruction `barrier{.cta}` has optional `.aligned` modifier. When specified, it indicates that
all threads in CTA will execute the same `barrier{.cta}` instruction. In conditionally executed
code, an aligned `barrier{.cta}` instruction should only be used if it is known that all threads
in CTA evaluate the condition identically, otherwise behavior is undefined.

Different warps may execute different forms of the `barrier{.cta}` instruction using the same
barrier name and thread count. One example mixes `barrier{.cta}.sync` and `barrier{.cta}.arrive`
to implement producer/consumer models. The producer threads execute `barrier{.cta}.arrive` to
announce their arrival at the barrier and continue execution without delay to produce the next
value, while the consumer threads execute the `barrier{.cta}.sync` to wait for a resource to be
produced. The roles are then reversed, using a different barrier, where the producer threads execute
a `barrier{.cta}.sync` to wait for a resource to consumed, while the consumer threads announce
that the resource has been consumed with `barrier{.cta}.arrive`. Care must be taken to keep a warp
from executing more `barrier{.cta}` instructions than intended (`barrier{.cta}.arrive` followed
by any other `barrier{.cta}` instruction to the same barrier) prior to the reset of the
barrier. `barrier{.cta}.red` should not be intermixed with `barrier{.cta}.sync` or
`barrier{.cta}.arrive` using the same active barrier. Execution in this case is unpredictable.

The optional `.cta` qualifier simply indicates CTA-level applicability of the barrier and it
doesn’t change the semantics of the instruction.

`bar{.cta}.sync` is equivalent to `barrier{.cta}.sync.aligned`. `bar{.cta}.arrive` is
equivalent to `barrier{.cta}.arrive.aligned`. `bar{.cta}.red` is equivalent to
`barrier{.cta}.red.aligned`.

Note

For .target `sm_6x` or below,

1. `barrier{.cta}` instruction without `.aligned` modifier is equivalent to `.aligned`
   variant and has the same restrictions as of `.aligned` variant.
2. All threads in warp (except for those have exited) must execute `barrier{.cta}` instruction
   in convergence.

PTX ISA Notes

`bar.sync` without a thread count introduced in PTX ISA version 1.0.

Register operands, thread count, and `bar.{arrive,red}` introduced in PTX ISA version 2.0.

`barrier` instruction introduced in PTX ISA version 6.0.

`.cta` qualifier introduced in PTX ISA version 7.8.

Target ISA Notes

Register operands, thread count, and `bar{.cta}.{arrive,red}` require `sm_20` or higher.

Only `bar{.cta}.sync` with an immediate barrier number is supported for `sm_1x` targets.

`barrier{.cta}` instruction requires `sm_30` or higher.

Examples

```
// Use bar.sync to arrive at a pre-computed barrier number and

// wait for all threads in CTA to also arrive:

    st.shared [r0],r1;  // write my result to shared memory

    bar.cta.sync  1;    // arrive, wait for others to arrive

    ld.shared r2,[r3];  // use shared results from other threads



// Use bar.sync to arrive at a pre-computed barrier number and

// wait for fixed number of cooperating threads to arrive:

    #define CNT1 (8*12) // Number of cooperating threads



    st.shared [r0],r1;     // write my result to shared memory

    bar.cta.sync  1, CNT1; // arrive, wait for others to arrive

    ld.shared r2,[r3];     // use shared results from other threads



// Use bar.red.and to compare results across the entire CTA:

    setp.eq.u32 p,r1,r2;         // p is True if r1==r2

    bar.cta.red.and.pred r3,1,p; // r3=AND(p) forall threads in CTA



// Use bar.red.popc to compute the size of a group of threads

// that have a specific condition True:

    setp.eq.u32 p,r1,r2;         // p is True if r1==r2

    bar.cta.red.popc.u32 r3,1,p; // r3=SUM(p) forall threads in CTA



// Examples of barrier.cta.sync

    st.shared         [r0],r1;

    barrier.cta.sync  0;

    ld.shared         r1, [r0];



/* Producer/consumer model. The producer deposits a value in

 * shared memory, signals that it is complete but does not wait

 * using bar.arrive, and begins fetching more data from memory.

 * Once the data returns from memory, the producer must wait

 * until the consumer signals that it has read the value from

 * the shared memory location. In the meantime, a consumer

 * thread waits until the data is stored by the producer, reads

 * it, and then signals that it is done (without waiting).

 */

    // Producer code places produced value in shared memory.

    st.shared   [r0],r1;

    bar.arrive  0,64;

    ld.global   r1,[r2];

    bar.sync    1,64;

    ...



    // Consumer code, reads value from shared memory

    bar.sync   0,64;

    ld.shared  r1,[r0];

    bar.arrive 1,64;

    ...
```

#### 9.7.13.2. [Parallel Synchronization and Communication Instructions: `bar.warp.sync`](#parallel-synchronization-and-communication-instructions-bar-warp-sync)[](#parallel-synchronization-and-communication-instructions-bar-warp-sync "Permalink to this headline")

`bar.warp.sync`

Barrier synchronization for threads in a warp.

Syntax

```
bar.warp.sync      membermask;
```

Description

`bar.warp.sync` will cause executing thread to wait until all threads corresponding to
`membermask` have executed a `bar.warp.sync` with the same `membermask` value before resuming
execution.

Operand `membermask` specifies a 32-bit integer which is a mask indicating threads participating
in barrier where the bit position corresponds to thread’s `laneid`.

The behavior of `bar.warp.sync` is undefined if the executing thread is not in the `membermask`.

`bar.warp.sync` also guarantee memory ordering among threads participating in barrier. Thus,
threads within warp that wish to communicate via memory can store to memory, execute
`bar.warp.sync`, and then safely read values stored by other threads in warp.

Note

For .target `sm_6x` or below, all threads in `membermask` must execute the same
`bar.warp.sync` instruction in convergence, and only threads belonging to some `membermask`
can be active when the `bar.warp.sync` instruction is executed. Otherwise, the behavior is
undefined.

PTX ISA Notes

Introduced in PTX ISA version 6.0.

Target ISA Notes

Requires `sm_30` or higher.

Examples

```
st.shared.u32 [r0],r1;         // write my result to shared memory

bar.warp.sync  0xffffffff;     // arrive, wait for others to arrive

ld.shared.u32 r2,[r3];         // read results written by other threads
```

#### 9.7.13.3. [Parallel Synchronization and Communication Instructions: `barrier.cluster`](#parallel-synchronization-and-communication-instructions-barrier-cluster)[](#parallel-synchronization-and-communication-instructions-barrier-cluster "Permalink to this headline")

`barrier.cluster`

Barrier synchronization within a cluster.

Syntax

```
barrier.cluster.arrive{.sem}{.aligned};

barrier.cluster.wait{.acquire}{.aligned};



.sem = {.release, .relaxed}
```

Description

Performs barrier synchronization and communication within a cluster.

`barrier.cluster` instructions can be used by the threads within the cluster for synchronization
and communication.

`barrier.cluster.arrive` instruction marks warps’ arrival at barrier without causing executing
thread to wait for threads of other participating warps.

`barrier.cluster.wait` instruction causes the executing thread to wait for all non-exited threads
of the cluster to perform `barrier.cluster.arrive`.

In addition, `barrier.cluster` instructions cause the executing thread to wait for all non-exited
threads from its warp.

When all non-exited threads in the cluster have executed `barrier.cluster.arrive`, the barrier
completes and is automatically reinitialized. After using `barrier.cluster.wait` to detect completion
of the barrier, a thread may immediately arrive at the barrier once again.
Each thread must arrive at the barrier only once before the barrier completes.

The `barrier.cluster.wait` instruction guarantees that when it completes the execution, memory
accesses (except asynchronous operations) requested, in program order, prior to the preceding
`barrier.cluster.arrive` by all threads in the cluster are complete and visible to the executing
thread.

There is no memory ordering and visibility guarantee for memory accesses requested by the executing
thread, in program order, after `barrier.cluster.arrive` and prior to `barrier.cluster.wait`.

The optional `.relaxed` qualifier on `barrier.cluster.arrive` specifies that there are no memory
ordering and visibility guarantees provided for the memory accesses performed prior to
`barrier.cluster.arrive`.

The optional `.sem` and `.acquire` qualifiers on instructions `barrier.cluster.arrive` and
`barrier.cluster.wait` specify the memory synchronization as described in the
[Memory Consistency Model](#memory-consistency-model). If the optional `.sem` qualifier is absent for
`barrier.cluster.arrive`, `.release` is assumed by default. If the optional `.acquire`
qualifier is absent for `barrier.cluster.wait`, `.acquire` is assumed by default.

The optional `.aligned` qualifier indicates that all threads in the warp must execute the same
`barrier.cluster` instruction. In conditionally executed code, an aligned `barrier.cluster`
instruction should only be used if it is known that all threads in the warp evaluate the condition
identically, otherwise behavior is undefined.

PTX ISA Notes

Introduced in PTX ISA version 7.8.

Support for `.acquire`, `.relaxed`, `.release` qualifiers introduced in PTX ISA version 8.0.

Target ISA Notes

Requires `sm_90` or higher.

Examples

```
// use of arrive followed by wait

ld.shared::cluster.u32 r0, [addr];

barrier.cluster.arrive.aligned;

...

barrier.cluster.wait.aligned;

st.shared::cluster.u32 [addr], r1;



// use memory fence prior to arrive for relaxed barrier

@cta0 ld.shared::cluster.u32 r0, [addr];

fence.cluster.acq_rel;

barrier.cluster.arrive.relaxed.aligned;

...

barrier.cluster.wait.aligned;

@cta1 st.shared::cluster.u32 [addr], r1;
```

#### 9.7.13.4. [Parallel Synchronization and Communication Instructions: `membar` / `fence`](#parallel-synchronization-and-communication-instructions-membar)[](#parallel-synchronization-and-communication-instructions-membar "Permalink to this headline")

`membar`, `fence`

Enforce an ordering of memory operations.

Syntax

```
// Thread fence:

fence{.sem}.scope;



// Thread fence (uni-directional):

fence.acquire.sync_restrict::shared::cluster.cluster;

fence.release.sync_restrict::shared::cta.cluster;



// Operation fence (uni-directional):

fence.op_restrict.release.cluster;



// Proxy fence (bi-directional):

fence.proxy.proxykind;



// Proxy fence (uni-directional):

fence.proxy.to_proxykind::from_proxykind.release.scope;

fence.proxy.to_proxykind::from_proxykind.acquire.scope  [addr], size;

fence.proxy.async::generic.acquire.sync_restrict::shared::cluster.cluster;

fence.proxy.async::generic.release.sync_restrict::shared::cta.cluster;



// Old style membar:

membar.level;

membar.proxy.proxykind;



.sem       = { .sc, .acq_rel, .acquire, .release };

.scope     = { .cta, .cluster, .gpu, .sys };

.level     = { .cta, .gl, .sys };

.proxykind = { .alias, .async, .async.global, .async.shared::{cta, cluster} };

.op_restrict = { .mbarrier_init };

.to_proxykind::from_proxykind = {.tensormap::generic};
```

Description

The `membar` instruction guarantees that prior memory accesses requested by this thread (`ld`,
`st`, `atom` and `red` instructions) are performed at the specified `level`, before later
memory operations requested by this thread following the `membar` instruction. The `level`
qualifier specifies the set of threads that may observe the ordering effect of this operation.

A memory read (e.g., by `ld` or `atom`) has been performed when the value read has been
transmitted from memory and cannot be modified by another thread at the indicated level. A memory
write (e.g., by `st`, `red` or `atom`) has been performed when the value written has become
visible to other threads at the specified level, that is, when the previous value can no longer be
read.

The `fence` instruction establishes an ordering between memory accesses requested by this thread
(`ld`, `st`, `atom` and `red` instructions) as described in the
[Memory Consistency Model](#memory-consistency-model). The scope qualifier specifies the set of threads that may
observe the ordering effect of this operation.

`fence.acq_rel` is a light-weight fence that is sufficient for memory synchronization in most
programs. Instances of `fence.acq_rel` synchronize when combined with additional memory operations
as described in `acquire` and `release` patterns in the [Memory Consistency Model](#memory-consistency-model).
If the optional `.sem` qualifier is absent, `.acq_rel`
is assumed by default.

`fence.sc` is a slower fence that can restore *sequential consistency* when used in sufficient
places, at the cost of performance. Instances of `fence.sc` with sufficient scope always
synchronize by forming a total order per scope, determined at runtime. This total order can be
constrained further by other synchronization in the program.

Qualifiers `.op_restrict` and `.sync_restrict` restrict the class of memory operations
for which the `fence` instruction provides the memory ordering guarantees. When `.op_restrict`
is `.mbarrier_init`, the synchronizing effect of the fence only applies to the prior
`mbarrier.init` operations executed by the same thread on *mbarrier objects* in `.shared::cta`
state space. When `.sync_restrict` is `.sync_restrict::shared::cta`, `.sem` must be
`.release`, and the effect of the fence only applies to operations performed on objects in
`.shared::cta` state space. Likewise, when `.sync_restrict` is `.sync_restrict::shared::cluster`,
`.sem` must be `.acquire`, and the effect of the fence only applies to operations performed on
objects in `.shared::cluster` state space. When either `.sync_restrict::shared::cta` or
`.sync_restrict::shared::cluster` is present, the `.scope` must be specified as `.cluster`.

The address operand `addr` and the operand `size` together specify the memory range
`[addr, addr+size-1]` on which the ordering guarantees on the memory accesses across the proxies is to be
provided. The only supported value for the `size` operand is 128, which must be a constant integer literal.
[Generic Addressing](#generic-addressing) is used unconditionally, and the address specified by
the operand `addr` must fall within the `.global` state space. Otherwise, the behavior is undefined.

On `sm_70` and higher `membar` is a synonym for `fence.sc`1, and the `membar`
levels `cta`, `gl` and `sys` are synonymous with the `fence` scopes `cta`, `gpu` and
`sys` respectively.

`membar.proxy` and `fence.proxy` instructions establish an ordering between memory accesses that
may happen through different *proxies*.

A *uni-directional* proxy ordering from the *from-proxykind* to the *to-proxykind* establishes
ordering between a prior memory access performed via the *from-proxykind* and a subsequent memory access
performed via the *to-proxykind*.

A *bi-directional* proxy ordering between two proxykinds establishes two *uni-directional* proxy orderings
: one from the first proxykind to the second proxykind and the other from the second proxykind to the first
proxykind.

The `.proxykind` qualifier indicates the *bi-directional* proxy ordering that is established between the memory
accesses done between the generic proxy and the proxy specified by `.proxykind`.

Value `.alias` of the `.proxykind` qualifier refers to memory accesses performed using virtually
aliased addresses to the same memory location. Value `.async` of the `.proxykind` qualifier specifies
that the memory ordering is established between the async proxy and the generic proxy. The memory
ordering is limited only to operations performed on objects in the state space specified. If no state space
is specified, then the memory ordering applies on all state spaces.

A `.release` proxy fence can form a release sequence that synchronizes with an acquire
sequence that contains a `.acquire` proxy fence. The `.to_proxykind` and
`.from_proxykind` qualifiers indicate the *uni-directional* proxy ordering that is established.

On `sm_70` and higher, `membar.proxy` is a synonym for `fence.proxy`.

1 The semantics of `fence.sc` introduced with `sm_70` is a superset of the semantics of
`membar` and the two are compatible; when executing on `sm_70` or later architectures,
`membar` acquires the full semantics of `fence.sc`.

PTX ISA Notes

`membar.{cta,gl}` introduced in PTX ISA version 1.4.

`membar.sys` introduced in PTX ISA version 2.0.

`fence` introduced in PTX ISA version 6.0.

`membar.proxy` and `fence.proxy` introduced in PTX ISA version 7.5.

`.cluster` scope qualifier introduced in PTX ISA version 7.8.

`.op_restrict` qualifier introduced in PTX ISA version 8.0.

`fence.proxy.async` is introduced in PTX ISA version 8.0.

`.to_proxykind::from_proxykind` qualifier introduced in PTX ISA version 8.3.

`.acquire` and `.release` qualifiers for `fence` instruction introduced in PTX ISA version 8.6.

`.sync_restrict` qualifier introduced in PTX ISA version 8.6.

Target ISA Notes

`membar.{cta,gl}` supported on all target architectures.

`membar.sys` requires `sm_20` or higher.

`fence` requires `sm_70` or higher.

`membar.proxy` requires `sm_60` or higher.

`fence.proxy` requires `sm_70` or higher.

`.cluster` scope qualifier requires `sm_90` or higher.

`.op_restrict` qualifier requires `sm_90` or higher.

`fence.proxy.async` requires `sm_90` or higher.

`.to_proxykind::from_proxykind` qualifier requires `sm_90` or higher.

`.acquire` and `.release` qualifiers for `fence` instruction require `sm_90` or higher..

`.sync_restrict` qualifier requires `sm_90` or higher..

Examples

```
membar.gl;

membar.cta;

membar.sys;

fence.sc.cta;

fence.sc.cluster;

fence.proxy.alias;

membar.proxy.alias;

fence.mbarrier_init.release.cluster;

fence.proxy.async;

fence.proxy.async.shared::cta;

fence.proxy.async.shared::cluster;

fence.proxy.async.global;



tensormap.replace.tile.global_address.global.b1024.b64   [gbl], new_addr;

fence.proxy.tensormap::generic.release.gpu;

cvta.global.u64  tmap, gbl;

fence.proxy.tensormap::generic.acquire.gpu [tmap], 128;

cp.async.bulk.tensor.1d.shared::cluster.global.tile  [addr0], [tmap, {tc0}], [mbar0];



// Acquire remote barrier state via async proxy.

barrier.cluster.wait.acquire;

fence.proxy.async::generic.acquire.sync_restrict::shared::cluster.cluster;



// Release local barrier state via async proxy.

mbarrier.init [bar];

fence.mbarrier_init.release.cluster;

fence.proxy.async::generic.release.sync_restrict::shared::cta.cluster;

barrier.cluster.arrive.relaxed;



// Acquire local shared memory via generic proxy.

mbarrier.try_wait.relaxed.cluster.shared::cta.b64 complete, [addr], parity;

fence.acquire.sync_restrict::shared::cluster.cluster;



// Release local shared memory via generic proxy.

fence.release.sync_restrict::shared::cta.cluster;

mbarrier.arrive.relaxed.cluster.shared::cluster.b64 state, [bar];
```

#### 9.7.13.5. [Parallel Synchronization and Communication Instructions: `atom`](#parallel-synchronization-and-communication-instructions-atom)[](#parallel-synchronization-and-communication-instructions-atom "Permalink to this headline")

`atom`

Atomic reduction operations for thread-to-thread communication.

Syntax

Atomic operation with scalar type:

```
atom{.sem}{.scope}{.space}.op{.level::cache_hint}.type d, [a], b{, cache-policy};

atom{.sem}{.scope}{.space}.op.type d, [a], b, c;



atom{.sem}{.scope}{.space}.cas.b16 d, [a], b, c;



atom{.sem}{.scope}{.space}.cas.b128 d, [a], b, c;

atom{.sem}{.scope}{.space}.exch{.level::cache_hint}.b128 d, [a], b {, cache-policy};



atom{.sem}{.scope}{.space}.add.noftz{.level::cache_hint}.f16     d, [a], b{, cache-policy};

atom{.sem}{.scope}{.space}.add.noftz{.level::cache_hint}.f16x2   d, [a], b{, cache-policy};



atom{.sem}{.scope}{.space}.add.noftz{.level::cache_hint}.bf16    d, [a], b{, cache-policy};

atom{.sem}{.scope}{.space}.add.noftz{.level::cache_hint}.bf16x2  d, [a], b{, cache-policy};



.space =              { .global, .shared{::cta, ::cluster} };

.sem =                { .relaxed, .acquire, .release, .acq_rel };

.scope =              { .cta, .cluster, .gpu, .sys };



.op =                 { .and, .or, .xor,

                        .cas, .exch,

                        .add, .inc, .dec,

                        .min, .max };

.level::cache_hint =  { .L2::cache_hint };

.type =               { .b32, .b64, .u32, .u64, .s32, .s64, .f32, .f64 };
```

Atomic operation with vector type:

```
atom{.sem}{.scope}{.global}.add{.level::cache_hint}.vec_32_bit.f32                  d, [a], b{, cache-policy};

atom{.sem}{.scope}{.global}.op.noftz{.level::cache_hint}.vec_16_bit.half_word_type  d, [a], b{, cache-policy};

atom{.sem}{.scope}{.global}.op.noftz{.level::cache_hint}.vec_32_bit.packed_type     d, [a], b{, cache-policy};



.sem =               { .relaxed, .acquire, .release, .acq_rel };

.scope =             { .cta, .cluster, .gpu, .sys };

.op =                { .add, .min, .max };

.half_word_type =    { .f16, .bf16 };

.packed_type =       { .f16x2, .bf16x2 };

.vec_16_bit =        { .v2, .v4, .v8 }

.vec_32_bit =        { .v2, .v4 };

.level::cache_hint = { .L2::cache_hint }
```

Description

Atomically loads the original value at location `a` into destination register `d`, performs a
reduction operation with operand `b` and the value in location `a`, and stores the result of the
specified operation at location `a`, overwriting the original value. Operand `a` specifies a
location in the specified state space. If no state space is given, perform the memory accesses using
[Generic Addressing](#generic-addressing). `atom` with scalar type may be used only
with `.global` and `.shared` spaces and with generic addressing, where the address points to
`.global` or `.shared` space. `atom` with vector type may be used only with `.global` space
and with generic addressing where the address points to `.global` space.

For `atom` with vector type, operands `d` and `b` are brace-enclosed vector expressions, size
of which is equal to the size of vector qualifier.

If no sub-qualifier is specified with `.shared` state space, then `::cta` is assumed by default.

The optional `.sem` qualifier specifies a memory synchronizing effect as described in the
[Memory Consistency Model](#memory-consistency-model). If the `.sem` qualifier is absent,
`.relaxed` is assumed by default.

The optional `.scope` qualifier specifies the set of threads that can directly observe the memory
synchronizing effect of this operation, as described in the [Memory Consistency Model](#memory-consistency-model).
If the `.scope` qualifier is absent, `.gpu` scope is
assumed by default.

For `atom` with vector type, the supported combinations of vector qualifier and types, and atomic
operations supported on these combinations are depicted in the following table:

| Vector qualifier | Types | | |
| --- | --- | --- | --- |
| `.f16`/ `bf16` | `.f16x2`/ `bf16x2` | `.f32` |
| `.v2` | `.add`, `.min`, `.max` | `.add`, `.min`, `.max` | `.add` |
| `.v4` | `.add`, `.min`, `.max` | `.add`, `.min`, `.max` | `.add` |
| `.v8` | `.add`, `.min`, `.max` | Not supported | Not Supported |

Two atomic operations (`atom` or `red`) are performed atomically with respect to each other only
if each operation specifies a scope that includes the other. When this condition is not met, each
operation observes the other operation being performed as if it were split into a read followed by a
dependent write.

`atom` instruction on packed type or vector type, accesses adjacent scalar elements in memory. In
such cases, the atomicity is guaranteed separately for each of the individual scalar elements; the
entire `atom` is not guaranteed to be atomic as a single access.

For `sm_6x` and earlier architectures, `atom` operations on `.shared` state space do not
guarantee atomicity with respect to normal store instructions to the same address. It is the
programmer’s responsibility to guarantee correctness of programs that use shared memory atomic
instructions, e.g., by inserting barriers between normal stores and atomic operations to a common
address, or by using atom.exch to store to locations accessed by other atomic operations.

Supported addressing modes for operand `a` and alignment requirements are described in [Addresses as Operands](#addresses-as-operands)

The bit-size operations are `.and`, `.or`, `.xor`, `.cas` (compare-and-swap), and `.exch`
(exchange).

The integer operations are `.add`, `.inc`, `.dec`, `.min`, `.max`. The `.inc` and
`.dec` operations return a result in the range `[0..b]`.

The floating-point operation `.add` operation rounds to nearest even. Current implementation of
`atom.add.f32` on global memory flushes subnormal inputs and results to sign-preserving zero;
whereas `atom.add.f32` on shared memory supports subnormal inputs and results and doesn’t flush
them to zero.

`atom.add.f16`, `atom.add.f16x2`, `atom.add.bf16` and `atom.add.bf16x2` operation requires
the `.noftz` qualifier; it preserves subnormal inputs and results, and does not flush them to
zero.

When the optional argument `cache-policy` is specified, the qualifier `.level::cache_hint` is
required. The 64-bit operand `cache-policy` specifies the cache eviction policy that may be used
during the memory access.

The qualifier `.level::cache_hint` is only supported for `.global` state space and for generic
addressing where the address points to the `.global` state space.

`cache-policy` is a hint to the cache subsystem and may not always be respected. It is treated as
a performance hint only, and does not change the memory consistency behavior of the program.

Semantics

```
atomic {

    d = *a;

    *a = (operation == cas) ? operation(*a, b, c)

                            : operation(*a, b);

}

where

    inc(r, s)  = (r >= s) ? 0 : r+1;

    dec(r, s)  = (r==0 || r > s)  ? s : r-1;

    exch(r, s) =  s;

    cas(r,s,t) = (r == s) ? t : r;
```

Notes

Simple reductions may be specified by using the *bit bucket* destination operand `_`.

PTX ISA Notes

32-bit atom.global introduced in PTX ISA version 1.1.

`atom.shared` and 64-bit `atom.global.{add,cas,exch}` introduced in PTX ISA 1.2.

`atom.add.f32` and 64-bit `atom.shared.{add,cas,exch}` introduced in PTX ISA 2.0.

64-bit `atom.{and,or,xor,min,max}` introduced in PTX ISA 3.1.

`atom.add.f64` introduced in PTX ISA 5.0.

`.scope` qualifier introduced in PTX ISA 5.0.

`.sem` qualifier introduced in PTX ISA version 6.0.

`atom.add.noftz.f16x2` introduced in PTX ISA 6.2.

`atom.add.noftz.f16` and `atom.cas.b16` introduced in PTX ISA 6.3.

Per-element atomicity of `atom.f16x2` clarified in PTX ISA version 6.3, with retrospective effect
from PTX ISA version 6.2.

Support for `.level::cache_hint` qualifier introduced in PTX ISA version 7.4.

`atom.add.noftz.bf16` and `atom.add.noftz.bf16x2` introduced in PTX ISA 7.8.

Support for `.cluster` scope qualifier introduced in PTX ISA version 7.8.

Support for `::cta` and `::cluster` sub-qualifiers introduced in PTX ISA version 7.8.

Support for vector types introduced in PTX ISA version 8.1.

Support for `.b128` type introduced in PTX ISA version 8.3.

Support for `.sys` scope with `.b128` type introduced in PTX ISA version 8.4.

Target ISA Notes

`atom.global` requires `sm_11` or higher.

`atom.shared` requires `sm_12` or higher.

64-bit `atom.global.{add,cas,exch}` require `sm_12` or higher.

64-bit `atom.shared.{add,cas,exch}` require `sm_20` or higher.

64-bit `atom.{and,or,xor,min,max}` require `sm_32` or higher.

`atom.add.f32` requires `sm_20` or higher.

`atom.add.f64` requires `sm_60` or higher.

`.scope` qualifier requires `sm_60` or higher.

`.sem` qualifier requires `sm_70` or higher.

Use of generic addressing requires `sm_20` or higher.

`atom.add.noftz.f16x2` requires `sm_60` or higher.

`atom.add.noftz.f16` and `atom.cas.b16` requires `sm_70` or higher.

Support for `.level::cache_hint` qualifier requires `sm_80` or higher.

`atom.add.noftz.bf16` and `atom.add.noftz.bf16x2` require `sm_90` or higher.

Support for `.cluster` scope qualifier requires `sm_90` or higher.

Sub-qualifier `::cta` requires `sm_30` or higher.

Sub-qualifier `::cluster` requires `sm_90` or higher.

Support for vector types requires `sm_90` or higher.

Support for `.b128` type requires `sm_90` or higher.

Examples

```
atom.global.add.s32  d,[a],1;

atom.shared::cta.max.u32  d,[x+4],0;

@p  atom.global.cas.b32  d,[p],my_val,my_new_val;

atom.global.sys.add.u32 d, [a], 1;

atom.global.acquire.sys.inc.u32 ans, [gbl], %r0;

atom.add.noftz.f16x2 d, [a], b;

atom.add.noftz.f16   hd, [ha], hb;

atom.global.cas.b16  hd, [ha], hb, hc;

atom.add.noftz.bf16   hd, [a], hb;

atom.add.noftz.bf16x2 bd, [b], bb;

atom.add.shared::cluster.noftz.f16   hd, [ha], hb;

atom.shared.b128.cas d, a, b, c; // 128-bit atom

atom.global.b128.exch d, a, b;   // 128-bit atom



atom.global.cluster.relaxed.add.u32 d, [a], 1;



createpolicy.fractional.L2::evict_last.b64 cache-policy, 0.25;

atom.global.add.L2::cache_hint.s32  d, [a], 1, cache-policy;



atom.global.v8.f16.max.noftz  {%hd0, %hd1, %hd2, %hd3, %hd4, %hd5, %hd6, %hd7}, [gbl],

                                              {%h0, %h1, %h2, %h3, %h4, %h5, %h6, %h7};

atom.global.v8.bf16.add.noftz  {%hd0, %hd1, %hd2, %hd3, %hd4, %hd5, %hd6, %hd7}, [gbl],

                                              {%h0, %h1, %h2, %h3, %h4, %h5, %h6, %h7};

atom.global.v2.f16.add.noftz  {%hd0, %hd1}, [gbl], {%h0, %h1};

atom.global.v2.bf16.add.noftz  {%hd0, %hd1}, [gbl], {%h0, %h1};

atom.global.v4.b16x2.min.noftz  {%hd0, %hd1, %hd2, %hd3}, [gbl], {%h0, %h1, %h2, %h3};

atom.global.v4.f32.add  {%f0, %f1, %f2, %f3}, [gbl], {%f0, %f1, %f2, %f3};

atom.global.v2.f16x2.min.noftz  {%bd0, %bd1}, [g], {%b0, %b1};

atom.global.v2.bf16x2.max.noftz  {%bd0, %bd1}, [g], {%b0, %b1};

atom.global.v2.f32.add  {%f0, %f1}, [g], {%f0, %f1};
```

#### 9.7.13.6. [Parallel Synchronization and Communication Instructions: `red`](#parallel-synchronization-and-communication-instructions-red)[](#parallel-synchronization-and-communication-instructions-red "Permalink to this headline")

`red`

Reduction operations on global and shared memory.

Syntax

Reduction operation with scalar type:

```
red{.sem}{.scope}{.space}.op{.level::cache_hint}.type          [a], b{, cache-policy};



red{.sem}{.scope}{.space}.add.noftz{.level::cache_hint}.f16    [a], b{, cache-policy};



red{.sem}{.scope}{.space}.add.noftz{.level::cache_hint}.f16x2  [a], b{, cache-policy};



red{.sem}{.scope}{.space}.add.noftz{.level::cache_hint}.bf16

                                                      [a], b {, cache-policy};



red{.sem}{.scope}{.space}.add.noftz{.level::cache_hint}.bf16x2

                                                      [a], b {, cache-policy};



.space =              { .global, .shared{::cta, ::cluster} };

.sem =                {.relaxed, .release};

.scope =              {.cta, .cluster, .gpu, .sys};



.op =                 { .and, .or, .xor,

                        .add, .inc, .dec,

                        .min, .max };

.level::cache_hint =  { .L2::cache_hint };

.type =               { .b32, .b64, .u32, .u64, .s32, .s64, .f32, .f64 };
```

Reduction operation with vector type:

```
red{.sem}{.scope}{.global}.add{.level::cache_hint}.vec_32_bit.f32 [a], b{, cache-policy};

red{.sem}{.scope}{.global}.op.noftz{.level::cache_hint}. vec_16_bit.half_word_type [a], b{, cache-policy};

red{.sem}{.scope}{.global}.op.noftz{.level::cache_hint}.vec_32_bit.packed_type [a], b {, cache-policy};



.sem =                { .relaxed, .release };

.scope =              { .cta, .cluster, .gpu, .sys };

.op =                 { .add, .min, .max };

.half_word_type =     { .f16, .bf16 };

.packed_type =        { .f16x2,.bf16x2 };

.vec_16_bit =         { .v2, .v4, .v8 }

.vec_32_bit =         { .v2, .v4 };

.level::cache_hint =  { .L2::cache_hint }
```

Description

Performs a reduction operation with operand `b` and the value in location `a`, and stores the
result of the specified operation at location `a`, overwriting the original value. Operand `a`
specifies a location in the specified state space. If no state space is given, perform the memory
accesses using [Generic Addressing](#generic-addressing). `red` with scalar type may
be used only with `.global` and `.shared` spaces and with generic addressing, where the address
points to `.global` or `.shared` space. `red` with vector type may be used only with
`.global` space and with generic addressing where the address points to `.global` space.

For `red` with vector type, operand `b` is brace-enclosed vector expressions, size of which is
equal to the size of vector qualifier.

If no sub-qualifier is specified with `.shared` state space, then `::cta` is assumed by default.

The optional `.sem` qualifier specifies a memory synchronizing effect as described in the
[Memory Consistency Model](#memory-consistency-model). If the `.sem` qualifier is absent,
`.relaxed` is assumed by default.

The optional `.scope` qualifier specifies the set of threads that can directly observe the memory
synchronizing effect of this operation, as described in the [Memory Consistency Model](#memory-consistency-model).
If the `.scope` qualifier is absent, `.gpu` scope is
assumed by default.

For `red` with vector type, the supported combinations of vector qualifier, types and reduction
operations supported on these combinations are depicted in following table:

| Vector qualifier | Types | | |
| --- | --- | --- | --- |
| `.f16`/ `bf16` | `.f16x2`/ `bf16x2` | `.f32` |
| `.v2` | `.add`, `.min`, `.max` | `.add`, `.min`, `.max` | `.add` |
| `.v4` | `.add`, `.min`, `.max` | `.add`, `.min`, `.max` | `.add` |
| `.v8` | `.add`, `.min`, `.max` | Not supported | Not Supported |

Two atomic operations (`atom` or `red`) are performed atomically with respect to each other only
if each operation specifies a scope that includes the other. When this condition is not met, each
operation observes the other operation being performed as if it were split into a read followed by a
dependent write.

`red` instruction on packed type or vector type, accesses adjacent scalar elements in memory. In
such case, the atomicity is guaranteed separately for each of the individual scalar elements; the
entire `red` is not guaranteed to be atomic as a single access.

For `sm_6x` and earlier architectures, `red` operations on `.shared` state space do not
guarantee atomicity with respect to normal store instructions to the same address. It is the
programmer’s responsibility to guarantee correctness of programs that use shared memory reduction
instructions, e.g., by inserting barriers between normal stores and reduction operations to a common
address, or by using `atom.exch` to store to locations accessed by other reduction operations.

Supported addressing modes for operand `a` and alignment requirements are described in [Addresses as Operands](#addresses-as-operands)

The bit-size operations are `.and`, `.or`, and `.xor`.

The integer operations are `.add`, `.inc`, `.dec`, `.min`, `.max`. The `.inc` and
`.dec` operations return a result in the range `[0..b]`.

The floating-point operation `.add` operation rounds to nearest even. Current implementation of
`red.add.f32` on global memory flushes subnormal inputs and results to sign-preserving zero;
whereas `red.add.f32` on shared memory supports subnormal inputs and results and doesn’t flush
them to zero.

`red.add.f16`, `red.add.f16x2`, `red.add.bf16` and `red.add.bf16x2` operation requires the
`.noftz` qualifier; it preserves subnormal inputs and results, and does not flush them to zero.

When the optional argument `cache-policy` is specified, the qualifier `.level::cache_hint` is
required. The 64-bit operand `cache-policy` specifies the cache eviction policy that may be used
during the memory access.

The qualifier `.level::cache_hint` is only supported for `.global` state space and for generic
addressing where the address points to the `.global` state space.

`cache-policy` is a hint to the cache subsystem and may not always be respected. It is treated as
a performance hint only, and does not change the memory consistency behavior of the program.

Semantics

```
*a = operation(*a, b);



where

    inc(r, s) = (r >= s) ? 0 : r+1;

    dec(r, s) = (r==0 || r > s)  ? s : r-1;
```

PTX ISA Notes

Introduced in PTX ISA version 1.2.

`red.add.f32` and `red.shared.add.u64` introduced in PTX ISA 2.0.

64-bit `red.{and,or,xor,min,max}` introduced in PTX ISA 3.1.

`red.add.f64` introduced in PTX ISA 5.0.

`.scope` qualifier introduced in PTX ISA 5.0.

`.sem` qualifier introduced in PTX ISA version 6.0.

`red.add.noftz.f16x2` introduced in PTX ISA 6.2.

`red.add.noftz.f16` introduced in PTX ISA 6.3.

Per-element atomicity of `red.f16x2` clarified in PTX ISA version 6.3, with retrospective effect
from PTX ISA version 6.2

Support for `.level::cache_hint` qualifier introduced in PTX ISA version 7.4.

`red.add.noftz.bf16` and `red.add.noftz.bf16x2` introduced in PTX ISA 7.8.

Support for `.cluster` scope qualifier introduced in PTX ISA version 7.8.

Support for `::cta` and `::cluster` sub-qualifiers introduced in PTX ISA version 7.8.

Support for vector types introduced in PTX ISA version 8.1.

Target ISA Notes

`red.global` requires `sm_11` or higher

`red.shared` requires `sm_12` or higher.

`red.global.add.u64` requires `sm_12` or higher.

`red.shared.add.u64` requires `sm_20` or higher.

64-bit `red.{and,or,xor,min,max}` require `sm_32` or higher.

`red.add.f32` requires `sm_20` or higher.

`red.add.f64` requires `sm_60` or higher.

`.scope` qualifier requires `sm_60` or higher.

`.sem` qualifier requires `sm_70` or higher.

Use of generic addressing requires `sm_20` or higher.

`red.add.noftz.f16x2` requires `sm_60` or higher.

`red.add.noftz.f16` requires `sm_70` or higher.

Support for `.level::cache_hint` qualifier requires `sm_80` or higher.

`red.add.noftz.bf16` and `red.add.noftz.bf16x2` require `sm_90` or higher.

Support for `.cluster` scope qualifier requires `sm_90` or higher.

Sub-qualifier `::cta` requires `sm_30` or higher.

Sub-qualifier `::cluster` requires `sm_90` or higher.

Support for vector types requires `sm_90` or higher.

Examples

```
red.global.add.s32  [a],1;

red.shared::cluster.max.u32  [x+4],0;

@p  red.global.and.b32  [p],my_val;

red.global.sys.add.u32 [a], 1;

red.global.acquire.sys.add.u32 [gbl], 1;

red.add.noftz.f16x2 [a], b;

red.add.noftz.bf16   [a], hb;

red.add.noftz.bf16x2 [b], bb;

red.global.cluster.relaxed.add.u32 [a], 1;

red.shared::cta.min.u32  [x+4],0;



createpolicy.fractional.L2::evict_last.b64 cache-policy, 0.25;

red.global.and.L2::cache_hint.b32 [a], 1, cache-policy;



red.global.v8.f16.add.noftz  [gbl], {%h0, %h1, %h2, %h3, %h4, %h5, %h6, %h7};

red.global.v8.bf16.min.noftz [gbl], {%h0, %h1, %h2, %h3, %h4, %h5, %h6, %h7};

red.global.v2.f16.add.noftz [gbl], {%h0, %h1};

red.global.v2.bf16.add.noftz [gbl], {%h0, %h1};

red.global.v4.f16x2.max.noftz [gbl], {%h0, %h1, %h2, %h3};

red.global.v4.f32.add  [gbl], {%f0, %f1, %f2, %f3};

red.global.v2.f16x2.max.noftz {%bd0, %bd1}, [g], {%b0, %b1};

red.global.v2.bf16x2.add.noftz {%bd0, %bd1}, [g], {%b0, %b1};

red.global.v2.f32.add  {%f0, %f1}, [g], {%f0, %f1};
```

#### 9.7.13.7. [Parallel Synchronization and Communication Instructions: `red.async`](#parallel-synchronization-and-communication-instructions-red-async)[](#parallel-synchronization-and-communication-instructions-red-async "Permalink to this headline")

`red.async`

Asynchronous reduction operation.

Syntax

```
// Increment and Decrement reductions

red.async.sem.scope{.ss}.completion_mechanism.op.type [a], b, [mbar];



.sem  =                 { .relaxed };

.scope =                { .cluster };

.ss   =                 { .shared::cluster };

.op   =                 { .inc, .dec };

.type =                 { .u32 };

.completion_mechanism = { .mbarrier::complete_tx::bytes };





// MIN and MAX reductions

red.async.sem.scope{.ss}.completion_mechanism.op.type [a], b, [mbar];



.sem  = { .relaxed };

.scope = { .cluster };

.ss   = { .shared::cluster };

.op   = { .min, .max };

.type = { .u32, .s32 };

.completion_mechanism = { .mbarrier::complete_tx::bytes };



// Bitwise AND, OR and XOR reductions

red.async.sem.scope{.ss}.completion_mechanism.op.type [a], b, [mbar];



.sem  = { .relaxed };

.scope = { .cluster };

.ss   = { .shared::cluster };

.op   = { .and, .or, .xor };

.type = { .b32 };

.completion_mechanism = { .mbarrier::complete_tx::bytes };



// ADD reductions

red.async.sem.scope{.ss}.completion_mechanism.add.type [a], b, [mbar];



.sem  = { .relaxed };

.scope = { .cluster };

.ss   = { .shared::cluster };

.type = { .u32, .s32, .u64 };

.completion_mechanism = { .mbarrier::complete_tx::bytes };



red.async{.mmio}.sem.scope{.ss}.add.type [a], b;



.sem  = { .release };

.scope = { .gpu, .cluster };

.ss   = { .global };

.type = { .u32, .s32, .u64, .s64 };
```

Description

`red.async` is a non-blocking instruction which initiates an asynchronous reduction operation
specified by `.op`, with the operand `b` and the value at destination shared memory location
specified by operand `a`.

Operands

* `a` is a destination address, and must be either a register, or of the form
  `register + immOff`, as described in [Addresses as Operands](#addresses-as-operands).
* `b` is a source value, of the type indicated by qualifier `.type`.
* `mbar` is an mbarrier object address.

Qualifiers

* `.mmio` indicates whether this is an [mmio Operation](#mmio-operation).
* `.sem` specifies the memory ordering semantics as described in the
  [Memory Consistency Model](#memory-consistency-model).
* `.scope` specifies the set of threads with which this instruction can
  directly synchronize.
* `.ss` specifies the state space of the destination operand `a` and the
  mbarrier operand `mbar`.

  + If `.ss` is not specified, [Generic Addressing](#generic-addressing)
    is used.
* `.completion_mechanism` specifies the mechanism for observing the
  completion of the asynchronous operation.

  + When `.completion_mechanism` is `.mbarrier::complete_tx::bytes`: upon
    completion of the asynchronous operation, a
    [complete-tx](#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation)
    operation will be performed on the mbarrier object specified by the operand `mbar`,
    with `completeCount` argument equal to the amount of data stored in bytes.
  + When `.completion_mechanism` is not specified: the completion of the store
    synchronizes with the end of the CTA.
* `.op` specifies the reduction operation.

  + The `.inc` and `.dec` operations return a result in the range `[0..b]`.
* `.type` specifies the type of the source operand `b`.

Conditions

When `.sem` is `.relaxed`:

* The reduce operation is a relaxed memory operation.
* The complete-tx operation on the mbarrier has `.release`
  semantics at `.cluster` scope.
* The shared-memory addresses of the destination operand `a` and the
  mbarrier operand `mbar` must meet all of the following conditions:

  + They belong to the same CTA.
  + The CTA to which they belong is different from the CTA of the executing thread,
    but must be within the same cluster.

  Otherwise, the behavior is undefined.
* `.mmio` must not be specified.
* If `.ss` is specified, it must be `.shared::cluster`.
* If `.ss` is not specified, generic addressing is used for operands `a` and `mbar`.
  If the generic addresses specified do not fall within the address window of
  `.shared::cluster` state space, the behavior is undefined.
* If `.completion_mechanism` is specified, it must be `.mbarrier::complete_tx::bytes`.
* If `.completion_mechanism` is not specified, it defaults to `.mbarrier::complete_tx::bytes`.

When `.sem` is `.release`:

* The reduce operation is a strong memory operation with `.release` semantics
  at the scope specified by `.scope`.
* If `.mmio` is specified, `.scope` must be `.sys`.
* If `.ss` is specified, it must be `.global`.
* If `.ss` is not specified, generic addressing is used for operand `a`.
  If the generic address specified does not fall within the address window of
  `.global` state space, the behavior is undefined.
* `.completion_mechanism` must not be specified.

PTX ISA Notes

Introduced in PTX ISA version 8.1.

Support for `.mmio` qualifier, `.release` semantics, `.global` state space,
and `.gpu` and `.sys` scopes introduced in PTX ISA version 8.7.

Target ISA Notes

Requires `sm_90` or higher.

`.mmio` qualifier, `.release` semantics, `.global` state space,
and `.gpu` and `.sys` scopes require `sm_100` or higher.

Examples

```
red.async.relaxed.cluster.shared::cluster.mbarrier::complete_tx::bytes.min.u32 [addr], b, [mbar_addr];



red.async.release.sys.global.add.u32 [addr], b;
```

#### 9.7.13.8. [Parallel Synchronization and Communication Instructions: `vote` (deprecated)](#parallel-synchronization-and-communication-instructions-vote)[](#parallel-synchronization-and-communication-instructions-vote "Permalink to this headline")

`vote` (deprecated)

Vote across thread group.

Syntax

```
vote.mode.pred  d, {!}a;

vote.ballot.b32 d, {!}a;  // 'ballot' form, returns bitmask



.mode = { .all, .any, .uni };
```

Deprecation Note

The `vote` instruction without a `.sync` qualifier is deprecated in PTX ISA version 6.0.

* Support for this instruction with `.target` lower than `sm_70` may be removed in a future PTX
  ISA version.

Removal Note

Support for `vote` instruction without a `.sync` qualifier is removed in PTX ISA version 6.4 for
`.target` `sm_70` or higher.

Description

Performs a reduction of the source predicate across all active threads in a warp. The destination
predicate value is the same across all threads in the warp.

The reduction modes are:

`.all`
:   `True` if source predicate is `True` for all active threads in warp. Negate the source
    predicate to compute `.none`.

`.any`
:   `True` if source predicate is `True` for some active thread in warp. Negate the source
    predicate to compute `.not_all`.

`.uni`
:   `True` if source predicate has the same value in all active threads in warp. Negating the
    source predicate also computes `.uni`.

In the *ballot* form, `vote.ballot.b32` simply copies the predicate from each thread in a warp
into the corresponding bit position of destination register `d`, where the bit position
corresponds to the thread’s lane id.

An inactive thread in warp will contribute a 0 for its entry when participating in
`vote.ballot.b32`.

PTX ISA Notes

Introduced in PTX ISA version 1.2.

Deprecated in PTX ISA version 6.0 in favor of `vote.sync`.

Not supported in PTX ISA version 6.4 for .target `sm_70` or higher.

Target ISA Notes

`vote` requires `sm_12` or higher.

`vote.ballot.b32` requires `sm_20` or higher.

`vote` is not supported on `sm_70` or higher starting PTX ISA version 6.4.

Release Notes

Note that `vote` applies to threads in a single warp, not across an entire CTA.

Examples

```
vote.all.pred    p,q;

vote.uni.pred    p,q;

vote.ballot.b32  r1,p;  // get 'ballot' across warp
```

#### 9.7.13.9. [Parallel Synchronization and Communication Instructions: `vote.sync`](#parallel-synchronization-and-communication-instructions-vote-sync)[](#parallel-synchronization-and-communication-instructions-vote-sync "Permalink to this headline")

`vote.sync`

Vote across thread group.

Syntax

```
vote.sync.mode.pred  d, {!}a, membermask;

vote.sync.ballot.b32 d, {!}a, membermask;  // 'ballot' form, returns bitmask



.mode = { .all, .any, .uni };
```

Description

`vote.sync` will cause executing thread to wait until all non-exited threads corresponding to
`membermask` have executed `vote.sync` with the same qualifiers and same `membermask` value
before resuming execution.

Operand `membermask` specifies a 32-bit integer which is a mask indicating threads participating
in this instruction where the bit position corresponds to thread’s `laneid`. Operand `a` is a
predicate register.

In the *mode* form, `vote.sync` performs a reduction of the source predicate across all non-exited
threads in `membermask`. The destination operand `d` is a predicate register and its value is
the same across all threads in `membermask`.

The reduction modes are:

`.all`
:   `True` if source predicate is `True` for all non-exited threads in `membermask`. Negate the
    source predicate to compute `.none`.

`.any`
:   `True` if source predicate is `True` for some thread in `membermask`. Negate the source
    predicate to compute `.not_all`.

`.uni`
:   `True` if source predicate has the same value in all non-exited threads in
    `membermask`. Negating the source predicate also computes `.uni`.

In the *ballot* form, the destination operand `d` is a `.b32` register. In this form,
`vote.sync.ballot.b32` simply copies the predicate from each thread in `membermask` into the
corresponding bit position of destination register `d`, where the bit position corresponds to the
thread’s lane id.

A thread not specified in `membermask` will contribute a 0 for its entry in
`vote.sync.ballot.b32`.

The behavior of `vote.sync` is undefined if the executing thread is not in the `membermask`.

Note

For .target `sm_6x` or below, all threads in `membermask` must execute the same `vote.sync`
instruction in convergence, and only threads belonging to some `membermask` can be active when
the `vote.sync` instruction is executed. Otherwise, the behavior is undefined.

PTX ISA Notes

Introduced in PTX ISA version 6.0.

Target ISA Notes

Requires `sm_30` or higher.

Examples

```
vote.sync.all.pred    p,q,0xffffffff;

vote.sync.ballot.b32  r1,p,0xffffffff;  // get 'ballot' across warp
```

#### 9.7.13.10. [Parallel Synchronization and Communication Instructions: `match.sync`](#parallel-synchronization-and-communication-instructions-match-sync)[](#parallel-synchronization-and-communication-instructions-match-sync "Permalink to this headline")

`match.sync`

Broadcast and compare a value across threads in warp.

Syntax

```
match.any.sync.type  d, a, membermask;

match.all.sync.type  d[|p], a, membermask;



.type = { .b32, .b64 };
```

Description

`match.sync` will cause executing thread to wait until all non-exited threads from `membermask`
have executed `match.sync` with the same qualifiers and same `membermask` value before resuming
execution.

Operand `membermask` specifies a 32-bit integer which is a mask indicating threads participating
in this instruction where the bit position corresponds to thread’s laneid.

`match.sync` performs broadcast and compare of operand `a` across all non-exited threads in
`membermask` and sets destination `d` and optional predicate `p` based on mode.

Operand `a` has instruction type and `d` has `.b32` type.

Destination `d` is a 32-bit mask where bit position in mask corresponds to thread’s laneid.

The matching operation modes are:

`.all`
:   `d` is set to mask corresponding to non-exited threads in `membermask` if all non-exited
    threads in `membermask` have same value of operand `a`; otherwise `d` is set
    to 0. Optionally predicate `p` is set to true if all non-exited threads in `membermask` have
    same value of operand `a`; otherwise `p` is set to false. The sink symbol ‘\_’ may be used in
    place of any one of the destination operands.

`.any`
:   `d` is set to mask of non-exited threads in `membermask` that have same value of operand
    `a`.

The behavior of `match.sync` is undefined if the executing thread is not in the `membermask`.

PTX ISA Notes

Introduced in PTX ISA version 6.0.

Target ISA Notes

Requires `sm_70` or higher.

Release Notes

Note that `match.sync` applies to threads in a single warp, not across an entire CTA.

Examples

```
match.any.sync.b32    d, a, 0xffffffff;

match.all.sync.b64    d|p, a, mask;
```

#### 9.7.13.11. [Parallel Synchronization and Communication Instructions: `activemask`](#parallel-synchronization-and-communication-instructions-activemask)[](#parallel-synchronization-and-communication-instructions-activemask "Permalink to this headline")

`activemask`

Queries the active threads within a warp.

Syntax

```
activemask.b32 d;
```

Description

`activemask` queries predicated-on active threads from the executing warp and sets the destination
`d` with 32-bit integer mask where bit position in the mask corresponds to the thread’s
`laneid`.

Destination `d` is a 32-bit destination register.

An active thread will contribute 1 for its entry in the result and exited or inactive or
predicated-off thread will contribute 0 for its entry in the result.

PTX ISA Notes

Introduced in PTX ISA version 6.2.

Target ISA Notes

Requires `sm_30` or higher.

Examples

```
activemask.b32  %r1;
```

#### 9.7.13.12. [Parallel Synchronization and Communication Instructions: `redux.sync`](#parallel-synchronization-and-communication-instructions-redux-sync)[](#parallel-synchronization-and-communication-instructions-redux-sync "Permalink to this headline")

`redux.sync`

Perform reduction operation on the data from each predicated active thread in the thread group.

Syntax

```
redux.sync.op.type dst, src, membermask;

.op   = {.add, .min, .max}

.type = {.u32, .s32}



redux.sync.op.b32 dst, src, membermask;

.op   = {.and, .or, .xor}



redux.sync.op{.abs.}{.NaN}.f32 dst, src, membermask;

.op   = { .min, .max }
```

Description

`redux.sync` will cause the executing thread to wait until all non-exited threads corresponding to
`membermask` have executed `redux.sync` with the same qualifiers and same `membermask` value
before resuming execution.

Operand `membermask` specifies a 32-bit integer which is a mask indicating threads participating
in this instruction where the bit position corresponds to thread’s `laneid`.

`redux.sync` performs a reduction operation `.op` of the 32 bit source register `src` across
all non-exited threads in the `membermask`. The result of the reduction operation is written to
the 32 bit destination register `dst`.

Reduction operation can be one of the bitwise operation in `.and`, `.or`, `.xor` or arithmetic
operation in `.add`, `.min` , `.max`.

For the `.add` operation result is truncated to 32 bits.

For `.f32` instruction type, if the input value is 0.0 then +0.0 > -0.0.

If `.abs` qualifier is specified, then the absolute value of the input is considered for the
reduction operation.

If the `.NaN` qualifier is specified, then the result of the reduction operation is canonical NaN
if the input to the reduction operation from any participating thread is NaN.

In the absence of `.NaN` qualifier, only non-NaN values are considered for the reduction operation
and the result will be canonical NaN when all inputs are NaNs.

The behavior of `redux.sync` is undefined if the executing thread is not in the `membermask`.

PTX ISA Notes

Introduced in PTX ISA version 7.0.

Support for `.f32` type is introduced in PTX ISA version 8.6.

Support for `.abs` and `.NaN` qualifiers is introduced in PTX ISA version 8.6.

Target ISA Notes

Requires `sm_80` or higher.

`.f32` type requires `sm_100a` and is supported on `sm_100f` from PTX ISA version 8.8.

Qualifiers `.abs` and `.NaN` require `sm_100a` and are supported on `sm_100f` or
higher in the same family from PTX ISA version 8.8.

Release Notes

Note that `redux.sync` applies to threads in a single warp, not across an entire CTA.

Examples

```
.reg .b32 dst, src, init, mask;

redux.sync.add.s32 dst, src, 0xff;

redux.sync.xor.b32 dst, src, mask;



redux.sync.min.abs.NaN.f32 dst, src, mask;
```

#### 9.7.13.13. [Parallel Synchronization and Communication Instructions: `griddepcontrol`](#parallel-synchronization-and-communication-instructions-griddepcontrol)[](#parallel-synchronization-and-communication-instructions-griddepcontrol "Permalink to this headline")

`griddepcontrol`

Control execution of dependent grids.

Syntax

```
griddepcontrol.action;



.action   = { .launch_dependents, .wait }
```

Description

The `griddepcontrol` instruction allows the dependent grids and prerequisite grids as defined by
the runtime, to control execution in the following way:

`.launch_dependents` modifier signals that specific dependents the runtime system designated to
react to this instruction can be scheduled as soon as all other CTAs in the grid issue the same
instruction or have completed. The dependent may launch before the completion of the current
grid. There is no guarantee that the dependent will launch before the completion of the current
grid. Repeated invocations of this instruction by threads in the current CTA will have no additional
side effects past that of the first invocation.

`.wait` modifier causes the executing thread to wait until all prerequisite grids in flight have
completed and all the memory operations from the prerequisite grids are performed and made visible
to the current grid.

Note

If the prerequisite grid is using `griddepcontrol.launch_dependents`, then the dependent grid
must use `griddepcontrol.wait` to ensure correct functional execution.

PTX ISA Notes

Introduced in PTX ISA version 7.8.

Target ISA Notes

Requires `sm_90` or higher.

Examples

```
griddepcontrol.launch_dependents;

griddepcontrol.wait;
```

#### 9.7.13.14. [Parallel Synchronization and Communication Instructions: `elect.sync`](#parallel-synchronization-and-communication-instructions-elect-sync)[](#parallel-synchronization-and-communication-instructions-elect-sync "Permalink to this headline")

`elect.sync`

Elect a leader thread from a set of threads.

Syntax

```
elect.sync d|p, membermask;
```

Description

`elect.sync` elects one predicated active leader thread from among a set of threads specified by
`membermask`. `laneid` of the elected thread is returned in the 32-bit destination operand
`d`. The sink symbol ‘\_’ can be used for destination operand `d`. The predicate destination
`p` is set to `True` for the leader thread, and `False` for all other threads.

Operand `membermask` specifies a 32-bit integer indicating the set of threads from which a leader
is to be elected. The behavior is undefined if the executing thread is not in `membermask`.

Election of a leader thread happens deterministically, i.e. the same leader thread is elected for
the same `membermask` every time.

The mandatory `.sync` qualifier indicates that `elect` causes the executing thread to wait until
all threads in the `membermask` execute the `elect` instruction before resuming execution.

PTX ISA Notes

Introduced in PTX ISA version 8.0.

Target ISA Notes

Requires `sm_90` or higher.

Examples

```
elect.sync    %r0|%p0, 0xffffffff;
```

#### 9.7.13.15. [Parallel Synchronization and Communication Instructions: `mbarrier`](#parallel-synchronization-and-communication-instructions-mbarrier)[](#parallel-synchronization-and-communication-instructions-mbarrier "Permalink to this headline")

`mbarrier` is a barrier created in shared memory that supports :

* Synchronizing any subset of threads within a CTA
* One-way synchronization of threads across CTAs of a cluster. As noted in
  [mbarrier support with shared memory](#parallel-synchronization-and-communication-instructions-mbarrier-smem), threads can
  perform only *arrive* operations but not *\*\_wait* on an mbarrier located in `shared::cluster`
  space.
* Waiting for completion of asynchronous memory operations initiated by a thread and making them
  visible to other threads.

An *mbarrier object* is an opaque object in memory which can be initialized and invalidated using :

* `mbarrier.init`
* `mbarrier.inval`

Operations supported on *mbarrier object*s are :

* `mbarrier.expect_tx`
* `mbarrier.complete_tx`
* `mbarrier.arrive`
* `mbarrier.arrive_drop`
* `mbarrier.test_wait`
* `mbarrier.try_wait`
* `mbarrier.pending_count`
* `cp.async.mbarrier.arrive`

Performing any *mbarrier* operation except `mbarrier.init` on an uninitialized *mbarrier object*
results in undefined behavior.
Performing any *non-mbarrier* or `mbarrier.init` operations on an initialized *mbarrier object*
results in undefined behavior.

Unlike `bar{.cta}`/`barrier{.cta}` instructions which can access a limited number of barriers
per CTA, *mbarrier objects* are user defined and are only limited by the total shared memory size
available.

*mbarrier* operations enable threads to perform useful work after the arrival at the *mbarrier* and
before waiting for the *mbarrier* to complete.

##### 9.7.13.15.1. [Size and alignment of mbarrier object](#parallel-synchronization-and-communication-instructions-mbarrier-size-alignment)[](#parallel-synchronization-and-communication-instructions-mbarrier-size-alignment "Permalink to this headline")

An mbarrier object is an opaque object with the following type and alignment requirements :

| Type | Alignment (bytes) | Memory space |
| --- | --- | --- |
| `.b64` | 8 | `.shared` |

##### 9.7.13.15.2. [Contents of the mbarrier object](#parallel-synchronization-and-communication-instructions-mbarrier-contents)[](#parallel-synchronization-and-communication-instructions-mbarrier-contents "Permalink to this headline")

An opaque *mbarrier object* keeps track of the following information :

* Current phase of the *mbarrier object*
* Count of pending arrivals for the current phase of the *mbarrier object*
* Count of expected arrivals for the next phase of the *mbarrier object*
* Count of pending asynchronous memory operations (or transactions) tracked by the current phase of
  the *mbarrier object*. This is also referred to as *tx-count*.

An *mbarrier object* progresses through a sequence of phases where each phase is defined by threads
performing an expected number of
[arrive-on](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on)
operations.

The valid range of each of the counts is as shown below:

| Count name | Minimum value | Maximum value |
| --- | --- | --- |
| Expected arrival count | 1 | 220 - 1 |
| Pending arrival count | 0 | 220 - 1 |
| tx-count | -(220 - 1) | 220 - 1 |

##### 9.7.13.15.3. [Lifecycle of the mbarrier object](#parallel-synchronization-and-communication-instructions-mbarrier-lifecycle)[](#parallel-synchronization-and-communication-instructions-mbarrier-lifecycle "Permalink to this headline")

The *mbarrier object* must be initialized prior to use.

An *mbarrier object* is used to synchronize threads and asynchronous memory operations.

An *mbarrier object* may be used to perform a sequence of such synchronizations.

An *mbarrier object* must be invalidated to repurpose its memory for any purpose,
including repurposing it for another mbarrier object.

##### 9.7.13.15.4. [Phase of the mbarrier object](#parallel-synchronization-and-communication-instructions-mbarrier-phase)[](#parallel-synchronization-and-communication-instructions-mbarrier-phase "Permalink to this headline")

The phase of an *mbarrier object* is the number of times the *mbarrier object* has been used to
synchronize threads and [asynchronous](#program-order-async-operations)
operations. In each phase {0, 1, 2, …}, threads perform in program order :

* [arrive-on](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on)
  operations to complete the current phase and
* *test\_wait* / *try\_wait* operations to check for the completion of the current phase.

An *mbarrier object* is automatically reinitialized upon completion of the current phase for
immediate use in the next phase. The current phase is incomplete and all prior phases are complete.

For each phase of the mbarrier object, at least one *test\_wait* or *try\_wait* operation must be
performed which returns `True` for `waitComplete` before an [arrive-on](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on) operation
in the subsequent phase.

##### 9.7.13.15.5. [Tracking asynchronous operations by the mbarrier object](#parallel-synchronization-and-communication-instructions-mbarrier-tracking-async-operations)[](#parallel-synchronization-and-communication-instructions-mbarrier-tracking-async-operations "Permalink to this headline")

Starting with the Hopper architecture (`sm_9x`), *mbarrier object* supports a new count, called
*tx-count*, which is used for tracking the completion of asynchronous memory operations or
transactions. *tx-count* tracks the number of asynchronous transactions, in units specified by the
asynchronous memory operation, that are outstanding and yet to be complete.

The *tx-count* of an *mbarrier object* must be set to the total amount of asynchronous memory
operations, in units as specified by the asynchronous operations, to be tracked by the current
phase. Upon completion of each of the asynchronous operations, the [complete-tx](#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation)
operation will be performed on the *mbarrier object* and thus progress the mbarrier towards the
completion of the current phase.

###### 9.7.13.15.5.1. [expect-tx operation](#parallel-synchronization-and-communication-instructions-mbarrier-expect-tx-operation)[](#parallel-synchronization-and-communication-instructions-mbarrier-expect-tx-operation "Permalink to this headline")

The *expect-tx* operation, with an `expectCount` argument, increases the *tx-count* of an
*mbarrier object* by the value specified by `expectCount`. This sets the current phase of the
*mbarrier object* to expect and track the completion of additional asynchronous transactions.

###### 9.7.13.15.5.2. [complete-tx operation](#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation)[](#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation "Permalink to this headline")

The *complete-tx* operation, with an `completeCount` argument, on an *mbarrier object* consists of the following:

mbarrier signaling
:   Signals the completion of asynchronous transactions that were tracked by the current phase. As a
    result of this, *tx-count* is decremented by `completeCount`.

mbarrier potentially completing the current phase
:   If the current phase has been completed then the mbarrier transitions to the next phase. Refer to
    [Phase Completion of the mbarrier object](#parallel-synchronization-and-communication-instructions-mbarrier-phase-completion)
    for details on phase completion requirements and phase transition process.

##### 9.7.13.15.6. [Phase Completion of the mbarrier object](#parallel-synchronization-and-communication-instructions-mbarrier-phase-completion)[](#parallel-synchronization-and-communication-instructions-mbarrier-phase-completion "Permalink to this headline")

The requirements for completion of the current phase are described below. Upon completion of the
current phase, the phase transitions to the subsequent phase as described below.

Current phase completion requirements
:   An *mbarrier object* completes the current phase when all of the following conditions are met:

    * The count of the pending arrivals has reached zero.
    * The *tx-count* has reached zero.

Phase transition
:   When an *mbarrier* object completes the current phase, the following actions are performed
    atomically:

    * The *mbarrier object* transitions to the next phase.
    * The pending arrival count is reinitialized to the expected arrival count.

##### 9.7.13.15.7. [Arrive-on operation on mbarrier object](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on)[](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on "Permalink to this headline")

An *arrive-on* operation, with an optional *count* argument, on an *mbarrier object* consists of the
following 2 steps :

* mbarrier signalling:

  Signals the arrival of the executing thread OR completion of the asynchronous instruction which
  signals the arrive-on operation initiated by the executing thread on the *mbarrier object*. As a
  result of this, the pending arrival count is decremented by *count*. If the *count* argument is
  not specified, then it defaults to 1.
* mbarrier potentially completing the current phase:

  If the current phase has been completed then the mbarrier transitions to the next phase. Refer to
  [Phase Completion of the mbarrier object](#parallel-synchronization-and-communication-instructions-mbarrier-phase-completion)
  for details on phase completion requirements and phase transition process.

##### 9.7.13.15.8. [mbarrier support with shared memory](#parallel-synchronization-and-communication-instructions-mbarrier-smem)[](#parallel-synchronization-and-communication-instructions-mbarrier-smem "Permalink to this headline")

The following table summarizes the support of various mbarrier operations on *mbarrier objects*
located at different shared memory locations:

| mbarrier operations | `.shared::cta` | `.shared::cluster` |
| --- | --- | --- |
| `mbarrier.arrive` | Supported | Supported, cannot return result |
| `mbarrier.expect_tx` | Supported | Supported |
| `mbarrier.complete_tx` | Supported | Supported |
| Other mbarrier operations | Supported | Not supported |

##### 9.7.13.15.9. [Parallel Synchronization and Communication Instructions: `mbarrier.init`](#parallel-synchronization-and-communication-instructions-mbarrier-init)[](#parallel-synchronization-and-communication-instructions-mbarrier-init "Permalink to this headline")

`mbarrier.init`

Initialize the *mbarrier object*.

Syntax

```
mbarrier.init{.shared{::cta}}.b64 [addr], count;
```

Description

`mbarrier.init` initializes the *mbarrier object* at the location specified by the address operand
`addr` with the unsigned 32-bit integer `count`. The value of operand count must be in the range
as specified in [Contents of the mbarrier object](#parallel-synchronization-and-communication-instructions-mbarrier-contents).

Initialization of the *mbarrier object* involves :

* Initializing the current phase to 0.
* Initializing the expected arrival count to `count`.
* Initializing the pending arrival count to `count`.
* Initializing the *tx-count* to 0.

The valid range of values for the operand `count` is [1, …, 220 - 1].
Refer [Contents of the mbarrier object](#parallel-synchronization-and-communication-instructions-mbarrier-contents) for the
valid range of values for the various constituents of the mbarrier.

If no state space is specified then [Generic Addressing](#generic-addressing) is
used. If the address specified by `addr` does not fall within the address window of
`.shared::cta` state space then the behavior is undefined.

Supported addressing modes for operand `addr` is as described in [Addresses as Operands](#addresses-as-operands).
Alignment for operand `addr` is as described in the
[Size and alignment of mbarrier object](#parallel-synchronization-and-communication-instructions-mbarrier-size-alignment).

The behavior of performing an `mbarrier.init` operation on a memory location containing a
valid *mbarrier object* is undefined; invalidate the *mbarrier object* using `mbarrier.inval`
first, before repurposing the memory location for any other purpose, including another *mbarrier object*.

PTX ISA Notes

Introduced in PTX ISA version 7.0.

Support for sub-qualifier `::cta` on `.shared` introduced in PTX ISA version 7.8.

Target ISA Notes

Requires `sm_80` or higher.

Examples

```
.shared .b64 shMem, shMem2;

.reg    .b64 addr;

.reg    .b32 %r1;



cvta.shared.u64          addr, shMem2;

mbarrier.init.b64        [addr],   %r1;

bar.cta.sync             0;

// ... other mbarrier operations on addr



mbarrier.init.shared::cta.b64 [shMem], 12;

bar.sync                 0;

// ... other mbarrier operations on shMem
```

##### 9.7.13.15.10. [Parallel Synchronization and Communication Instructions: `mbarrier.inval`](#parallel-synchronization-and-communication-instructions-mbarrier-inval)[](#parallel-synchronization-and-communication-instructions-mbarrier-inval "Permalink to this headline")

`mbarrier.inval`

Invalidates the *mbarrier object*.

Syntax

```
mbarrier.inval{.shared{::cta}}.b64 [addr];
```

Description

`mbarrier.inval` invalidates the *mbarrier object* at the location specified by the address
operand `addr`.

An *mbarrier object* must be invalidated before using its memory location for any other purpose.

Performing any *mbarrier* operation except `mbarrier.init` on a memory location that does not
contain a valid *mbarrier object*, results in undefined behaviour.

If no state space is specified then [Generic Addressing](#generic-addressing) is
used. If the address specified by `addr` does not fall within the address window of
`.shared::cta` state space then the behavior is undefined.

Supported addressing modes for operand `addr` is as described in [Addresses as Operands](#addresses-as-operands).
Alignment for operand `addr` is as described in the
[Size and alignment of mbarrier object](#parallel-synchronization-and-communication-instructions-mbarrier-size-alignment).

PTX ISA Notes

Introduced in PTX ISA version 7.0.

Support for sub-qualifier `::cta` on `.shared` introduced in PTX ISA version 7.8.

Target ISA Notes

Requires `sm_80` or higher.

Examples

```
.shared .b64 shmem;

.reg    .b64 addr;

.reg    .b32 %r1;

.reg    .pred t0;



// Example 1 :

bar.sync                      0;

@t0 mbarrier.init.b64     [addr], %r1;

// ... other mbarrier operations on addr

bar.sync                      0;

@t0 mbarrier.inval.b64    [addr];





// Example 2 :

bar.cta.sync                  0;

mbarrier.init.shared.b64           [shmem], 12;

// ... other mbarrier operations on shmem

bar.cta.sync                  0;

@t0 mbarrier.inval.shared.b64      [shmem];



// shmem can be reused here for unrelated use :

bar.cta.sync                  0;

st.shared.b64                      [shmem], ...;



// shmem can be re-initialized as mbarrier object :

bar.cta.sync                  0;

@t0 mbarrier.init.shared.b64       [shmem], 24;

// ... other mbarrier operations on shmem

bar.cta.sync                  0;

@t0 mbarrier.inval.shared::cta.b64 [shmem];
```

##### 9.7.13.15.11. [Parallel Synchronization and Communication Instructions: `mbarrier.expect_tx`](#parallel-synchronization-and-communication-instructions-mbarrier-expect-tx)[](#parallel-synchronization-and-communication-instructions-mbarrier-expect-tx "Permalink to this headline")

`mbarrier.expect_tx`

Perfoms
[expect-tx](#parallel-synchronization-and-communication-instructions-mbarrier-expect-tx-operation)
operation on the *mbarrier object*.

Syntax

```
mbarrier.expect_tx{.sem}{.scope}{.space}.b64 [addr], txCount;



.sem   = { .relaxed }

.scope = { .cta, .cluster }

.space = { .shared{::cta}, .shared::cluster }
```

Description

A thread executing `mbarrier.expect_tx` performs an [expect-tx](#parallel-synchronization-and-communication-instructions-mbarrier-expect-tx-operation)
operation on the *mbarrier object* at the location specified by the address operand `addr`. The
32-bit unsigned integer operand `txCount` specifies the `expectCount` argument to the
*expect-tx* operation.

If no state space is specified then [Generic Addressing](#generic-addressing) is
used. If the address specified by `addr` does not fall within the address window of
`.shared::cta` or `.shared::cluster` state space then the behavior is undefined.

Supported addressing modes for operand `addr` are as described in [Addresses as Operands](#addresses-as-operands).
Alignment for operand `addr` is as described in the
[Size and alignment of mbarrier object](#parallel-synchronization-and-communication-instructions-mbarrier-size-alignment).

This operation does not provide any memory ordering semantics and thus is a *relaxed* operation.

PTX ISA Notes

Introduced in PTX ISA version 8.0.

Target ISA Notes

Requires `sm_90` or higher.

Examples

```
mbarrier.expect_tx.b64                       [addr], 32;

mbarrier.expect_tx.relaxed.cta.shared.b64    [mbarObj1], 512;

mbarrier.expect_tx.relaxed.cta.shared.b64    [mbarObj2], 512;
```

##### 9.7.13.15.12. [Parallel Synchronization and Communication Instructions: `mbarrier.complete_tx`](#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx)[](#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx "Permalink to this headline")

`mbarrier.complete_tx`

Perfoms
[complete-tx](#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation)
operation on the *mbarrier object*.

Syntax

```
mbarrier.complete_tx{.sem}{.scope}{.space}.b64 [addr], txCount;



.sem   = { .relaxed }

.scope = { .cta, .cluster }

.space = { .shared{::cta}, .shared::cluster }
```

Description

A thread executing `mbarrier.complete_tx` performs a [complete-tx](#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation)
operation on the *mbarrier object* at the location specified by the address operand `addr`. The
32-bit unsigned integer operand `txCount` specifies the `completeCount` argument to the
*complete-tx* operation.

`mbarrier.complete_tx` does not involve any asynchronous memory operations and only simulates the
completion of an asynchronous memory operation and its side effect of signaling to the *mbarrier
object*.

If no state space is specified then [Generic Addressing](#generic-addressing) is
used. If the address specified by `addr` does not fall within the address window of
`.shared::cta` or `.shared::cluster` state space then the behavior is undefined.

Supported addressing modes for operand `addr` are as described in [Addresses as Operands](#addresses-as-operands).
Alignment for operand `addr` is as described in the
[Size and alignment of mbarrier object](#parallel-synchronization-and-communication-instructions-mbarrier-size-alignment).

This operation does not provide any memory ordering semantics and thus is a *relaxed* operation.

PTX ISA Notes

Introduced in PTX ISA version 8.0.

Target ISA Notes

Requires `sm_90` or higher.

Examples

```
mbarrier.complete_tx.b64             [addr],     32;

mbarrier.complete_tx.shared.b64      [mbarObj1], 512;

mbarrier.complete_tx.relaxed.cta.b64 [addr2],    32;
```

##### 9.7.13.15.13. [Parallel Synchronization and Communication Instructions: `mbarrier.arrive`](#parallel-synchronization-and-communication-instructions-mbarrier-arrive)[](#parallel-synchronization-and-communication-instructions-mbarrier-arrive "Permalink to this headline")

`mbarrier.arrive`

Performs [arrive-on operation](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on) on the
*mbarrier object*.

Syntax

```
mbarrier.arrive{.sem}{.scope}{.shared{::cta}}.b64           state, [addr]{, count};

mbarrier.arrive{.sem}{.scope}{.shared::cluster}.b64         _, [addr] {,count}

mbarrier.arrive.expect_tx{.sem}{.scope}{.shared{::cta}}.b64 state, [addr], txCount;

mbarrier.arrive.expect_tx{.sem}{.scope}{.shared::cluster}.b64   _, [addr], txCount;

mbarrier.arrive.noComplete{.release}{.cta}{.shared{::cta}}.b64  state, [addr], count;



.sem   = { .release, .relaxed }

.scope = { .cta, .cluster }
```

Description

A thread executing `mbarrier.arrive` performs an [arrive-on](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on) operation
on the *mbarrier object* at the location specified by the address operand `addr`. The 32-bit
unsigned integer operand `count` specifies the *count* argument to the [arrive-on](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on)
operation.

If no state space is specified then [Generic Addressing](#generic-addressing) is
used. If the address specified by `addr` does not fall within the address window of
`.shared::cta` state space then the behavior is undefined.

Supported addressing modes for operand `addr` is as described in [Addresses as Operands](#addresses-as-operands).
Alignment for operand `addr` is as described in the
[Size and alignment of mbarrier object](#parallel-synchronization-and-communication-instructions-mbarrier-size-alignment).

The optional qualifier `.expect_tx` specifies that an [expect-tx](#parallel-synchronization-and-communication-instructions-mbarrier-expect-tx-operation)
operation is performed prior to the [arrive-on](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on)
operation. The 32-bit unsigned integer operand `txCount` specifies the *expectCount* argument to
the *expect-tx* operation. When both qualifiers `.arrive` and `.expect_tx` are specified, then
the count argument of the *arrive-on* operation is assumed to be 1.

A `mbarrier.arrive` operation with `.noComplete` qualifier must not cause the `mbarrier` to
complete its current phase, otherwise the behavior is undefined.

The value of the operand `count` must be in the range as specified in
[Contents of the mbarrier object](#parallel-synchronization-and-communication-instructions-mbarrier-contents).

Note: for `sm_8x`, when the argument `count` is specified, the modifier `.noComplete` is
required.

`mbarrier.arrive` operation on an *mbarrier object* located in `.shared::cta` returns an opaque
64-bit register capturing the phase of the *mbarrier object* prior to the [arrive-on operation](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on) in the
destination operand `state.` Contents of the `state` operand are implementation
specific. Optionally, sink symbol `'_'` can be used for the `state` argument.

`mbarrier.arrive` operation on an *mbarrier object* located in `.shared::cluster` but not in
`.shared::cta` cannot return a value. Sink symbol ‘\_’ is mandatory for the destination operand for
such cases.

The optional `.sem` qualifier specifies a memory synchronizing effect as described in the
[Memory Consistency Model](#memory-consistency-model). If the `.sem` qualifier is absent,
`.release` is assumed by default.

The `.relaxed` qualifier does not provide any memory ordering semantics and visibility
guarantees.

The optional `.scope` qualifier indicates the set of threads that directly observe the memory
synchronizing effect of this operation, as described in the [Memory Consistency Model](#memory-consistency-model).
If the `.scope` qualifier is not specified then it
defaults to `.cta`. In contrast, the `.shared::<scope>` indicates the state space where the
mbarrier resides.

PTX ISA Notes

Introduced in PTX ISA version 7.0.

Support for sink symbol ‘\_’ as the destination operand is introduced in PTX ISA version 7.1.

Support for sub-qualifier `::cta` on `.shared` introduced in PTX ISA version 7.8.

Support for `count` argument without the modifier `.noComplete` introduced in PTX ISA version
7.8.

Support for sub-qualifier `::cluster` introduced in PTX ISA version 8.0.

Support for qualifier `.expect_tx` is introduced in PTX ISA version 8.0.

Support for `.scope` and `.sem` qualifiers introduced in PTX ISA version 8.0

Support for `.relaxed` qualifier introduced in PTX ISA version 8.6.

Target ISA Notes

Requires `sm_80` or higher.

Support for `count` argument without the modifier `.noComplete` requires `sm_90` or higher.

Qualifier `.expect_tx` requires `sm_90` or higher.

Sub-qualifier `::cluster` requires `sm_90` or higher.

Support for `.cluster` scope requires `sm_90` or higher.

Examples

```
.reg .b32 cnt, remoteAddr32, remoteCTAId, addr32;

.reg .b64 %r<5>, addr, remoteAddr64;

.shared .b64 shMem, shMem2;



cvta.shared.u64            addr, shMem2;

mov.b32                    addr32, shMem2;

mapa.shared::cluster.u32   remoteAddr32, addr32, remoteCTAId;

mapa.u64                   remoteAddr64, addr,   remoteCTAId;



cvta.shared.u64          addr, shMem2;



mbarrier.arrive.shared.b64                       %r0, [shMem];

mbarrier.arrive.shared::cta.b64                  %r0, [shMem2];

mbarrier.arrive.release.cta.shared::cluster.b64  _, [remoteAddr32];

mbarrier.arrive.release.cluster.b64              _, [remoteAddr64], cnt;

mbarrier.arrive.expect_tx.release.cluster.b64    _, [remoteAddr64], tx_count;

mbarrier.arrive.noComplete.b64                   %r1, [addr], 2;

mbarrier.arrive.relaxed.cta.b64                  %r2, [addr], 4;

mbarrier.arrive.b64                              %r2, [addr], cnt;
```

##### 9.7.13.15.14. [Parallel Synchronization and Communication Instructions: `mbarrier.arrive_drop`](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-drop)[](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-drop "Permalink to this headline")

`mbarrier.arrive_drop`

Decrements the expected count of the *mbarrier object* and performs [arrive-on operation](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on).

Syntax

```
mbarrier.arrive_drop{.sem}{.scope}{.shared{::cta}}.b64 state,           [addr]{, count};

mbarrier.arrive_drop{.sem}{.scope}{.shared::cluster}.b64           _,   [addr] {,count};

mbarrier.arrive_drop.expect_tx{.shared{::cta}}{.sem}{.scope}.b64 state, [addr], tx_count;

mbarrier.arrive_drop.expect_tx{.shared::cluster}{.sem}{.scope}.b64   _, [addr], tx_count;

mbarrier.arrive_drop.noComplete{.release}{.cta}{.shared{::cta}}.b64 state,  [addr], count;



.sem   = { .release, .relaxed }

.scope = { .cta, .cluster }
```

Description

A thread executing `mbarrier.arrive_drop` on the *mbarrier object* at the location specified by
the address operand `addr` performs the following steps:

* Decrements the expected arrival count of the *mbarrier object* by the value specified by the
  32-bit integer operand `count`. If `count` operand is not specified, it defaults to 1.
* Performs an [arrive-on operation](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on) on the
  *mbarrier object*. The operand `count` specifies the *count* argument to the [arrive-on operation](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on).

The decrement done in the expected arrivals count of the *mbarrier object* will be for all the
subsequent phases of the *mbarrier object*.

If no state space is specified then [Generic Addressing](#generic-addressing) is
used. If the address specified by `addr` does not fall within the address window of
`.shared::cta` or `.shared::cluster` state space then the behavior is undefined.

Supported addressing modes for operand `addr` is as described in [Addresses as Operands](#addresses-as-operands).
Alignment for operand `addr` is as described in the
[Size and alignment of mbarrier object](#parallel-synchronization-and-communication-instructions-mbarrier-size-alignment).

The optional qualifier `.expect_tx` specifies that an [expect-tx](#parallel-synchronization-and-communication-instructions-mbarrier-expect-tx-operation)
operation is performed prior to the [arrive-on](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on)
operation. The 32-bit unsigned integer operand `txCount` specifies the *expectCount* argument to
the *expect-tx* operation. When both qualifiers `.arrive` and `.expect_tx` are specified, then
the count argument of the *arrive-on* operation is assumed to be 1.

`mbarrier.arrive_drop` operation with `.release` qualifier forms the *release* pattern as
described in the Memory Consistency Model and synchronizes with the *acquire* patterns.

The optional `.sem` qualifier specifies a memory synchronizing effect as described in the
[Memory Consistency Model](#memory-consistency-model). If the `.sem` qualifier is absent,
`.release` is assumed by default. The `.relaxed` qualifier does not provide any memory
ordering semantics and visibility guarantees.

The optional `.scope` qualifier indicates the set of threads that an `mbarrier.arrive_drop`
instruction can directly synchronize. If the `.scope` qualifier is not specified then it defaults
to `.cta`. In contrast, the `.shared::<scope>` indicates the state space where the mbarrier
resides.

A `mbarrier.arrive_drop` with `.noComplete` qualifier must not complete the `mbarrier,`
otherwise the behavior is undefined.

The value of the operand `count` must be in the range as specified in
[Contents of the mbarrier object](#parallel-synchronization-and-communication-instructions-mbarrier-contents).

Note: for `sm_8x`, when the argument `count` is specified, the modifier `.noComplete` is
required.

A thread that wants to either exit or opt out of participating in the [arrive-on operation](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on) can use
`mbarrier.arrive_drop` to drop itself from the `mbarrier`.

`mbarrier.arrive_drop` operation on an *mbarrier object* located in `.shared::cta` returns an
opaque 64-bit register capturing the phase of the *mbarrier object* prior to the [arrive-on
operation](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on)
in the destination operand `state`. Contents of the returned state are implementation
specific. Optionally, sink symbol `'_'` can be used for the `state` argument.

`mbarrier.arrive_drop` operation on an *mbarrier* object located in `.shared::cluster` but not
in `.shared::cta` cannot return a value. Sink symbol ‘\_’ is mandatory for the destination operand
for such cases.

PTX ISA Notes

Introduced in PTX ISA version 7.0.

Support for sub-qualifier `::cta` on `.shared` introduced in PTX ISA version 7.8.

Support for `count` argument without the modifier `.noComplete` introduced in PTX ISA version
7.8.

Support for qualifier `.expect_tx` is introduced in PTX ISA version 8.0.

Support for sub-qualifier `::cluster` introduced in PTX ISA version 8.0.

Support for `.scope` and `.sem` qualifiers introduced in PTX ISA version 8.0

Support for `.relaxed` qualifier introduced in PTX ISA version 8.6.

Target ISA Notes

Requires `sm_80` or higher.

Support for `count` argument without the modifier `.noComplete` requires `sm_90` or higher.

Qualifier `.expect_tx` requires `sm_90` or higher.

Sub-qualifier `::cluster` requires `sm_90` or higher.

Support for `.cluster` scope requires `sm_90` or higher.

Examples

```
.reg .b32 cnt;

.reg .b64 %r1;

.shared .b64 shMem;



// Example 1

@p mbarrier.arrive_drop.shared.b64 _, [shMem];

@p exit;

@p2 mbarrier.arrive_drop.noComplete.shared.b64 _, [shMem], %a;

@p2 exit;

..

@!p mbarrier.arrive.shared.b64   %r1, [shMem];

@!p mbarrier.test_wait.shared.b64  q, [shMem], %r1;



// Example 2

mbarrier.arrive_drop.shared::cluster.b64 _, [addr];

mbarrier.arrive_drop.shared::cta.release.cluster.b64     _, [addr], cnt;



// Example 3

mbarrier.arrive_drop.expect_tx.shared::cta.relaxed.cluster.b64 state, [addr], tx_count;
```

##### 9.7.13.15.15. [Parallel Synchronization and Communication Instructions: `cp.async.mbarrier.arrive`](#parallel-synchronization-and-communication-instructions-cp-async-mbarrier-arrive)[](#parallel-synchronization-and-communication-instructions-cp-async-mbarrier-arrive "Permalink to this headline")

`cp.async.mbarrier.arrive`

Makes the *mbarrier object* track all prior [cp.async](#data-movement-and-conversion-instructions-cp-async)
operations initiated by the
executing thread.

Syntax

```
cp.async.mbarrier.arrive{.noinc}{.shared{::cta}}.b64 [addr];
```

Description

Causes an [arrive-on operation](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on) to be
triggered by the system on the *mbarrier object* upon the completion of all prior [cp.async](#data-movement-and-conversion-instructions-cp-async)
operations initiated by the
executing thread. The *mbarrier object* is at the location specified by the operand `addr`. The
[arrive-on operation](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on) is
asynchronous to execution of `cp.async.mbarrier.arrive`.

When `.noinc` modifier is not specified, the pending count of the mbarrier object is incremented
by 1 prior to the asynchronous [arrive-on operation](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on). This
results in a zero-net change for the pending count from the asynchronous [arrive-on](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on) operation
during the current phase. The pending count of the *mbarrier object* after the increment should not
exceed the limit as mentioned in
[Contents of the mbarrier object](#parallel-synchronization-and-communication-instructions-mbarrier-contents). Otherwise,
the behavior is undefined.

When the `.noinc` modifier is specified, the increment to the pending count of the *mbarrier
object* is not performed. Hence the decrement of the pending count done by the asynchronous
[arrive-on operation](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on) must be
accounted for in the initialization of the *mbarrier object*.

If no state space is specified then [Generic Addressing](#generic-addressing) is
used. If the address specified by `addr` does not fall within the address window of
`.shared::cta` state space then the behavior is undefined.

Supported addressing modes for operand `addr` is as described in [Addresses as Operands](#addresses-as-operands).
Alignment for operand `addr` is as described in the
[Size and alignment of mbarrier object](#parallel-synchronization-and-communication-instructions-mbarrier-size-alignment).

PTX ISA Notes

Introduced in PTX ISA version 7.0.

Support for sub-qualifier `::cta` on `.shared` introduced in PTX ISA version 7.8.

Target ISA Notes

Requires `sm_80` or higher.

Examples

```
// Example 1: no .noinc

mbarrier.init.shared.b64 [shMem], threadCount;

....

cp.async.ca.shared.global [shard1], [gbl1], 4;

cp.async.cg.shared.global [shard2], [gbl2], 16;

....

// Absence of .noinc accounts for arrive-on from completion of prior cp.async operations.

// So mbarrier.init must only account for arrive-on from mbarrier.arrive.

cp.async.mbarrier.arrive.shared.b64 [shMem];

....

mbarrier.arrive.shared.b64 state, [shMem];



waitLoop:

mbarrier.test_wait.shared.b64 p, [shMem], state;

@!p bra waitLoop;







// Example 2: with .noinc



// Tracks arrive-on from mbarrier.arrive and cp.async.mbarrier.arrive.



// All threads participating in the mbarrier perform cp.async

mov.b32 copyOperationCnt, threadCount;



// 3 arrive-on operations will be triggered per-thread

mul.lo.u32 copyArrivalCnt, copyOperationCnt, 3;



add.u32 totalCount, threadCount, copyArrivalCnt;



mbarrier.init.shared.b64 [shMem], totalCount;

....

cp.async.ca.shared.global [shard1], [gbl1], 4;

cp.async.cg.shared.global [shard2], [gbl2], 16;

...

// Presence of .noinc requires mbarrier initalization to have accounted for arrive-on from cp.async

cp.async.mbarrier.arrive.noinc.shared.b64 [shMem]; // 1st instance

....

cp.async.ca.shared.global [shard3], [gbl3], 4;

cp.async.ca.shared.global [shard4], [gbl4], 16;

cp.async.mbarrier.arrive.noinc.shared::cta.b64 [shMem]; // 2nd instance

....

cp.async.ca.shared.global [shard5], [gbl5], 4;

cp.async.cg.shared.global [shard6], [gbl6], 16;

cp.async.mbarrier.arrive.noinc.shared.b64 [shMem]; // 3rd and last instance

....

mbarrier.arrive.shared.b64 state, [shMem];



waitLoop:

mbarrier.test_wait.shared.b64 p, [shMem], state;

@!p bra waitLoop;
```

##### 9.7.13.15.16. [Parallel Synchronization and Communication Instructions: `mbarrier.test_wait` / `mbarrier.try_wait`](#parallel-synchronization-and-communication-instructions-mbarrier-test-wait-try-wait)[](#parallel-synchronization-and-communication-instructions-mbarrier-test-wait-try-wait "Permalink to this headline")

`mbarrier.test_wait`, `mbarrier.try_wait`

Checks whether the *mbarrier object* has completed the phase.

Syntax

```
mbarrier.test_wait{.sem}{.scope}{.shared{::cta}}.b64        waitComplete, [addr], state;

mbarrier.test_wait.parity{.sem}{.scope}{.shared{::cta}}.b64 waitComplete, [addr], phaseParity;



mbarrier.try_wait{.sem}{.scope}{.shared{::cta}}.b64         waitComplete, [addr], state

                                                               {, suspendTimeHint};



mbarrier.try_wait.parity{.sem}{.scope}{.shared{::cta}}.b64  waitComplete, [addr], phaseParity

                                                               {, suspendTimeHint};



.sem   = { .acquire, .relaxed }

.scope = { .cta, .cluster }
```

Description

The *test\_wait* and *try\_wait* operations test for the completion of the current or the immediately
preceding phase of an *mbarrier object* at the location specified by the operand `addr`.

`mbarrier.test_wait` is a non-blocking instruction which tests for the completion of the phase.

`mbarrier.try_wait` is a potentially blocking instruction which tests for the completion of the
phase. If the phase is not complete, the executing thread may be suspended. Suspended thread resumes
execution when the specified phase completes OR before the phase completes following a
system-dependent time limit. The optional 32-bit unsigned integer operand `suspendTimeHint`
specifies the time limit, in nanoseconds, that may be used for the time limit instead of the
system-dependent limit.

`mbarrier.test_wait` and `mbarrier.try_wait` test for completion of the phase :

* Specified by the operand `state`, which was returned by an `mbarrier.arrive` instruction on
  the same *mbarrier object* during the current or the immediately preceding phase. Or
* Indicated by the operand `phaseParity`, which is the integer parity of either the current phase
  or the immediately preceding phase of the *mbarrier object*.

The `.parity` variant of the instructions test for the completion of the phase indicated by the
operand `phaseParity`, which is the integer parity of either the current phase or the immediately
preceding phase of the *mbarrier object*. An even phase has integer parity 0 and an odd phase has
integer parity of 1. So the valid values of `phaseParity` operand are 0 and 1.

Note: the use of the `.parity` variants of the instructions requires tracking the phase of an
*mbarrier object* throughout its lifetime.

The *test\_wait* and *try\_wait* operations are valid only for :

* the current incomplete phase, for which `waitComplete` returns `False`.
* the immediately preceding phase, for which `waitComplete` returns `True`.

If no state space is specified then [Generic Addressing](#generic-addressing) is
used. If the address specified by `addr` does not fall within the address window of
`.shared::cta` state space then the behavior is undefined.

Supported addressing modes for operand `addr` is as described in [Addresses as Operands](#addresses-as-operands).
Alignment for operand `addr` is as described in the
[Size and alignment of mbarrier object](#parallel-synchronization-and-communication-instructions-mbarrier-size-alignment).

When `mbarrier.test_wait` and `mbarrier.try_wait` operations with `.acquire` qualifier
returns `True`, they form the *acquire* pattern as described in the
[Memory Consistency Model](#memory-consistency-model).

The optional `.sem` qualifier specifies a memory synchronizing effect as described in the
[Memory Consistency Model](#memory-consistency-model). If the `.sem` qualifier is absent,
`.acquire` is assumed by default. The `.relaxed` qualifier does not provide any memory
ordering semantics and visibility guarantees.

The optional `.scope` qualifier indicates the set of threads that the `mbarrier.test_wait` and
`mbarrier.try_wait` instructions can directly synchronize. If the `.scope` qualifier is not
specified then it defaults to `.cta`. In contrast, the `.shared::<scope>` indicates the state
space where the mbarrier resides.

The following ordering of memory operations hold for the executing thread when
`mbarrier.test_wait` or `mbarrier.try_wait` having acquire semantics returns `True` :

1. All memory accesses (except [async operations](#data-movement-and-conversion-instructions-cp-async)) requested prior, in program
   order, to `mbarrier.arrive` having release semantics during the completed phase by
   the participating threads of the CTA are performed and are visible to the executing thread.
2. All [cp.async](#data-movement-and-conversion-instructions-cp-async) operations
   requested prior, in program order, to `cp.async.mbarrier.arrive` during the completed phase by
   the participating threads of the CTA are performed and made visible to the executing thread.
3. All `cp.async.bulk` asynchronous operations using the same *mbarrier object* requested prior,
   in program order, to `mbarrier.arrive` having release semantics during the completed
   phase by the participating threads of the CTA are performed and made visible to the executing thread.
4. All memory accesses requested after the `mbarrier.test_wait` or `mbarrier.try_wait`, in
   program order, are not performed and not visible to memory accesses performed prior to
   `mbarrier.arrive` having release semantics, in program order, by other threads
   participating in the `mbarrier`.
5. There is no ordering and visibility guarantee for memory accesses requested by the thread after
   `mbarrier.arrive` having release semantics and prior to `mbarrier.test_wait`,
   in program order.

PTX ISA Notes

`mbarrier.test_wait` introduced in PTX ISA version 7.0.

Modifier `.parity` is introduced in PTX ISA version 7.1.

`mbarrier.try_wait` introduced in PTX ISA version 7.8.

Support for sub-qualifier `::cta` on `.shared` introduced in PTX ISA version 7.8.

Support for `.scope` and `.sem` qualifiers introduced in PTX ISA version 8.0

Support for `.relaxed` qualifier introduced in PTX ISA version 8.6.

Target ISA Notes

`mbarrier.test_wait` requires `sm_80` or higher.

`mbarrier.try_wait` requires `sm_90` or higher.

Support for `.cluster` scope requires `sm_90` or higher.

Examples

```
// Example 1a, thread synchronization with test_wait:



.reg .b64 %r1;

.shared .b64 shMem;



mbarrier.init.shared.b64 [shMem], N;  // N threads participating in the mbarrier.

...

mbarrier.arrive.shared.b64  %r1, [shMem]; // N threads executing mbarrier.arrive



// computation not requiring mbarrier synchronization...



waitLoop:

mbarrier.test_wait.shared.b64    complete, [shMem], %r1;

@!complete nanosleep.u32 20;

@!complete bra waitLoop;



// Example 1b, thread synchronization with try_wait :



.reg .b64 %r1;

.shared .b64 shMem;



mbarrier.init.shared.b64 [shMem], N;  // N threads participating in the mbarrier.

...

mbarrier.arrive.shared.b64  %r1, [shMem]; // N threads executing mbarrier.arrive



// computation not requiring mbarrier synchronization...



waitLoop:

mbarrier.try_wait.relaxed.cluster.shared.b64    complete, [shMem], %r1;

@!complete bra waitLoop;





// Example 2, thread synchronization using phase parity :



.reg .b32 i, parArg;

.reg .b64 %r1;

.shared .b64 shMem;



mov.b32 i, 0;

mbarrier.init.shared.b64 [shMem], N;  // N threads participating in the mbarrier.

...

loopStart :                           // One phase per loop iteration

    ...

    mbarrier.arrive.shared.b64  %r1, [shMem]; // N threads

    ...

    and.b32 parArg, i, 1;

    waitLoop:

    mbarrier.test_wait.parity.shared.b64  complete, [shMem], parArg;

    @!complete nanosleep.u32 20;

    @!complete bra waitLoop;

    ...

    add.u32 i, i, 1;

    setp.lt.u32 p, i, IterMax;

@p bra loopStart;





// Example 3, Asynchronous copy completion waiting :



.reg .b64 state;

.shared .b64 shMem2;

.shared .b64 shard1, shard2;

.global .b64 gbl1, gbl2;



mbarrier.init.shared.b64 [shMem2], threadCount;

...

cp.async.ca.shared.global [shard1], [gbl1], 4;

cp.async.cg.shared.global [shard2], [gbl2], 16;



// Absence of .noinc accounts for arrive-on from prior cp.async operation

cp.async.mbarrier.arrive.shared.b64 [shMem2];

...

mbarrier.arrive.shared.b64 state, [shMem2];



waitLoop:

mbarrier.test_wait.shared::cta.b64 p, [shMem2], state;

@!p bra waitLoop;



// Example 4, Synchronizing the CTA0 threads with cluster threads

.reg .b64 %r1, addr, remAddr;

.shared .b64 shMem;



cvta.shared.u64          addr, shMem;

mapa.u64                 remAddr, addr, 0;     // CTA0's shMem instance



// One thread from CTA0 executing the below initialization operation

@p0 mbarrier.init.shared::cta.b64 [shMem], N;  // N = no of cluster threads



barrier.cluster.arrive;

barrier.cluster.wait;



// Entire cluster executing the below arrive operation

mbarrier.arrive.release.cluster.b64              _, [remAddr];



// computation not requiring mbarrier synchronization ...



// Only CTA0 threads executing the below wait operation

waitLoop:

mbarrier.try_wait.parity.acquire.cluster.shared::cta.b64  complete, [shMem], 0;

@!complete bra waitLoop;
```

##### 9.7.13.15.17. [Parallel Synchronization and Communication Instructions: `mbarrier.pending_count`](#parallel-synchronization-and-communication-instructions-mbarrier-pending-count)[](#parallel-synchronization-and-communication-instructions-mbarrier-pending-count "Permalink to this headline")

`mbarrier.pending_count`

Query the pending arrival count from the opaque mbarrier state.

Syntax

```
mbarrier.pending_count.b64 count, state;
```

Description

The pending count can be queried from the opaque mbarrier state using `mbarrier.pending_count`.

The `state` operand is a 64-bit register that must be the result of a prior
`mbarrier.arrive.noComplete` or `mbarrier.arrive_drop.noComplete` instruction. Otherwise, the
behavior is undefined.

The destination register `count` is a 32-bit unsigned integer representing the pending count of
the *mbarrier object* prior to the [arrive-on operation](#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on) from
which the `state` register was obtained.

PTX ISA Notes

Introduced in PTX ISA version 7.0.

Target ISA Notes

Requires `sm_80` or higher.

Examples

```
.reg .b32 %r1;

.reg .b64 state;

.shared .b64 shMem;



mbarrier.arrive.noComplete.b64 state, [shMem], 1;

mbarrier.pending_count.b64 %r1, state;
```

#### 9.7.13.16. [Parallel Synchronization and Communication Instructions: `tensormap.cp_fenceproxy`](#parallel-synchronization-and-communication-instructions-tensormap-cp-fenceproxy)[](#parallel-synchronization-and-communication-instructions-tensormap-cp-fenceproxy "Permalink to this headline")

`tensormap.cp_fenceproxy`

A fused copy and fence operation.

Syntax

```
tensormap.cp_fenceproxy.cp_qualifiers.fence_qualifiers.sync.aligned  [dst], [src], size;



.cp_qualifiers    = { .global.shared::cta }

.fence_qualifiers = { .to_proxy::from_proxy.release.scope }

.to_proxy::from_proxy  = { .tensormap::generic }

.scope            = { .cta, .cluster, .gpu , .sys }
```

Description

The `tensormap.cp_fenceproxy` instructions perform the following operations in order :

* Copies data of size specified by the `size` argument, in bytes, from the location specified
  by the address operand `src` in shared memory to the location specified by the address operand
  `dst` in the global memory, in the generic proxy.
* Establishes a *uni-directional* proxy release pattern on the ordering from the copy operation
  to the subsequent access performed in the tensormap proxy on the address `dst`.

The valid value of immediate operand `size` is 128.

The operands `src` and `dst` specify non-generic addresses in `shared::cta` and `global`
state space respectively.

The `.scope` qualifier specifies the set of threads that can directly observe the proxy
synchronizing effect of this operation, as described in [Memory Consistency Model](#memory-consistency-model).

The mandatory `.sync` qualifier indicates that `tensormap.cp_fenceproxy` causes the executing
thread to wait until all threads in the warp execute the same `tensormap.cp_fenceproxy`
instruction before resuming execution.

The mandatory `.aligned` qualifier indicates that all threads in the warp must execute the same
`tensormap.cp_fenceproxy` instruction. In conditionally executed code, an aligned `tensormap.cp_fenceproxy`
instruction should only be used if it is known that all threads in the warp evaluate the condition
identically, otherwise behavior is undefined.

PTX ISA Notes

Introduced in PTX ISA version 8.3.

Target ISA Notes

Requires `sm_90` or higher.

Examples

```
// Example: manipulate a tensor-map object and then consume it in cp.async.bulk.tensor



.reg .b64 new_addr;

.global .align 128 .b8 gbl[128];

.shared .align 128 .b8 sMem[128];



cp.async.bulk.shared::cluster.global.mbarrier::complete_tx::bytes [sMem], [gMem], 128, [mbar];

...

try_wait_loop:

mbarrier.try_wait.shared.b64 p, [mbar], state;

@!p bra try_wait loop;



tensormap.replace.tile.global_address.shared.b1024.b64   [sMem], new_addr;

tensormap.cp_fenceproxy.global.shared::cta.tensormap::generic.release.gpu.sync.aligned

                                                         [gbl], [sMem], 128;

fence.proxy.tensormap::generic.acquire.gpu [gbl], 128;

cp.async.bulk.tensor.1d.shared::cluster.global.tile  [addr0], [gbl, {tc0}], [mbar0];
```

#### 9.7.13.17. [Parallel Synchronization and Communication Instructions: `clusterlaunchcontrol.try_cancel`](#parallel-synchronization-and-communication-instructions-clusterlaunchcontrol-try-cancel)[](#parallel-synchronization-and-communication-instructions-clusterlaunchcontrol-try-cancel "Permalink to this headline")

`clusterlaunchcontrol.try_cancel`

Requests cancellation of cluster which is not launched yet.

Syntax

```
clusterlaunchcontrol.try_cancel.async{.space}.completion_mechanism{.multicast::cluster::all}.b128 [addr], [mbar];



.completion_mechanism = { .mbarrier::complete_tx::bytes };

.space = { .shared::cta };
```

Description

The `clusterlaunchcontrol.try_cancel` instruction requests atomically cancelling the launch of
a cluster that has not started running yet. It asynchronously writes an opaque response to shared
memory indicating whether the operation succeeded or failed. The completion of the asynchronous
operation is tracked using the mbarrier completion mechanism at `.cluster` scope.

On success, the opaque response contains the `ctaid` of the first CTA of the canceled cluster; no
other successful response from other `clusterlaunchcontrol.try_cancel` operations from the same
grid will contain that id.

The mandatory `.async` qualifier indicates that the instruction will initiate the cancellation
operation asynchronously and control will return to the executing thread before the requested
operation is complete.

The `.space` qualifier is specified, both operands `addr` and `mbar` must be in the
`.shared::cta` state space. Otherwise, generic addressing will be assumed for both. The result
is undefined if any of address operands do not fall within the address window of `.shared::cta`.

The qualifier `.completion_mechanism` specifies that upon completion of the asynchronous operation,
[complete-tx](#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation)
operation, with `completeCount` argument equal to amount of data stored in bytes, will be performed
on the mbarrier object specified by the operand `mbar`.

The executing thread can then use [mbarrier instructions](#parallel-synchronization-and-communication-instructions-mbarrier) to wait for completion
of the asynchronous operation. No other synchronization mechanisms described in [Memory Consistency Model](#memory-consistency-model) can be used to guarantee the completion of the asynchronous copy operations.

The `.multicast::cluster::all` qualifier indicates that the response is asynchronously written using
weak async-proxy writes to the corresponding local shared memory `addr` of each CTA in the requesting
cluster. The completion of the writes to `addr` of a particular CTA is signaled via a complete-tx operation
to the mbarrier object on the shared memory of that CTA.

The behavior of instruction with `.multicast::cluster::all` qualifier is undefined if any CTA in the
cluster is exited.

Operand `addr` specifies the naturally aligned address of the 16-byte wide shared memory location where
the request’s response is written.

The response of `clusterlaunchcontrol.try_cancel` instruction will be 16-byte opaque value and will be
it available at location specified by operand `addr`. After loading this response into 16-byte register,
instruction `clusterlaunchcontrol.query_cancel` can be used to check if request was successful and to
retrieve `ctaid` of the first CTA of the canceled cluster.

If the executing CTA has already observed the completion of a `clusterlaunchcontrol.try_cancel` instruction
as failed, then the behavior of issuing a subsequent `clusterlaunchcontrol.try_cancel` instruction is undefined.

PTX ISA Notes

Introduced in PTX ISA version 8.6.

Target ISA Notes

Requires `sm_100` or higher.

Qualifier `.multicast::cluster::all` is supported on following architectures:

* `sm_100a`
* `sm_101a` (Renamed to `sm_110a` from PTX ISA version 9.0)
* `sm_120a`
* And is supported on following family-specific architectures from PTX ISA version 8.8:

  + `sm_100f` or higher in the same family
  + `sm_101f` or higher in the same family (Renamed to `sm_110f` from PTX ISA version 9.0)
  + `sm_120f` or higher in the same family
* `sm_110f` or higher in the same family

Examples

```
// Assumption: 1D cluster (cluster_ctaid.y/.z == 1)

// with 1 thread per CTA.



// Current Cluster to be processed, initially the

// currently launched cluster:



mov.b32 xctaid, %ctaid.x;

barrier.cluster.arrive.relaxed;

processCluster:



// Wait on all cluster CTAs completing initialization or processing of previous cluster:



barrier.cluster.wait.acquire;

mov.u32  %r0, %tid.x;

setp.u32.eq p0, %r0, 0x0;

@!p0 bra asyncWork;



// All CTAs in the cluster arrive at their local

// SMEM   barrier and set 16B handle tx count:



mbarrier.arrive.expect_tx.cluster.relaxed.shared::cta.b64 state, [mbar], 16;



// first CTA in Cluster attempts to cancel a

// not-yet-started cluster:



mov.u32  %r0, %cluster_ctaid.x;

setp.u32.eq p0, %r0, 0x0;

@p0 clusterlaunchcontrol.try_cancel.async.mbarrier::complete_tx::bytes.multicast::cluster::all.b128 [addr], [mbar];



asyncWork:

// ...process xctaid while cancellation request completes

// asynchronously...



// All CTAs in Cluster wait on cancellation responses on their local SMEM:



waitLoop:

// .acquire prevents the load of the handle from overtaking this read:



mbarrier.try_wait.cluster.acquire.shared::cta.b64   complete, [mbar], state;

@!complete bra waitLoop;



// Load response into 16-byte wide register after unblocking

// from mbarrier:



ld.shared.b128 handle, [addr];



// Check whether cancellation succeeded:



clusterlaunchcontrol.query_cancel.is_canceled.pred.b128 p, handle;

@!p ret; // If failed, we are don end exit:



// Otherwise, read ctaid of first CTA of cancelled Cluster for next iteration...



@p clusterlaunchcontrol.query_cancel.get_first_ctaid.v4.b32.b128 {xctaid, _, _, _},  handle;



// ...and signal CTA0 that we are done reading from handle:

// Fence generic->async



fence.proxy.async.shared::cta;

barrier.cluster.arrive.relaxed;



bra processCluster;
```

#### 9.7.13.18. [Parallel Synchronization and Communication Instructions: `clusterlaunchcontrol.query_cancel`](#parallel-synchronization-and-communication-instructions-clusterlaunchcontrol-query-cancel)[](#parallel-synchronization-and-communication-instructions-clusterlaunchcontrol-query-cancel "Permalink to this headline")

`clusterlaunchcontrol.query_cancel`

Queries response of `clusterlaunchcontrol.try_cancel` operation.

Syntax

```
clusterlaunchcontrol.query_cancel.is_canceled.pred.b128 pred, try_cancel_response;



clusterlaunchcontrol.query_cancel.get_first_ctaid.v4.b32.b128 {xdim, ydim, zdim, _},  try_cancel_response;



clusterlaunchcontrol.query_cancel.get_first_ctaid{::dimension}.b32.b128 reg, try_cancel_response;



::dimension = { ::x, ::y, ::z };
```

Description

Instruction `clusterlaunchcontrol.query_cancel` can be used to decode opaque response
written by instruction `clusterlaunchcontrol.try_cancel`.

After loading response from `clusterlaunchcontrol.try_cancel` instruction into 16-byte
register it can be further queried using `clusterlaunchcontrol.query_cancel` instruction
as follows:

`clusterlaunchcontrol.query_cancel.is_canceled.pred.b128`: If the cluster is canceled
successfully, predicate `p` is set to `true`; otherwise, it is set to `false`.

If the request succeeded, the instruction `clusterlaunchcontrol.query_cancel.get_first_ctaid`
extracts the CTA id of the first CTA in the canceled cluster. By default, the instruction
returns a `.v4` vector whose first three elements are the `x`, `y` and `z` coordinate
of first CTA in canceled cluster. The contents of the 4th element are unspecified. The
explicit `.get_first_ctaid::x`, `.get_first_ctaid::y`, or `.get_first_ctaid::z`
qualifiers can be used to extract individual `x`, `y` or `z` coordinates into a 32-bit
register.

If the request fails the behavior of `clusterlaunchcontrol.query_cancel.get_first_ctaid`
is undefined.

PTX ISA Notes

Introduced in PTX ISA version 8.6.

Target ISA Notes

Requires `sm_100` or higher.

Examples

```
clusterlaunchcontrol.query_cancel.is_canceled pred.b128 p, handle;



@p clusterlaunchcontrol.query_cancel.get_first_ctaid.v4.b32.b128 {xdim, ydim, zdim, ignr}  handle;



clusterlaunchcontrol.query_cancel.get_first_ctaid::x.b32.b128 reg0, handle;



clusterlaunchcontrol.query_cancel.get_first_ctaid::y.b32.b128 reg1, handle;



clusterlaunchcontrol.query_cancel.get_first_ctaid::z.b32.b128 reg2, handle;
```