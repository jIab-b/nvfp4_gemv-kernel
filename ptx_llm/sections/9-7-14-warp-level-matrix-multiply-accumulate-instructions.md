### 9.7.14. Warp Level Matrix Multiply-Accumulate Instructions 

The matrix multiply and accumulate operation has the following form:

```
D = A * B + C
```

where `D` and `C` are called accumulators and may refer to the same matrix.

PTX provides two ways to perform matrix multiply-and-accumulate computation:

* Using `wmma` instructions:

  + This warp-level computation is performed collectively by all threads in the warp as follows:

    - Load matrices A, B and C from memory into registers using the `wmma.load` operation. When
      the operation completes, the destination registers in each thread hold a fragment of the
      loaded matrix.
    - Perform the matrix multiply and accumulate operation using the `wmma.mma` operation on the
      loaded matrices. When the operation completes, the destination registers in each thread hold
      a fragment of the result matrix returned by the `wmma.mma` operation.
    - Store result Matrix D back to memory using the `wmma.store` operation. Alternately, result
      matrix D can also be used as argument C for a subsequent `wmma.mma` operation.

    The `wmma.load` and `wmma.store` instructions implicitly handle the organization of matrix
    elements when loading the input matrices from memory for the `wmma.mma` operation and when
    storing the result back to memory.
* Using `mma` instruction:

  + Similar to `wmma`, `mma` also requires computation to be performed collectively by all
    threads in the warp however distribution of matrix elements across different threads in warp
    needs to be done explicitly before invoking the `mma` operation. The `mma` instruction
    supports both dense as well as sparse matrix A. The sparse variant can be used when A is a
    structured sparse matrix as described in [Sparse matrix storage](#warp-level-sparse-matrix-storage).

#### 9.7.14.1. [Matrix Shape](#warp-level-matrix-shape)[](#warp-level-matrix-shape "Permalink to this headline")

The matrix multiply and accumulate operations support a limited set of shapes for the operand
matrices A, B and C. The shapes of all three matrix operands are collectively described by the tuple
`MxNxK`, where A is an `MxK` matrix, B is a `KxN` matrix, while C and D are `MxN` matrices.

The following matrix shapes are supported for the specified types:

| Instruction | Scale | Sparsity | Multiplicand Data-type | Shape | PTX ISA version |
| --- | --- | --- | --- | --- | --- |
| `wmma` | NA | Dense | Floating-point - `.f16` | `.m16n16k16`, `.m8n32k16`, and `.m32n8k16` | PTX ISA version 6.0 |
| `wmma` | Dense | Alternate floating-point format - `.bf16` | `.m16n16k16`, `.m8n32k16`, and `.m32n8k16` | PTX ISA version 7.0 |
| `wmma` | Dense | Alternate floating-point format - `.tf32` | `.m16n16k8` | PTX ISA version 7.0 |
| `wmma` | Dense | Integer - `.u8`/`.s8` | `.m16n16k16`, `.m8n32k16`, and `.m32n8k16` | PTX ISA version 6.3 |
| `wmma` | Dense | Sub-byte integer - `.u4`/`.s4` | `.m8n8k32` | PTX ISA version 6.3 (preview feature) |
| `wmma` | Dense | Single-bit - `.b1` | `.m8n8k128` | PTX ISA version 6.3 (preview feature) |
| `mma` | NA | Dense | Floating-point - `.f64` | `.m8n8k4` | PTX ISA version 7.0 |
| `.m16n8k4`, `.m16n8k8`, and `.m16n8k16` | PTX ISA version 7.8 |
| `mma` | Dense | Floating-point - `.f16` | `.m8n8k4` | PTX ISA version 6.4 |
| `.m16n8k8` | PTX ISA version 6.5 |
| `.m16n8k16` | PTX ISA version 7.0 |
| `mma` | Dense | Alternate floating-point format - `.bf16` | `.m16n8k8` and `.m16n8k16` | PTX ISA version 7.0 |
| `mma` | Dense | Alternate floating-point format - `.tf32` | `.m16n8k4` and `.m16n8k8` | PTX ISA version 7.0 |
| `mma` | Dense | Integer - `.u8`/`.s8` | `.m8n8k16` | PTX ISA version 6.5 |
| `.m16n8k16` and `.m16n8k32` | PTX ISA version 7.0 |
| `mma` | Dense | Sub-byte integer - `.u4`/`.s4` | `.m8n8k32` | PTX ISA version 6.5 |
| `.m16n8k32` and `.m16n8k64` | PTX ISA version 7.0 |
| `mma` | Dense | Single-bit - `.b1` | `.m8n8k128`, `.m16n8k128`, and `.m16n8k256` | PTX ISA version 7.0 |
| `mma` | Dense | Alternate floating-point format - `.e4m3` / `.e5m2` | `.m16n8k32` | PTX ISA version 8.4 |
| `mma` | Dense | Alternate floating-point format - `.e4m3` / `.e5m2` | `.m16n8k16` | PTX ISA version 8.7 |
| `mma` | Dense | Alternate floating-point format - `.e3m2` / `.e2m3`/`.e2m1` | `.m16n8k32` | PTX ISA version 8.7 |
| `mma` | Yes | Dense | Alternate floating-point format - `.e4m3` / `.e5m2`/`.e3m2`/`.e2m3`/`.e2m1` X (Scale) `.ue8m0` | `.m16n8k32` | PTX ISA version 8.7 |
| `mma` | Dense | Alternate floating-point format - `.e2m1` X (Scale) `.ue8m0`/`.ue4m3` | `.m16n8k64` | PTX ISA version 8.7 |
| `mma` | NA | Sparse | Floating-point - `.f16` | `.m16n8k16` and `.m16n8k32` | PTX ISA version 7.1 |
| `mma` | Sparse | Alternate floating-point format - `.bf16` | `.m16n8k16` and `.m16n8k32` | PTX ISA version 7.1 |
| `mma` | Sparse | Alternate floating-point format - `.tf32` | `.m16n8k8` and `.m16n8k16` | PTX ISA version 7.1 |
| `mma` | Sparse | Integer - `.u8`/`.s8` | `.m16n8k32` and `.m16n8k64` | PTX ISA version 7.1 |
| `mma` | Sparse | Sub-byte integer - `.u4`/`.s4` | `.m16n8k64` and `.m16n8k128` | PTX ISA version 7.1 |
| `mma` | Sparse | Alternate floating-point format - `.e4m3` / `.e5m2` | `.m16n8k64` | PTX ISA version 8.4 |
| `mma` | Sparse with ordered metadata | Floating-point - `.f16` | `.m16n8k16` and `.m16n8k32` | PTX ISA version 8.5 |
| `mma` | Sparse with ordered metadata | Alternate floating-point format - `.bf16` | `.m16n8k16` and `.m16n8k32` | PTX ISA version 8.5 |
| `mma` | Sparse with ordered metadata | Alternate floating-point format - `.tf32` | `.m16n8k8` and `.m16n8k16` | PTX ISA version 8.5 |
| `mma` | Sparse with ordered metadata | Integer - `.u8`/`.s8` | `.m16n8k32` and `.m16n8k64` | PTX ISA version 8.5 |
| `mma` | Sparse with ordered metadata | Sub-byte integer - `.u4`/`.s4` | `.m16n8k64` and `.m16n8k128` | PTX ISA version 8.5 |
| `mma` | Sparse with ordered metadata | Alternate floating-point format - `.e4m3` / `.e5m2` | `.m16n8k64` | PTX ISA version 8.5 |
| `mma` | Sparse with ordered metadata | Alternate floating-point format - `.e3m2` / `.e2m3`/`.e2m1` | `.m16n8k64` | PTX ISA version 8.7 |
| `mma` | Yes | Sparse with ordered metadata | Alternate floating-point format - `.e4m3` / `.e5m2`/`.e3m2`/`.e2m3`/`.e2m1` X (Scale) `.ue8m0` | `.m16n8k64` | PTX ISA version 8.7 |
| `mma` | Sparse with ordered metadata | Alternate floating-point format - `.e2m1` X (Scale) `.ue8m0`/`.ue4m3` | `.m16n8k128` | PTX ISA version 8.7 |

#### 9.7.14.2. [Matrix Data-types](#warp-level-matrix-data-types)[](#warp-level-matrix-data-types "Permalink to this headline")

The matrix multiply and accumulate operation is supported separately on integer, floating-point,
sub-byte integer and single bit data-types. All operands must contain the same basic type kind,
i.e., integer or floating-point.

For floating-point matrix multiply and accumulate operation, different matrix operands may have
different precision, as described later.

| Data-type | Multiplicands (A or B) | Accumulators (C or D) |
| --- | --- | --- |
| Integer | `.u8`, `.s8` | `.s32` |
| Floating Point | `.f16` | `.f16`, `.f32` |
| Alternate floating Point | `.bf16` | `.f32` |
| Alternate floating Point | `.tf32` | `.f32` |
| Alternate floating Point | `.e4m3` or `.e5m2` or `.e3m2` or `.e2m3` or `.e2m1` | `.f16`, `.f32` |
| Alternate floating Point with scale | `.e4m3` or `.e5m2` or `.e3m2` or `.e2m3` or `.e2m1` X (Scale) `.ue8m0` | `.f32` |
| Alternate floating Point with scale | `.e2m1` X (Scale) `.ue8m0` or `.ue4m3` | `.f32` |
| Floating Point | `.f64` | `.f64` |
| Sub-byte integer | both `.u4` or both `.s4` | `.s32` |
| Single-bit integer | `.b1` | `.s32` |

#### 9.7.14.3. [Block Scaling](#warp-level-block-scaling)[](#warp-level-block-scaling "Permalink to this headline")

The `mma` instruction with the following `.kind` qualifier:

* `.kind::mxf8f6f4`
* `.kind::mxf4`
* `.kind::mxf4nvf4`

perform matrix multiplication with block scaling. This operation has the following form:
`D = (A * scale_A) * (B * scale_B) + C`.

For a `scale_A` matrix of shape *M x SFA\_N*, each row of matrix `A` is divided into
*SFA\_N* number of chunks and each chunk of a row is multiplied with the corresponding
element (henceforth referred as *SF\_A*) from the same row of `scale_A`.

Similarly, for a `scale_B` matrix of shape *SFB\_M x N*, each column of matrix `B` is
divided into the *SFB\_M* number of chunks and each chunk of a column is multiplied with
the corresponding element (henceforth referred as *SF\_B*) from the same column of `scale_B`.

[Figure 42](#mma-block-scaling) shows an example of `mma` with block scaling of `scale_vec::2X`.

![_images/mma-block-scaling.png](_images/mma-block-scaling.png)


Figure 42 `mma` with block scaling of `.scale_vec::2X`[](#mma-block-scaling "Permalink to this image")

The shapes for `scale_A` and `scale_B` matrices depend upon the qualifier `.scale_vec_size`
as shown in [Table 35](#mma-scale-vec-matrix-shape).

Table 35 Shapes for scale matrices depending upon `.scale_vec_size` qualifier[](#mma-scale-vec-matrix-shape "Permalink to this table")





| .scale\_vec\_size | Shape of scale\_A | Shape of scale\_B |
| --- | --- | --- |
| `.scale_vec::1X` | M x 1 | 1 x N |
| `.scale_vec::2X` | M x 2 | 2 x N |
| `.scale_vec::4X` | M x 4 | 4 x N |

The valid combination of the exact element types and the `.scale_vec_size` are listed in
[Table 36](#mma-scaling-kind-type-valid-combination).

Table 36 Valid combinations of `.scale_vec_size` and `.kind` qualifier[](#mma-scaling-kind-type-valid-combination "Permalink to this table")






| .kind::\* | Element Data Type .atype and .btype | Scale Data Type .stype | .scale\_vec\_size |
| --- | --- | --- | --- |
| `.kind::mxf8f6f4` | `.e4m3`, `.e5m2` `.e3m2`, `.e2m3` `.e2m1` | `.ue8m0` | `.scale_vec::1X` |
| `.kind::mxf4` | `.e2m1` | `.ue8m0` | `.scale_vec::2X` |
| `.kind::mxf4nvf4` | `.e2m1` | `.ue8m0` | `.scale_vec::2X` |
| `.e2m1` | `.ue4m3` | `.scale_vec::4X` |

The `scale-a-data` and `scale-b-data` argument provides metadata for `scale_A` and
`scale_B` matrices respectively. The tuple `{byte-id-a, thread-id-a}` and
`{byte-id-b, thread-id-b}` provides the selector information to choose elements
*SF\_A* and *SF\_B* from corresponding metadata arguments `scale-a-data` and
`scale-b-data`.
The tuple `{byte-id-a, thread-id-a}` allows to select the scale matrix element *SF\_A*
from `scale-a-data`. Similarly, the tuple `{byte-id-b, thread-id-b}` allows to select
the scale matrix element *SF\_B* from `scale-b-data`.

The components `thread-id-a`, `thread-id-b` decides which threads among the quad
contribute the *SF\_A* and *SF\_B* values. The following listing describes the impact
of thread selector component `thread-id-a`, `thread-id-b`:

* One thread-pair within the quad determined by `thread-id-a`, contributes the *SF\_A*
  values. The value of 0 selects lower two threads whereas value of 1 selects upper two
  threads from the quad. In other words, when `thread-id-a` set to 0, thread-pair
  satisfying: `%laneid` % 4 == 0 or 1 provides the *SF\_A*. In contrast when
  `thread-id-a` set to 1, thread-pair satisfying: `%laneid` % 4 == 2 or 3 provides
  the *SF\_A*. Refer [Figure 43](#mma-scaling-thread-id-a-selection) for more details.

  ![_images/mma-scaling-thread-id-a-selection.png](_images/mma-scaling-thread-id-a-selection.png)


  Figure 43 Selection of set of values for *SF\_A* based on `thread-id-a`[](#mma-scaling-thread-id-a-selection "Permalink to this image")
* One thread within the quad, determined by `thread-id-b`, contributes the *SF\_B*
  value. In other words, each thread satisfying: `%laneid` % 4 == `thread-id-b`
  provides the *SF\_B*. Refer [Figure 44](#mma-scaling-thread-id-b-selection) for more details.

  ![_images/mma-scaling-thread-id-b-selection.png](_images/mma-scaling-thread-id-b-selection.png)


  Figure 44 Selection of set of values for *SF\_B* based on `thread-id-b`[](#mma-scaling-thread-id-b-selection "Permalink to this image")

The arguments `byte-id-a`, `byte-id-b` selects which bytes from the `scale-a-data`,
`scale-b-data` contribute the *SF\_A* and *SF\_B* values. The following listing describes
implications of `.scale_vec_size` qualifier on byte selector component `byte-id-a`,
`byte-id-b`:

* When `.scale_vec_size` is `.scale_vec::1X`

  + One byte each within `scale-a-data` and `scale-b-data` determined by `byte-id-a`,
    `byte-id-b` respectively contributes the *SF\_A* and *SF\_B* values.
* When `.scale_vec_size` is `.scale_vec::2X`

  + One byte-pair (two bytes) within `scale-a-data` and `scale-b-data` determined by
    `byte-id-a` and `byte-id-b` contributes the *SF\_A* and *SF\_B* values. The value
    of 0 selects lower two bytes whereas value of 2 selects upper two bytes from the
    corresponding metadata value.
* When `.scale_vec_size` is `.scale_vec::4X`

  + All four bytes within `scale-a-data` and `scale-b-data` contribute the values.
    Hence, `byte-id-a`, `byte-id-b` must be zero.

Refer [Figure 45](#mma-scaling-byte-id-selection) for more details.

![_images/mma-scaling-byte-id-selection.png](_images/mma-scaling-byte-id-selection.png)


Figure 45 Selection of set of values for *SF\_A* or *SF\_B* based on `byte-id-a` or `byte-id-b`[](#mma-scaling-byte-id-selection "Permalink to this image")

[Table 37](#mma-scaling-valid-values-of-selector-components) enumerates the valid values for
various selector components. Any other value results in an undefined behavior.

Table 37 Valid values for various selector components[](#mma-scaling-valid-values-of-selector-components "Permalink to this table")







| .scale\_vec\_size | Selector Components | | | |
| --- | --- | --- | --- | --- |
| byte-id-a | thread-id-a | byte-id-b | thread-id-b |
| `scale_vec::1X` | [0, 1, 2, 3] | [0, 1] | [0, 1, 2, 3] | [0, 1, 2, 3] |
| `scale_vec::2X` | [0, 2] | [0, 2] |
| `scale_vec::4X` | 0 | 0 |

#### 9.7.14.4. [Matrix multiply-accumulate operation using `wmma` instructions](#warp-level-matrix-instructions-wmma)[](#warp-level-matrix-instructions-wmma "Permalink to this headline")

This section describes warp level `wmma.load, wmma.mma` and `wmma.store` instructions and the
organization of various matrices invovled in these instruction.

##### 9.7.14.4.1. [Matrix Fragments for WMMA](#warp-level-matrix-fragment)[](#warp-level-matrix-fragment "Permalink to this headline")

Each thread in the warp holds a fragment of the matrix. The distribution of fragments loaded by the
threads in a warp is unspecified and is target architecture dependent, and hence the identity of the
fragment within the matrix is also unspecified and is target architecture dependent. The fragment
returned by a `wmma` operation can be used as an operand for another `wmma` operation if the
shape, layout and element type of the underlying matrix matches. Since fragment layout is
architecture dependent, using the fragment returned by a `wmma` operation in one function as an
operand for a `wmma` operation in a different function may not work as expected if the two
functions are linked together but were compiled for different link-compatible SM architectures. Note
passing `wmma` fragment to a function having `.weak` linkage is unsafe since at link time
references to such function may get resolved to a function in different compilation module.

Each fragment is a vector expression whose contents are determined as follows. The identity of
individual matrix elements in the fragment is unspecified.

Integer fragments

Multiplicands (A or B):

| Data-type | Shape | Matrix | Fragment |
| --- | --- | --- | --- |
| `.u8` or `.s8` | `.m16n16k16` | A | A vector expression of two `.b32` registers, with each register containing four elements from the matrix. |
| B | A vector expression of two `.b32` registers, with each register containing four elements from the matrix. |
|  | `.m8n32k16` | A | A vector expression containing a single `.b32` register containing four elements from the matrix. |
| B | A vector expression of four `.b32` registers, with each register containing four elements from the matrix. |
|  | `.m32n8k16` | A | A vector expression of four `.b32` registers, with each register containing four elements from the matrix. |
| B | A vector expression containing single `.b32` register, with each containing four elements from the matrix. |

Accumulators (C or D):

| Data-type | Shape | Fragment |
| --- | --- | --- |
| `.s32` | `.m16n16k16` | A vector expression of eight `.s32` registers. |
| `.m8n32k16` |
| `.m32n8k16` |

Floating point fragments

| Data-type | Matrix | Fragment |
| --- | --- | --- |
| `.f16` | A or B | A vector expression of eight `.f16x2` registers. |
| `.f16` | C or D | A vector expression of four `.f16x2` registers. |
| `.f32` | A vector expression of eight `.f32` registers. |

Floating point fragments for `.bf16` data format

Multiplicands (A or B):

| Data-type | Shape | Matrix | Fragment |
| --- | --- | --- | --- |
| `.bf16` | `.m16n16k16` | A | A vector expression of four `.b32` registers, with each register containing two elements from the matrix. |
| B |
| `.m8n32k16` | A | A vector expression containing a two `.b32` registers, with containing two elements from the matrix. |
| B | A vector expression of eight `.b32` registers, with each register containing two elements from the matrix. |
| `.m32n8k16` | A | A vector expression of eight `.b32` registers, with each register containing two elements from the matrix. |
| B | A vector expression containing two `.b32` registers, with each containing two elements from the matrix. |

Accumulators (C or D):

| Data-type | Matrix | Fragment |
| --- | --- | --- |
| `.f32` | C or D | A vector expression containing eight `.f32` registers. |

Floating point fragments for `.tf32` data format

Multiplicands (A or B):

| Data-type | Shape | Matrix | Fragment |
| --- | --- | --- | --- |
| `.tf32` | `.m16n16k8` | A | A vector expression of four `.b32` registers. |
| B | A vector expression of four `.b32` registers. |

Accumulators (C or D):

| Data-type | Shape | Matrix | Fragment |
| --- | --- | --- | --- |
| `.f32` | `.m16n16k8` | C or D | A vector expression containing eight `.f32` registers. |

Double precision floating point fragments

Multiplicands (A or B):

| Data-type | Shape | Matrix | Fragment |
| --- | --- | --- | --- |
| `.f64` | `.m8n8k4` | A or B | A vector expression of single `.f64` register. |

Accumulators (C or D):

| Data-type | Shape | Matrix | Fragment |
| --- | --- | --- | --- |
| `.f64` | `.m8n8k4` | C or D | A vector expression containing single `.f64` register. |

Sub-byte integer and single-bit fragments

Multiplicands (A or B):

| Data-type | Shape | Fragment |
| --- | --- | --- |
| `.u4` or `.s4` | `.m8n8k32` | A vector expression containing a single `.b32` register, containing eight elements from the matrix. |
| `.b1` | `.m8n8k128` | A vector expression containing a single `.b32` register, containing 32 elements from the matrix. |

Accumulators (C or D):

| Data-type | Shape | Fragment |
| --- | --- | --- |
| `.s32` | `.m8n8k32` | A vector expression of two `.s32` registers. |
| `.m8n8k128` | A vector expression of two `.s32` registers. |

Manipulating fragment contents

The contents of a matrix fragment can be manipulated by reading and writing to individual
registers in the fragment, provided the following conditions are satisfied:

* All matrix element in the fragment are operated on uniformly across threads, using the same
  parameters.
* The order of the matrix elements is not changed.

For example, if each register corresponding to a given matrix is multiplied by a uniform constant
value, then the resulting matrix is simply the scaled version of the original matrix.

Note that type conversion between `.f16` and `.f32` accumulator fragments is not supported in
either direction. The result is undefined even if the order of elements in the fragment remains
unchanged.

##### 9.7.14.4.2. [Matrix Storage for WMMA](#warp-level-matrix-storage)[](#warp-level-matrix-storage "Permalink to this headline")

Each matrix can be stored in memory with a *row-major* or *column-major* layout. In a *row-major*
format, consecutive elements of each row are stored in contiguous memory locations, and the row is
called the *leading dimension* of the matrix. In a *column-major* format, consecutive elements of
each column are stored in contiguous memory locations and the column is called the *leading
dimension* of the matrix.

Consecutive instances of the *leading dimension* (rows or columns) need not be stored contiguously
in memory. The `wmma.load` and `wmma.store` operations accept an optional argument `stride`
that specifies the offset from the beginning of each row (or column) to the next, in terms of matrix
elements (and not bytes). For example, the matrix being accessed by a `wmma` operation may be a
submatrix from a larger matrix stored in memory. This allows the programmer to compose a
multiply-and-accumulate operation on matrices that are larger than the shapes supported by the
`wmma` operation.

Address Alignment

The starting address of each instance of the leading dimension (row or column) must be aligned
with the size of the corresponding fragment in bytes. Note that the starting address is
determined by the base pointer and the optional `stride`.

Consider the following instruction as an example:

```
wmma.load.a.sync.aligned.row.m16n16k16.f16 {x0,...,x7}, [p], s;
```

* Fragment size in bytes = 32 (eight elements of type `.f16x2`)
* Actual `stride` in bytes = 2 \* `s` (since `stride` is specified in terms of `.f16`
  elements, not bytes)
* For each row of this matrix to be aligned at fragment size the following must be true:

  1. `p` is a multiple of 32.
  2. `2*s` is a multiple of 32.

Default value for stride

The default value of the `stride` is the size of the *leading dimension* of the matrix. For
example, for an `MxK` matrix, the `stride` is `K` for a *row-major* layout and `M` for a
*column-major* layout. In particular, the default strides for the supported matrix shapes are as
follows:

| Shape | A (row) | A (column) | B (row) | B (column) | Accumulator (row) | Accumulator (column) |
| --- | --- | --- | --- | --- | --- | --- |
| 16x16x16 | 16 | 16 | 16 | 16 | 16 | 16 |
| 8x32x16 | 16 | 8 | 32 | 16 | 32 | 8 |
| 32x8x16 | 16 | 32 | 8 | 16 | 8 | 32 |
| 8x8x32 | 32 | 8 | 8 | 32 | 8 | 8 |
| 8x8x128 | 128 | 8 | 8 | 128 | 8 | 8 |
| 16x16x8 | 8 | 16 | 16 | 8 | 16 | 16 |
| 8x8x4 | 4 | 8 | 8 | 4 | 8 | 8 |

##### 9.7.14.4.3. [Warp-level Matrix Load Instruction: `wmma.load`](#warp-level-matrix-instructions-wmma-ld)[](#warp-level-matrix-instructions-wmma-ld "Permalink to this headline")

`wmma.load`

Collectively load a matrix from memory for WMMA

Syntax

Floating point format `.f16` loads:

```
wmma.load.a.sync.aligned.layout.shape{.ss}.atype r, [p] {, stride};

wmma.load.b.sync.aligned.layout.shape{.ss}.btype r, [p] {, stride};

wmma.load.c.sync.aligned.layout.shape{.ss}.ctype r, [p] {, stride};



.layout = {.row, .col};

.shape  = {.m16n16k16, .m8n32k16, .m32n8k16};

.ss     = {.global, .shared{::cta}};

.atype  = {.f16, .s8, .u8};

.btype  = {.f16, .s8, .u8};

.ctype  = {.f16, .f32, .s32};
```

Alternate floating point format `.bf16` loads:

```
wmma.load.a.sync.aligned.layout.shape{.ss}.atype r, [p] {, stride}

wmma.load.b.sync.aligned.layout.shape{.ss}.btype r, [p] {, stride}

wmma.load.c.sync.aligned.layout.shape{.ss}.ctype r, [p] {, stride}

.layout = {.row, .col};

.shape  = {.m16n16k16, .m8n32k16, .m32n8k16};

.ss     = {.global, .shared{::cta}};

.atype  = {.bf16 };

.btype  = {.bf16 };

.ctype  = {.f32 };
```

Alternate floating point format `.tf32` loads:

```
wmma.load.a.sync.aligned.layout.shape{.ss}.atype r, [p] {, stride}

wmma.load.b.sync.aligned.layout.shape{.ss}.btype r, [p] {, stride}

wmma.load.c.sync.aligned.layout.shape{.ss}.ctype r, [p] {, stride}

.layout = {.row, .col};

.shape  = {.m16n16k8 };

.ss     = {.global, .shared{::cta}};

.atype  = {.tf32 };

.btype  = {.tf32 };

.ctype  = {.f32 };
```

Double precision Floating point `.f64` loads:

```
wmma.load.a.sync.aligned.layout.shape{.ss}.atype r, [p] {, stride}

wmma.load.b.sync.aligned.layout.shape{.ss}.btype r, [p] {, stride}

wmma.load.c.sync.aligned.layout.shape{.ss}.ctype r, [p] {, stride}

.layout = {.row, .col};

.shape  = {.m8n8k4 };

.ss     = {.global, .shared{::cta}};

.atype  = {.f64 };

.btype  = {.f64 };

.ctype  = {.f64 };
```

Sub-byte loads:

```
wmma.load.a.sync.aligned.row.shape{.ss}.atype r, [p] {, stride}

wmma.load.b.sync.aligned.col.shape{.ss}.btype r, [p] {, stride}

wmma.load.c.sync.aligned.layout.shape{.ss}.ctype r, [p] {, stride}

.layout = {.row, .col};

.shape  = {.m8n8k32};

.ss     = {.global, .shared{::cta}};

.atype  = {.s4, .u4};

.btype  = {.s4, .u4};

.ctype  = {.s32};
```

Single-bit loads:

```
wmma.load.a.sync.aligned.row.shape{.ss}.atype r, [p] {, stride}

wmma.load.b.sync.aligned.col.shape{.ss}.btype r, [p] {, stride}

wmma.load.c.sync.aligned.layout.shape{.ss}.ctype r, [p] {, stride}

.layout = {.row, .col};

.shape  = {.m8n8k128};

.ss     = {.global, .shared{::cta}};

.atype  = {.b1};

.btype  = {.b1};

.ctype  = {.s32};
```

Description

Collectively load a matrix across all threads in a warp from the location indicated by address
operand `p` in the specified state space into destination register `r`.

If no state space is given, perform the memory accesses using
[Generic Addressing](#generic-addressing). `wmma.load` operation may be used only with `.global` and
`.shared` spaces and with generic addressing, where the address points to `.global` or
`.shared` space.

The mutually exclusive qualifiers `.a`, `.b` and `.c` indicate whether matrix A, B or C is
being loaded respectively for the `wmma` computation.

The destination operand `r` is a brace-enclosed vector expression that can hold the fragment
returned by the load operation, as described in [Matrix Fragments for WMMA](#warp-level-matrix-fragment).

The `.shape` qualifier indicates the dimensions of all the matrix arguments involved in the
intended `wmma` computation.

The `.layout` qualifier indicates whether the matrix to be loaded is stored in *row-major* or
*column-major* format.

`stride` is an optional 32-bit integer operand that provides an offset in terms of matrix elements
between the start of consecutive instances of the *leading dimension* (rows or columns). The default
value of `stride` is described in
[Matrix Storage for WMMA](#warp-level-matrix-storage) and must be specified if the actual value is larger than
the default. For example, if the matrix is a sub-matrix of a larger matrix, then the value of stride
is the leading dimension of the larger matrix. Specifying a value lower than the default value
results in undefined behavior.

The required alignment for address `p` and `stride` is described in the
[Matrix Storage for WMMA](#warp-level-matrix-storage).

The mandatory `.sync` qualifier indicates that `wmma.load` causes the executing thread to wait
until all threads in the warp execute the same `wmma.load` instruction before resuming execution.

The mandatory `.aligned` qualifier indicates that all threads in the warp must execute the same
`wmma.load` instruction. In conditionally executed code, a `wmma.load` instruction should only
be used if it is known that all threads in the warp evaluate the condition identically, otherwise
behavior is undefined.

The behavior of `wmma.load` is undefined if all threads do not use the same qualifiers and the
same values of `p` and `stride`, or if any thread in the warp has exited.

`wmma.load` is treated as a *weak* memory operation in the [Memory Consistency Model](#memory-consistency-model).

PTX ISA Notes

Introduced in PTX ISA version 6.0.

`.m8n32k16` and `.m32n8k16` introduced in PTX ISA version 6.1.

Integer, sub-byte integer and single-bit `wmma` introduced in PTX ISA version 6.3.

`.m8n8k4` and `.m16n16k8` on `wmma` introduced in PTX ISA version 7.0.

Double precision and alternate floating point precision `wmma` introduced in PTX ISA version 7.0.

Modifier `.aligned` is required from PTX ISA version 6.3 onwards, and considered implicit in PTX
ISA versions less than 6.3.

Support for `::cta` sub-qualifier introduced in PTX ISA version 7.8.

Preview Feature:
:   Sub-byte `wmma` and single-bit `wmma` are preview features in PTX ISA version 6.3. All
    details are subject to change with no guarantees of backward compatibility on future PTX ISA
    versions or SM architectures.

Target ISA Notes

Floating point `wmma` requires `sm_70` or higher.

Integer `wmma` requires `sm_72` or higher.

Sub-byte and single-bit `wmma` requires `sm_75` or higher.

Double precision and alternate floating point precision `wmma` requires `sm_80` or higher.

Examples

```
// Load elements from f16 row-major matrix B

.reg .b32 x<8>;



wmma.load.b.sync.aligned.m16n16k16.row.f16 {x0,x1,x2,x3,x4,x5,x,x7}, [ptr];

// Now use {x0, ..., x7} for the actual wmma.mma



// Load elements from f32 column-major matrix C and scale the values:

.reg .b32 x<8>;



wmma.load.c.sync.aligned.m16n16k16.col.f32

                 {x0,x1,x2,x3,x4,x5,x6,x7}, [ptr];



mul.f32 x0, x0, 0.1;

// repeat for all registers x<8>;

...

mul.f32 x7, x7, 0.1;

// Now use {x0, ..., x7} for the actual wmma.mma



// Load elements from integer matrix A:

.reg .b32 x<4>

// destination registers x<4> contain four packed .u8 values each

wmma.load.a.sync.aligned.m32n8k16.row.u8 {x0,x1,x2,x3}, [ptr];



// Load elements from sub-byte integer matrix A:

.reg .b32 x0;

// destination register x0 contains eight packed .s4 values

wmma.load.a.sync.aligned.m8n8k32.row.s4 {x0}, [ptr];



// Load elements from .bf16 matrix A:

.reg .b32 x<4>;

wmma.load.a.sync.aligned.m16n16k16.row.bf16

                {x0,x1,x2,x3}, [ptr];



// Load elements from .tf32 matrix A:

.reg .b32 x<4>;

wmma.load.a.sync.aligned.m16n16k8.row.tf32

                {x0,x1,x2,x3}, [ptr];



// Load elements from .f64 matrix A:

.reg .b32 x<4>;

wmma.load.a.sync.aligned.m8n8k4.row.f64

                {x0}, [ptr];
```

##### 9.7.14.4.4. [Warp-level Matrix Store Instruction: `wmma.store`](#warp-level-matrix-instructions-wmma-st)[](#warp-level-matrix-instructions-wmma-st "Permalink to this headline")

`wmma.store`

Collectively store a matrix into memory for WMMA

Syntax

```
wmma.store.d.sync.aligned.layout.shape{.ss}.type [p], r {, stride};



.layout = {.row, .col};

.shape  = {.m16n16k16, .m8n32k16, .m32n8k16};

.ss     = {.global, .shared{::cta}};

.type   = {.f16, .f32, .s32};



wmma.store.d.sync.aligned.layout.shape{.ss}.type [p], r {, stride}

.layout = {.row, .col};

.shape  = {.m8n8k32, .m8n8k128};

.ss     = {.global, .shared{::cta}};

.type   = {.s32};



wmma.store.d.sync.aligned.layout.shape{.ss}.type [p], r {, stride}

.layout = {.row, .col};

.shape  = {.m16n16k8};

.ss     = {.global, .shared{::cta}};

.type   = {.f32};



wmma.store.d.sync.aligned.layout.shape{.ss}.type [p], r {, stride}

.layout = {.row, .col};

.shape  = {.m8n8k4 };

.ss     = {.global, .shared{::cta}};

.type   = {.f64};
```

Description

Collectively store a matrix across all threads in a warp at the location indicated by address
operand `p` in the specified state space from source register `r`.

If no state space is given, perform the memory accesses using
[Generic Addressing](#generic-addressing). `wmma.load` operation may be used only with `.global` and
`.shared` spaces and with generic addressing, where the address points to `.global` or
`.shared` space.

The source operand `r` is a brace-enclosed vector expression that matches the shape of the
fragment expected by the store operation, as described in [Matrix Fragments for WMMA](#warp-level-matrix-fragment).

The `.shape` qualifier indicates the dimensions of all the matrix arguments involved in the
intended `wmma` computation. It must match the `.shape` qualifier specified on the `wmma.mma`
instruction that produced the D matrix being stored.

The `.layout` qualifier indicates whether the matrix to be loaded is stored in *row-major* or
*column-major* format.

`stride` is an optional 32-bit integer operand that provides an offset in terms of matrix elements
between the start of consecutive instances of the *leading dimension* (rows or columns). The default
value of `stride` is described in
[Matrix Storage for WMMA](#warp-level-matrix-storage) and must be specified if the actual value is larger than
the default. For example, if the matrix is a sub-matrix of a larger matrix, then the value of stride
is the leading dimension of the larger matrix. Specifying a value lower than the default value
results in undefined behavior.

The required alignment for address `p` and `stride` is described in the
[Matrix Storage for WMMA](#warp-level-matrix-storage).

The mandatory `.sync` qualifier indicates that `wmma.store` causes the executing thread to wait
until all threads in the warp execute the same `wmma.store` instruction before resuming execution.

The mandatory `.aligned` qualifier indicates that all threads in the warp must execute the same
`wmma.store` instruction. In conditionally executed code, a `wmma.store` instruction should only
be used if it is known that all threads in the warp evaluate the condition identically, otherwise
behavior is undefined.

The behavior of `wmma.store` is undefined if all threads do not use the same qualifiers and the
same values of `p` and `stride`, or if any thread in the warp has exited.

`wmma.store` is treated as a *weak* memory operation in the [Memory Consistency Model](#memory-consistency-model).

PTX ISA Notes

Introduced in PTX ISA version 6.0.

`.m8n32k16` and `.m32n8k16` introduced in PTX ISA version 6.1.

Integer, sub-byte integer and single-bit `wmma` introduced in PTX ISA version 6.3.

`.m16n16k8` introduced in PTX ISA version 7.0.

Double precision `wmma` introduced in PTX ISA version 7.0.

Modifier `.aligned` is required from PTX ISA version 6.3 onwards, and considered implicit in PTX
ISA versions less than 6.3.

Support for `::cta` sub-qualifier introduced in PTX ISA version 7.8.

Preview Feature:
:   Sub-byte `wmma` and single-bit `wmma` are preview features in PTX ISA version 6.3. All
    details are subject to change with no guarantees of backward compatibility on future PTX ISA
    versions or SM architectures.

Target ISA Notes

Floating point `wmma` requires `sm_70` or higher.

Integer `wmma` requires `sm_72` or higher.

Sub-byte and single-bit `wmma` requires `sm_75` or higher.

Double precision `wmma` and shape `.m16n16k8` requires `sm_80` or higher.

Examples

```
// Storing f32 elements computed by a wmma.mma

.reg .b32 x<8>;



wmma.mma.sync.m16n16k16.row.col.f32.f32

              {d0, d1, d2, d3, d4, d5, d6, d7}, ...;

wmma.store.d.sync.m16n16k16.row.f32

              [ptr], {d0, d1, d2, d3, d4, d5, d6, d7};



// Store s32 accumulator for m16n16k16 shape:

.reg .b32 d<8>;

wmma.store.d.sync.aligned.m16n16k16.row.s32

              [ptr], {d0, d1, d2, d3, d4, d5, d6, d7};



// Store s32 accumulator for m8n8k128 shape:

.reg .b32 d<2>

wmma.store.d.sync.aligned.m8n8k128.row.s32

[ptr], {d0, d1};



// Store f64 accumulator for m8n8k4 shape:

.reg .f64 d<2>;

wmma.store.d.sync.aligned.m8n8k4.row.f64

              [ptr], {d0, d1};
```

##### 9.7.14.4.5. [Warp-level Matrix Multiply-and-Accumulate Instruction: `wmma.mma`](#warp-level-matrix-instructions-wmma-mma)[](#warp-level-matrix-instructions-wmma-mma "Permalink to this headline")

`wmma.mma`

Perform a single matrix multiply-and-accumulate operation across a warp

Syntax

```
// Floating point (.f16 multiplicands) wmma.mma

wmma.mma.sync.aligned.alayout.blayout.shape.dtype.ctype d, a, b, c;



// Integer (.u8/.s8 multiplicands) wmma.mma

wmma.mma.sync.aligned.alayout.blayout.shape.s32.atype.btype.s32{.satfinite} d, a, b, c;



.alayout = {.row, .col};

.blayout = {.row, .col};

.shape  =  {.m16n16k16, .m8n32k16, .m32n8k16};

.dtype   = {.f16, .f32};

.atype   = {.s8, .u8};

.btype   = {.s8, .u8};

.ctype   = {.f16, .f32};
```

Floating point format `.bf16` `wmma.mma`:

```
wmma.mma.sync.aligned.alayout.blayout.shape.f32.atype.btype.f32 d, a, b, c;

.alayout = {.row, .col};

.blayout = {.row, .col};

.shape   = {.m16n16k16, .m8n32k16, .m32n8k16};

.atype   = {.bf16 };

.btype   = {.bf16};
```

Floating point format `.tf32` `wmma.mma`:

```
wmma.mma.sync.aligned.alayout.blayout.shape.f32.atype.btype.f32 d, a, b, c;

.alayout = {.row, .col};

.blayout = {.row, .col};

.shape   = {.m16n16k8 };

.atype   = {.tf32 };

.btype   = {.tf32};
```

Floating point Double precision `wmma.mma`:

```
wmma.mma.sync.aligned.alayout.blayout.shape{.rnd}.f64.f64.f64.f64 d, a, b, c;

.alayout = {.row, .col};

.blayout = {.row, .col};

.shape   = {.m8n8k4 };

.rnd = { .rn, .rz, .rm, .rp };
```

Sub-byte (`.u4`/`.s4` multiplicands) `wmma.mma`:

```
wmma.mma.sync.aligned.row.col.shape.s32.atype.btype.s32{.satfinite} d, a, b, c;

.shape  = {.m8n8k32};

.atype  = {.s4, .u4};

.btype  = {.s4, .u4};
```

Single-bit (`.b1` multiplicands) `wmma.mma`:

```
wmma.mma.op.popc.sync.aligned.row.col.shape.s32.atype.btype.s32 d, a, b, c;

.shape  = {.m8n8k128};

.atype  = {.b1};

.btype  = {.b1};

.op     = {.xor, .and}
```

Description

Perform a warp-level matrix multiply-and-accumulate computation `D = A * B + C` using matrices A,
B and C loaded in registers `a`, `b` and `c` respectively, and store the result matrix in
register `d`. The register arguments `a`, `b`, `c` and `d` hold unspecified fragments of
the corresponding matrices as described in [Matrix Fragments for WMMA](#warp-level-matrix-fragment)

The qualifiers `.dtype`, `.atype`, `.btype` and `.ctype` indicate the data-type of the
elements in the matrices D, A, B and C respectively.

For `wmma.mma` without explicit `.atype` and `.btype`: `.atype` and `.btype` are
implicitly set to `.f16`.

For integer `wmma`, `.ctype` and `.dtype` must be specified as `.s32`. Also, the values for
`.atype` and `.btype` must be the same, i.e., either both are `.s8` or both are `.u8`.

For sub-byte single-bit `wmma`, `.ctype` and `.dtype` must be specified as `.s32`. Also, the
values for `.atype` and `.btype` must be the same; i.e., either both are `.s4`, both are
`.u4`, or both are `.b1`.

For single-bit `wmma`, multiplication is replaced by a sequence of logical operations;
specifically, `wmma.xor.popc` and `wmma.and.popc` computes the XOR, AND respectively of a
128-bit row of A with a 128-bit column of B, then counts the number of set bits in the result
(`popc`). This result is added to the corresponding element of C and written into D.

The qualifiers `.alayout` and `.blayout` must match the layout specified on the `wmma.load`
instructions that produce the contents of operands `a` and `b` respectively. Similarly, the
qualifiers `.atype`, `.btype` and `.ctype` must match the corresponding qualifiers on the
`wmma.load` instructions that produce the contents of operands `a`, `b` and `c`
respectively.

The `.shape` qualifier must match the `.shape` qualifier used on the `wmma.load` instructions
that produce the contents of all three input operands `a`, `b` and `c` respectively.

The destination operand `d` is a brace-enclosed vector expression that matches the `.shape` of
the fragment computed by the `wmma.mma` instruction.

Saturation at the output:
:   The optional qualifier `.satfinite` indicates that the final values in the destination register
    are saturated as follows:

    * The output is clamped to the minimum or maximum 32-bit signed integer value. Otherwise, if the
      accumulation would overflow, the value wraps.

Precision and rounding for `.f16` floating point operations:
:   Element-wise multiplication of matrix A and B is performed with at least single precision. When
    `.ctype` or `.dtype` is `.f32`, accumulation of the intermediate values is performed with
    at least single precision. When both `.ctype` and `.dtype` are specified as `.f16`, the
    accumulation is performed with at least half precision.

    The accumulation order, rounding and handling of subnormal inputs is unspecified.

Precision and rounding for `.bf16`, `.tf32` floating point operations:
:   Element-wise multiplication of matrix A and B is performed with specified precision. Accumulation
    of the intermediate values is performed with at least single precision.

    The accumulation order, rounding and handling of subnormal inputs is unspecified.

Rounding modifiers on double precision `wmma.mma` (default is `.rn`):

`.rn`
:   mantissa LSB rounds to nearest even

`.rz`
:   mantissa LSB rounds towards zero

`.rm`
:   mantissa LSB rounds towards negative infinity

`.rp`
:   mantissa LSB rounds towards positive infinity

The mandatory `.sync` qualifier indicates that `wmma.mma` causes the executing thread to wait
until all threads in the warp execute the same `wmma.mma` instruction before resuming execution.

The mandatory `.aligned` qualifier indicates that all threads in the warp must execute the same
`wmma.mma` instruction. In conditionally executed code, a `wmma.mma` instruction should only be
used if it is known that all threads in the warp evaluate the condition identically, otherwise
behavior is undefined.

The behavior of `wmma.mma` is undefined if all threads in the same warp do not use the same
qualifiers, or if any thread in the warp has exited.

PTX ISA Notes

Introduced in PTX ISA version 6.0.

`.m8n32k16` and `.m32n8k16` introduced in PTX ISA version 6.1.

Integer, sub-byte integer and single-bit `wmma` introduced in PTX ISA version 6.3.

Double precision and alternate floating point precision `wmma` introduced in PTX ISA version 7.0.

Support for `.and` operation in single-bit `wmma` introduced in PTX ISA version 7.1.

Modifier `.aligned` is required from PTX ISA version 6.3 onwards, and considered implicit in PTX
ISA versions less than 6.3.

Support for `.satfinite` on floating point `wmma.mma` is deprecated in PTX ISA version 6.4 and
is removed from PTX ISA version 6.5.

Preview Feature:
:   Sub-byte `wmma` and single-bit `wmma` are preview features in PTX ISA. All details are
    subject to change with no guarantees of backward compatibility on future PTX ISA versions or SM
    architectures.

Target ISA Notes

Floating point `wmma` requires `sm_70` or higher.

Integer `wmma` requires `sm_72` or higher.

Sub-byte and single-bit `wmma` requires `sm_75` or higher.

Double precision, alternate floating point precision `wmma` require `sm_80` or higher.

`.and` operation in single-bit `wmma` requires `sm_80` or higher.

Examples

```
.global .align 32 .f16 A[256], B[256];

.global .align 32 .f32 C[256], D[256];

.reg .b32 a<8> b<8> c<8> d<8>;



wmma.load.a.sync.aligned.m16n16k16.global.row.f16

        {a0, a1, a2, a3, a4, a5, a6, a7}, [A];

wmma.load.b.sync.aligned.m16n16k16.global.col.f16

        {b0, b1, b2, b3, b4, b5, b6, b7}, [B];



wmma.load.c.sync.aligned.m16n16k16.global.row.f32

        {c0, c1, c2, c3, c4, c5, c6, c7}, [C];



wmma.mma.sync.aligned.m16n16k16.row.col.f32.f32

        {d0, d1, d2, d3, d4, d5, d6, d7},

        {a0, a1, a2, a3, a4, a5, a6, a7},

        {b0, b1, b2, b3, b4, b5, b6, b7},

        {c0, c1, c2, c3, c4, c5, c6, c7};



wmma.store.d.sync.aligned.m16n16k16.global.col.f32

        [D], {d0, d1, d2, d3, d4, d5, d6, d7};



// Compute an integer WMMA:

.reg .b32  a, b<4>;

.reg .b32 c<8>, d<8>;

wmma.mma.sync.aligned.m8n32k16.row.col.s32.s8.s8.s32

        {d0, d1, d2, d3, d4, d5, d6, d7},

        {a}, {b0, b1, b2,  b3},

        {c0, c1, c2, c3, c4, c5, c6, c7};



// Compute sub-byte WMMA:

.reg .b32 a, b, c<2> d<2>

wmma.mma.sync.aligned.m8n8k32.row.col.s32.s4.s4.s32

        {d0, d1}, {a}, {b}, {c0, c1};



// Compute single-bit type WMMA:

.reg .b32 a, b, c<2> d<2>

wmma.mma.xor.popc.sync.aligned.m8n8k128.row.col.s32.b1.b1.s32

        {d0, d1}, {a}, {b}, {c0, c1};



// Compute double precision wmma

.reg .f64 a, b, c<2>, d<2>;

wmma.mma.sync.aligned.m8n8k4.row.col.f64.f64.f64.f64

        {d0, d1}, {a}, {b}, {c0, c1};



// Compute alternate floating point precision wmma

.reg .b32 a<2>, b<2>, c<8>, d<8>;

wmma.mma.sync.aligned.m16n16k8.row.col.f32.tf32.tf32.f32

        {d0, d1, d2, d3, d4, d5, d6, d7},

        {a0, a1, a2, a3}, {b0, b1, b2, b3},

        {c0, c1, c2, c3, c4, c5, c6, c7};
```

#### 9.7.14.5. Matrix multiply-accumulate operation using `mma` instruction[](#warp-level-matrix-instructions-for-mma "Permalink to this headline")

This section describes warp-level `mma`, `ldmatrix`, `stmatrix`, and `movmatrix`
instructions and the organization of various matrices involved in these instructions.

##### 9.7.14.5.1. [Matrix Fragments for `mma.m8n8k4` with `.f16` floating point type](#warp-level-matrix-fragment-mma-884-f16)[](#warp-level-matrix-fragment-mma-884-f16 "Permalink to this headline")

A warp executing `mma.m8n8k4` with `.f16` floating point type will compute 4 MMA operations of shape
`.m8n8k4`.

Elements of 4 matrices need to be distributed across the threads in a warp. The following table
shows distribution of matrices for MMA operations.

| MMA Computation | Threads participating in MMA computation |
| --- | --- |
| MMA computation 1 | Threads with `%laneid` 0-3 (low group) and 16-19 (high group) |
| MMA computation 2 | Threads with `%laneid` 4-7 (low group) and 20-23 (high group) |
| MMA computation 3 | Threads with `%laneid` 8-11 (low group) and 24-27 (high group) |
| MMA computation 4 | Threads with `%laneid` 12-15 (low group) and 28-31 (high group) |

For each of the individual MMA computation shown above, each of the required thread holds a fragment
of the matrix for performing mma operation as follows:

* Multiplicand A:

  | .atype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.f16` | A vector expression containing two `.f16x2` registers, with each register containing two `.f16` elements from the matrix A. | a0, a1, a2, a3 |

  The layout of the fragments held by different threads is shown below:

  + Fragment layout for Row Major matrix A is shown in [Figure 46](#mma-884-a-row-f16).

    ![_images/mma-884-A-row-f16.png](_images/mma-884-A-row-f16.png)


    Figure 46 MMA .m8n8k4 fragment layout for row-major matrix A with `.f16` type[](#mma-884-a-row-f16 "Permalink to this image")

    The row and column of a matrix fragment can be computed as:

    ```
    row = %laneid % 4 if %laneid < 16

     (%laneid % 4) + 4 otherwise



    col = i for ai where i = {0,..,3}
    ```
  + Fragment layout for Column Major matrix A is shown in [Figure 47](#mma-884-a-col-f16).

    The layout of the fragments held by different threads is shown below:

    ![_images/mma-884-A-col-f16.png](_images/mma-884-A-col-f16.png)


    Figure 47 MMA .m8n8k4 fragment layout for column-major matrix A with `.f16` type[](#mma-884-a-col-f16 "Permalink to this image")

    The row and column of a matrix fragment can be computed as:

    ```
    row = i % 4 for ai where i = {0,..,3} if %laneid < 16

     (i % 4) + 4 for ai where i = {0,..,3} otherwise



    col = %laneid % 4
    ```
* Multiplicand B:

  | .btype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.f16` | A vector expression containing two `.f16x2` registers, with each register containing two `.f16` elements from the matrix B. | b0, b1, b2, b3 |

  The layout of the fragments held by different threads is shown below:

  + Fragment layout for Row Major matrix B is shown in [Figure 48](#mma-884-b-row-f16).

    ![_images/mma-884-B-row-f16.png](_images/mma-884-B-row-f16.png)


    Figure 48 MMA .m8n8k4 fragment layout for row-major matrix B with `.f16` type[](#mma-884-b-row-f16 "Permalink to this image")

    The row and column of a matrix fragment can be computed as:

    ```
    row = %laneid % 4



    col = i for bi where i = {0,..,3} if %laneid < 16

     i+4 for bi where i = {0,..,3} otherwise
    ```
  + Fragment layout for Column Major matrix B is shown in [Figure 49](#mma-884-b-col-f16).

    ![_images/mma-884-B-col-f16.png](_images/mma-884-B-col-f16.png)


    Figure 49 MMA .m8n8k4 fragment layout for column-major matrix B with `.f16` type[](#mma-884-b-col-f16 "Permalink to this image")

    The row and column of a matrix fragment can be computed as:

    ```
    row = i for bi where i = {0,..,3}



    col = %laneid % 4 if %laneid < 16

     (%laneid % 4) + 4 otherwise
    ```
* Accumulators C (or D):

  | .ctype / .dtype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.f16` | A vector expression containing four `.f16x2` registers, with each register containing two `.f16` elements from the matrix C (or D). | c0, c1, c2, c3, c4, c5, c6, c7 |
  | `.f32` | A vector expression of eight `.f32` registers. |

  The layout of the fragments held by different threads is shown below:

  + Fragment layout for accumulator matrix when `.ctype` is `.f16` is shown in [Figure 50](#mma-884-c-f16).

    ![_images/mma-884-C-f16.png](_images/mma-884-C-f16.png)


    Figure 50 MMA .m8n8k4 fragment layout for matrix C/D with `.ctype` = `.f16`[](#mma-884-c-f16 "Permalink to this image")

    The row and column of a matrix fragment can be computed as:

    ```
    row = %laneid % 4 if %laneid < 16

     (%laneid % 4) + 4 otherwise



    col = i for ci where i = {0,..,7}
    ```
  + Fragment layout for accumulator matrix when `.ctype` is `.f32` is shown in
    [Figure 51](#mma-884-c-f32-1) and [Figure 52](#mma-884-c-f32-2).

    ![_images/mma-884-C-f32-1.png](_images/mma-884-C-f32-1.png)


    Figure 51 MMA .m8n8k4 computation 1 and 2 fragment layout for matrix C/D with `.ctype` = `.f32`[](#mma-884-c-f32-1 "Permalink to this image")


    ![_images/mma-884-C-f32-2.png](_images/mma-884-C-f32-2.png)


    Figure 52 MMA .m8n8k4 computation 3 and 4 fragment layout for matrix C/D with `.ctype` = `.f32`[](#mma-884-c-f32-2 "Permalink to this image")

    The row and column of a matrix fragment can be computed as:

    ```
    row = X if %laneid < 16

     X + 4 otherwise



     where X = (%laneid & 0b1) + (i & 0b10) for ci where i = {0,..,7}



    col = (i & 0b100) + (%laneid & 0b10) + (i & 0b1) for ci where i = {0,..,7}
    ```

##### 9.7.14.5.2. [Matrix Fragments for `mma.m8n8k4` with `.f64` floating point type](#warp-level-matrix-fragment-mma-884-f64)[](#warp-level-matrix-fragment-mma-884-f64 "Permalink to this headline")

A warp executing `mma.m8n8k4` with `.f64` floating point type will compute an MMA operation of
shape `.m8n8k4`.

Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.

* Multiplicand A:

  | .atype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.f64` | A vector expression containing a single `.f64` register, containing single `.f64` element from the matrix A. | a0 |

  The layout of the fragments held by different threads is shown in [Figure 53](#mma-884-a-f64).

  ![_images/mma-884-A-f64.png](_images/mma-884-A-f64.png)


  Figure 53 MMA .m8n8k4 fragment layout for matrix A with `.f64` type[](#mma-884-a-f64 "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  row = %laneid >> 2



  col = %laneid % 4
  ```
* Multiplicand B:

  | .btype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.f64` | A vector expression containing a single `.f64` register, containing a single `.f64` element from the matrix B. | b0 |

  The layout of the fragments held by different threads is shown in [Figure 54](#mma-884-b-f64).

  ![_images/mma-884-B-f64.png](_images/mma-884-B-f64.png)


  Figure 54 MMA .m8n8k4 fragment layout for matrix B with `.f64` type[](#mma-884-b-f64 "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  row = %laneid % 4



  col = %laneid >> 2
  ```
* Accumulators (C or D):

  | .ctype / .dtype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.f64` | A vector expression containing of two `.f64` registers containing two `.f64` elements from the matrix C. | c0, c1 |

  The layout of the fragments held by different threads is shown in [Figure 55](#mma-884-c-f64).

  ![_images/mma-884-C-f64.png](_images/mma-884-C-f64.png)


  Figure 55 MMA .m8n8k4 fragment layout for accumulator matrix C/D with `.f64` type[](#mma-884-c-f64 "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID



  col = (threadID_in_group * 2) + (i & 0x1) for ci where i = {0, 1}
  ```

##### 9.7.14.5.3. [Matrix Fragments for `mma.m8n8k16`](#warp-level-matrix-fragment-mma-8816)[](#warp-level-matrix-fragment-mma-8816 "Permalink to this headline")

A warp executing `mma.m8n8k16` will compute an MMA operation of shape `.m8n8k16`.

Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.

* Multiplicand A:

  | .atype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.s8` / `.u8` | A vector expression containing a single `.b32` register, containing four `.s8` or `.u8` elements from the matrix A. | a0, a1, a2, a3 |

  The layout of the fragments held by different threads is shown in [Figure 56](#mma-8816-a-i8).

  ![_images/mma-8816-A-i8.png](_images/mma-8816-A-i8.png)


  Figure 56 MMA .m8n8k16 fragment layout for matrix A with `.u8`/`.s8` type[](#mma-8816-a-i8 "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID



  col = (threadID_in_group * 4) + i for ai where i = {0,..,3}
  ```
* Multiplicand B:

  | .btype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.s8` / `.u8` | A vector expression containing a single `.b32` register, containing four `.s8` or `.u8` elements from the matrix B. | b0, b1, b2, b3 |

  The layout of the fragments held by different threads is shown in [Figure 57](#mma-8816-b-i8).

  ![_images/mma-8816-B-i8.png](_images/mma-8816-B-i8.png)


  Figure 57 MMA .m8n8k16 fragment layout for matrix B with `.u8`/`.s8` type[](#mma-8816-b-i8 "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = (threadID_in_group * 4) + i for bi where i = {0,..,3}



  col = groupID
  ```
* Accumulators (C or D):

  | .ctype / .dtype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.s32` | A vector expression containing of two `.s32` registers. | c0, c1 |

  The layout of the fragments held by different threads is shown in [Figure 58](#mma-8816-c-i8).

  ![_images/mma-8816-C-i8.png](_images/mma-8816-C-i8.png)


  Figure 58 MMA .m8n8k16 fragment layout for accumulator matrix C/D with `.s32` type[](#mma-8816-c-i8 "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID



  col = (threadID_in_group * 2) + i for ci where i = {0, 1}
  ```

##### 9.7.14.5.4. [Matrix Fragments for `mma.m8n8k32`](#warp-level-matrix-fragment-mma-8832)[](#warp-level-matrix-fragment-mma-8832 "Permalink to this headline")

A warp executing `mma.m8n8k32` will compute an MMA operation of shape `.m8n8k32`.

Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.

* Multiplicand A:

  | .atype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.s4` / `.u4` | A vector expression containing a single `.b32` register, containing eight `.s4` or `.u4` elements from the matrix A. | a0, a1, a2, a3, a4, a5, a6, a7 |

  The layout of the fragments held by different threads is shown in [Figure 59](#mma-8832-a-i4).

  ![_images/mma-8832-A-i4.png](_images/mma-8832-A-i4.png)


  Figure 59 MMA .m8n8k32 fragment layout for matrix A with `.u4`/`.s4` type[](#mma-8832-a-i4 "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID



  col = (threadID_in_group * 8) + i for ai where i = {0,..,7}
  ```
* Multiplicand B:

  | .btype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.s4` / `.u4` | A vector expression containing a single `.b32` register, containing eight `.s4` or `.u4` elements from the matrix B. | b0, b1, b2, b3, b4, b5, b6, b7 |

  The layout of the fragments held by different threads is shown in [Figure 60](#mma-8832-b-i4).

  ![_images/mma-8832-B-i4.png](_images/mma-8832-B-i4.png)


  Figure 60 MMA .m8n8k32 fragment layout for matrix B with `.u4`/`.s4` type[](#mma-8832-b-i4 "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = (threadID_in_group * 8) + i for bi where i = {0,..,7}



  col = groupID
  ```
* Accumulators (C or D):

  | .ctype / .dtype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.s32` | A vector expression of two `.s32` registers. | c0, c1 |

  The layout of the fragments held by different threads is shown in [Figure 61](#mma-8832-c-i4):

  ![_images/mma-8832-C-i4.png](_images/mma-8832-C-i4.png)


  Figure 61 MMA .m8n8k32 fragment layout for accumulator matrix C/D with `.s32` type[](#mma-8832-c-i4 "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID

  col = (threadID_in_group * 2) + i for ci where i = {0, 1}
  ```

##### 9.7.14.5.5. [Matrix Fragments for `mma.m8n8k128`](#warp-level-matrix-fragment-mma-88128)[](#warp-level-matrix-fragment-mma-88128 "Permalink to this headline")

A warp executing `mma.m8n8k128` will compute an MMA operation of shape `.m8n8k128`.

Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.

* Multiplicand A:

  | .atype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.b1` | A vector expression containing a single `.b32` register, containing thirty two `.b1` elements from the matrix A. | a0, a1, … a30, a31 |

  The layout of the fragments held by different threads is shown in [Figure 62](#mma-88128-a).

  ![_images/mma-88128-A.png](_images/mma-88128-A.png)


  Figure 62 MMA .m8n8k128 fragment layout for matrix A with `.b1` type.[](#mma-88128-a "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID



  col = (threadID_in_group * 32) + i for ai where i = {0,..,31}
  ```
* Multiplicand B:

  | .btype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.b1` | A vector expression containing a single `.b32` register, containing thirty two `.b1` elements from the matrix B. | b0, b1, …, b30, b31 |

  The layout of the fragments held by different threads is shown in [Figure 63](#mma-88128-b).

  ![_images/mma-88128-B.png](_images/mma-88128-B.png)


  Figure 63 MMA .m8n8k128 fragment layout for matrix B with `.b1` type.[](#mma-88128-b "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = (threadID_in_group * 32) + i for bi where i = {0,..,31}



  col = groupID
  ```
* Accumulators (C or D):

  | .ctype / .dtype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.s32` | A vector expression containing two `.s32` registers, containing two `.s32` elements from the matrix C (or D). | c0, c1 |

  The layout of the fragments held by different threads is shown in [Figure 64](#mma-88128-c).

  ![_images/mma-88128-C.png](_images/mma-88128-C.png)


  Figure 64 MMA .m8n8k128 fragment layout for accumulator matrix C/D with `.s32` type[](#mma-88128-c "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID



  col = (threadID_in_group * 2) + i for ci where i = {0, 1}
  ```

##### 9.7.14.5.6. [Matrix Fragments for `mma.m16n8k4`](#warp-level-matrix-fragment-mma-1684)[](#warp-level-matrix-fragment-mma-1684 "Permalink to this headline")

A warp executing `mma.m16n8k4` will compute an MMA operation of shape `.m16n8k4`.

Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.

* Multiplicand A:

  + `.tf32`:

    | .atype | Fragment | Elements (low to high) |
    | --- | --- | --- |
    | `.tf32` | A vector expression containing two `.b32` registers, containing two `.tf32` elements from the matrix A. | a0, a1 |

    The layout of the fragments held by different threads is shown in [Figure 65](#mma-1684-a-tf32).

    ![_images/mma-1684-A.png](_images/mma-1684-A.png)


    Figure 65 MMA .m16n8k4 fragment layout for matrix A with `.tf32` type.[](#mma-1684-a-tf32 "Permalink to this image")

    The row and column of a matrix fragment can be computed as:

    ```
    groupID = %laneid >> 2

    threadID_in_group = %laneid % 4



    row = groupID for a0

     groupID + 8 for a1



    col = threadID_in_group
    ```
  + `.f64`:

    > | .atype | Fragment | Elements (low to high) |
    > | --- | --- | --- |
    > | `.f64` | A vector expression containing two `.f64` registers, containing two `.f64` elements from the matrix A. | a0, a1 |
    >
    > The layout of the fragments held by different threads is shown in [Figure 66](#mma-1684-a-f64).
    >
    > ![_images/mma-1684-A.png](_images/mma-1684-A.png)
    >
    >
    > Figure 66 MMA .m16n8k4 fragment layout for matrix A with `.f64` type.[](#mma-1684-a-f64 "Permalink to this image")
    >
    > The row and column of a matrix fragment can be computed as:
    >
    > ```
    > groupID = %laneid >> 2
    >
    > threadID_in_group = %laneid % 4
    >
    >
    >
    > row = groupID for a0
    >
    >  groupID + 8 for a1
    >
    >
    >
    > col = threadID_in_group
    > ```
* Multiplicand B:

  + `.tf32`:

    > | .btype | Fragment | Elements (low to high) |
    > | --- | --- | --- |
    > | `.tf32` | A vector expression of a single `.b32` register, containing a single `.tf32` element from the matrix B. | b0 |
    >
    > The layout of the fragments held by different threads is shown in [Figure 67](#mma-1684-b-tf32).
    >
    > ![_images/mma-1684-B.png](_images/mma-1684-B.png)
    >
    >
    > Figure 67 MMA .m16n8k4 fragment layout for matrix B with `.tf32` type.[](#mma-1684-b-tf32 "Permalink to this image")
    >
    > The row and column of a matrix fragment can be computed as:
    >
    > ```
    > groupID = %laneid >> 2
    >
    > threadID_in_group = %laneid % 4
    >
    >
    >
    > row = threadID_in_group
    >
    >
    >
    > col = groupID
    > ```
  + `.f64`:

    > | .btype | Fragment | Elements (low to high) |
    > | --- | --- | --- |
    > | `.f64` | A vector expression of a single `.f64` register, containing a single `.f64` element from the matrix B. | b0 |
    >
    > The layout of the fragments held by different threads is shown in [Figure 68](#mma-1684-b-f64).
    >
    > ![_images/mma-1684-B.png](_images/mma-1684-B.png)
    >
    >
    > Figure 68 MMA .m16n8k4 fragment layout for matrix B with `.f64` type.[](#mma-1684-b-f64 "Permalink to this image")
    >
    > The row and column of a matrix fragment can be computed as:
    >
    > ```
    > groupID = %laneid >> 2
    >
    > threadID_in_group = %laneid % 4
    >
    >
    >
    > row = threadID_in_group
    >
    >
    >
    > col = groupID
    > ```
* Accumulators (C or D):

  + `.tf32`:

    > | .ctype / .dtype | Fragment | Elements (low to high) |
    > | --- | --- | --- |
    > | `.f32` | A vector expression containing four `.f32` registers, containing four `.f32` elements from the matrix C (or D). | c0, c1, c2, c3 |
    >
    > The layout of the fragments held by different threads is shown in [Figure 69](#mma-1684-c-f32).
    >
    > ![_images/mma-1684-C.png](_images/mma-1684-C.png)
    >
    >
    > Figure 69 MMA .m16n8k4 fragment layout for accumulator matrix C/D with `.f32` type.[](#mma-1684-c-f32 "Permalink to this image")
    >
    > The row and column of a matrix fragment can be computed as:
    >
    > ```
    > groupID = %laneid >> 2
    >
    > threadID_in_group = %laneid % 4
    >
    >
    >
    > row = groupID for c0 and c1
    >
    >  groupID + 8 for c2 and c3
    >
    >
    >
    > col = (threadID_in_group * 2) + (i & 0x1) for ci where i = {0,..,3}
    > ```
  + `.f64`:

    > | .ctype / .dtype | Fragment | Elements (low to high) |
    > | --- | --- | --- |
    > | `.f64` | A vector expression containing four `.f64` registers, containing four `.f64` elements from the matrix C (or D). | c0, c1, c2, c3 |
    >
    > The layout of the fragments held by different threads is shown in [Figure 70](#mma-1684-c-f64).
    >
    > ![_images/mma-1684-C.png](_images/mma-1684-C.png)
    >
    >
    > Figure 70 MMA .m16n8k4 fragment layout for accumulator matrix C/D with `.f64` type.[](#mma-1684-c-f64 "Permalink to this image")
    >
    > The row and column of a matrix fragment can be computed as:
    >
    > ```
    > groupID = %laneid >> 2
    >
    > threadID_in_group = %laneid % 4
    >
    >
    >
    > row = groupID for c0 and c1
    >
    >  groupID + 8 for c2 and c3
    >
    >
    >
    > col = (threadID_in_group * 2) + (i & 0x1) for ci where i = {0,..,3}
    > ```

##### 9.7.14.5.7. [Matrix Fragments for `mma.m16n8k8`](#warp-level-matrix-fragment-mma-1688)[](#warp-level-matrix-fragment-mma-1688 "Permalink to this headline")

A warp executing `mma.m16n8k8` will compute an MMA operation of shape `.m16n8k8`.

Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.

* Multiplicand A:

  + `.f16` and `.bf16` :

    > | .atype | Fragment | Elements (low to high) |
    > | --- | --- | --- |
    > | `.f16` / `.bf16` | A vector expression containing two `.f16x2` registers, with each register containing two `.f16` / `.bf16` elements from the matrix A. | a0, a1, a2, a3 |
    >
    > The layout of the fragments held by different threads is shown in [Figure 71](#mma-1688-a-f16).
    >
    > ![_images/mma-1688-A-f16.png](_images/mma-1688-A-f16.png)
    >
    >
    > Figure 71 MMA .m16n8k8 fragment layout for matrix A with `.f16` / `.bf16` type.[](#mma-1688-a-f16 "Permalink to this image")
    >
    > The row and column of a matrix fragment can be computed as:
    >
    > ```
    > groupID = %laneid >> 2
    >
    > threadID_in_group = %laneid % 4
    >
    >
    >
    > row = groupID for a0 and a1
    >
    >  groupID + 8 for a2 and a3
    >
    >
    >
    > col = threadID_in_group * 2 + (i & 0x1) for ai where i = {0,..,3}
    > ```
  + `.tf32` :

    > | .atype | Fragment | Elements (low to high) |
    > | --- | --- | --- |
    > | `.tf32` | A vector expression containing four `.b32` registers, containing four `.tf32` elements from the matrix A. | a0, a1, a2, a3 |
    >
    > The layout of the fragments held by different threads is shown in [Figure 72](#mma-1688-a-tf32).
    >
    > ![_images/mma-1688-A-tf32.png](_images/mma-1688-A-tf32.png)
    >
    >
    > Figure 72 MMA .m16n8k8 fragment layout for matrix A with `.tf32` type.[](#mma-1688-a-tf32 "Permalink to this image")
    >
    > The row and column of a matrix fragment can be computed as:
    >
    > ```
    > groupID = %laneid >> 2
    >
    > threadID_in_group = %laneid % 4
    >
    >
    >
    > row = groupID for a0 and a2
    >
    >  groupID + 8 for a1 and a3
    >
    >
    >
    > col = threadID_in_group for a0 and a1
    >
    >  threadID_in_group + 4 for a2 and a3
    > ```
  + `.f64` :

    | .atype | Fragment | Elements (low to high) |
    | --- | --- | --- |
    | `.f64` | A vector expression containing four `.f64` registers, containing four `.f64` elements from the matrix A. | a0, a1, a2, a3 |

    The layout of the fragments held by different threads is shown in [Figure 73](#mma-1688-a-f64).

    ![_images/mma-1688-A-tf32.png](_images/mma-1688-A-tf32.png)


    Figure 73 MMA .m16n8k8 fragment layout for matrix A with `.f64` type.[](#mma-1688-a-f64 "Permalink to this image")

    The row and column of a matrix fragment can be computed as:

    ```
    groupID = %laneid >> 2

    threadID_in_group = %laneid % 4



    row = groupID for a0 and a2

     groupID + 8 for a1 and a3



    col = threadID_in_group for a0 and a1

     threadID_in_group + 4 for a2 and a3
    ```
* Multiplicand B:

  + `.f16` and `.bf16` :

    > | .btype | Fragment | Elements (low to high) |
    > | --- | --- | --- |
    > | `.f16` / `.bf16` | A vector expression containing a single `.f16x2` register, containing two `.f16` / `.bf16` elements from the matrix B. | b0, b1 |
    >
    > The layout of the fragments held by different threads is shown in [Figure 74](#mma-1688-b-f16).
    >
    > ![_images/mma-1688-B-f16.png](_images/mma-1688-B-f16.png)
    >
    >
    > Figure 74 MMA .m16n8k8 fragment layout for matrix B with `.f16` / `.bf16` type.[](#mma-1688-b-f16 "Permalink to this image")
    >
    > The row and column of a matrix fragment can be computed as:
    >
    > ```
    > groupID = %laneid >> 2
    >
    > threadID_in_group = %laneid % 4
    >
    >
    >
    > row = (threadID_in_group * 2) + i for bi where i = {0, 1}
    >
    >
    >
    > col = groupID
    > ```
  + `.tf32` :

    > | .btype | Fragment | Elements (low to high) |
    > | --- | --- | --- |
    > | `.tf32` | A vector expression containing two `.b32` registers, containing two `.tf32` elements from the matrix B. | b0, b1 |
    >
    > The layout of the fragments held by different threads is shown in [Figure 75](#mma-1688-b-tf32).
    >
    > ![_images/mma-1688-B-tf32.png](_images/mma-1688-B-tf32.png)
    >
    >
    > Figure 75 MMA .m16n8k8 fragment layout for matrix B with `.tf32` type.[](#mma-1688-b-tf32 "Permalink to this image")
    >
    > The row and column of a matrix fragment can be computed as:
    >
    > ```
    > groupID = %laneid >> 2
    >
    > threadID_in_group = %laneid % 4
    >
    >
    >
    > row = threadID_in_group for b0
    >
    >  threadID_in_group + 4 for b1
    >
    >
    >
    > col = groupID
    > ```
  + `.f64` :

    > | .btype | Fragment | Elements (low to high) |
    > | --- | --- | --- |
    > | `.f64` | A vector expression containing two `.f64` registers, containing two `.f64` elements from the matrix B. | b0, b1 |
    >
    > The layout of the fragments held by different threads is shown in [Figure 76](#mma-1688-b-f64).
    >
    > ![_images/mma-1688-B-tf32.png](_images/mma-1688-B-tf32.png)
    >
    >
    > Figure 76 MMA .m16n8k8 fragment layout for matrix B with `.f64` type.[](#mma-1688-b-f64 "Permalink to this image")
    >
    > The row and column of a matrix fragment can be computed as:
    >
    > ```
    > groupID = %laneid >> 2
    >
    > threadID_in_group = %laneid % 4
    >
    >
    >
    > row = threadID_in_group for b0
    >
    >  threadID_in_group + 4 for b1
    >
    >
    >
    > col = groupID
    > ```
* Accumulators (C or D):

  + `.f16`, `.bf16` and `.tf32`:

    > | .ctype / .dtype | Fragment | Elements (low to high) |
    > | --- | --- | --- |
    > | `.f16` | A vector expression containing two `.f16x2` registers, with each register containing two `.f16` elements from the matrix C (or D). | c0, c1, c2, c3 |
    > | `.f32` | A vector expression of four `.f32` registers. |  |
    >
    > The layout of the fragments held by different threads is shown in [Figure 77](#mma-1688-c-f16-f32).
    >
    > ![_images/mma-1688-C.png](_images/mma-1688-C.png)
    >
    >
    > Figure 77 MMA .m16n8k8 fragment layout for accumulator matrix C/D with `.f16x2`/`.f32` type.[](#mma-1688-c-f16-f32 "Permalink to this image")
    >
    > The row and column of a matrix fragment can be computed as:
    >
    > ```
    > groupID = %laneid >> 2
    >
    > threadID_in_group = %laneid % 4
    >
    >
    >
    > row = groupID for c0 and c1
    >
    >  groupID + 8 for c2 and c3
    >
    >
    >
    > col = (threadID_in_group * 2) + (i & 0x1) for ci where i = {0,..,3}
    > ```
  + `.f64` :

    > | .ctype / .dtype | Fragment | Elements (low to high) |
    > | --- | --- | --- |
    > | `.f64` | A vector expression of four `.f64` registers containing four `.f64` elements from the matrix C (or D). | c0, c1, c2, c3 |
    >
    > The layout of the fragments held by different threads is shown in [Figure 78](#mma-1688-c-f64).
    >
    > ![_images/mma-1688-C.png](_images/mma-1688-C.png)
    >
    >
    > Figure 78 MMA .m16n8k8 fragment layout for accumulator matrix C/D with `.f64` type.[](#mma-1688-c-f64 "Permalink to this image")
    >
    > The row and column of a matrix fragment can be computed as:
    >
    > ```
    > groupID = %laneid >> 2
    >
    > threadID_in_group = %laneid % 4
    >
    >
    >
    > row = groupID for c0 and c1
    >
    >  groupID + 8 for c2 and c3
    >
    >
    >
    > col = (threadID_in_group * 2) + (i & 0x1) for ci where i = {0,..,3}
    > ```

##### 9.7.14.5.8. [Matrix Fragments for `mma.m16n8k16` with floating point type](#warp-level-matrix-fragment-mma-16816-float)[](#warp-level-matrix-fragment-mma-16816-float "Permalink to this headline")

A warp executing `mma.m16n8k16` floating point types will compute an MMA operation of shape
`.m16n8k16`.

Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.

* Multiplicand A:

  + `.f16` and `.bf16` :

    > | .atype | Fragment | Elements (low to high) |
    > | --- | --- | --- |
    > | `.f16` / `.bf16` | A vector expression containing four `.f16x2` registers, with each register containing two `.f16` / `.bf16` elements from the matrix A. | a0, a1, a2, a3, a4, a5, a6, a7 |
    >
    > The layout of the fragments held by different threads is shown in [Figure 79](#mma-16816-a-f16).
    >
    > ![_images/mma-16816-A-f16.png](_images/mma-16816-A-f16.png)
    >
    >
    > Figure 79 MMA .m16n8k16 fragment layout for matrix A with `.f16` / `.bf16` type.[](#mma-16816-a-f16 "Permalink to this image")
    >
    > The row and column of a matrix fragment can be computed as:
    >
    > ```
    > groupID = %laneid >> 2
    >
    > threadID_in_group = %laneid % 4
    >
    >
    >
    > row = groupID for ai where 0 <= i < 2 || 4 <= i < 6
    >
    >  groupID + 8 Otherwise
    >
    >
    >
    > col = (threadID_in_group * 2) + (i & 0x1) for ai where i < 4
    >
    > (threadID_in_group * 2) + (i & 0x1) + 8 for ai where i >= 4
    > ```
  + `.f64` :

    > | .atype | Fragment | Elements (low to high) |
    > | --- | --- | --- |
    > | `.f64` | A vector expression containing eight `.f64` registers, with each register containing one `.f64` element from the matrix A. | a0, a1, a2, a3, a4, a5, a6, a7 |
    >
    > The layout of the fragments held by different threads is shown in [Figure 80](#mma-16816-a-f64).
    >
    > ![_images/mma-16816-A-f64.png](_images/mma-16816-A-f64.png)
    >
    >
    > Figure 80 MMA .m16n8k16 fragment layout for matrix A with `.f64` type.[](#mma-16816-a-f64 "Permalink to this image")
    >
    > The row and column of a matrix fragment can be computed as:
    >
    > ```
    > groupID = %laneid >> 2
    >
    > threadID_in_group = %laneid % 4
    >
    >
    >
    > row = groupID for ai where i % 2 = 0
    >
    >  groupID + 8 Otherwise
    >
    >
    >
    > col = (i * 2) + threadID_in_group for ai where i % 2 = 0
    >
    >  (i * 2) - 2 + (threadID_in_group Otherwise
    > ```
* Multiplicand B:

  + `.f16` and `.bf16` :

    > | .btype | Fragment | Elements (low to high) |
    > | --- | --- | --- |
    > | `.f16` / `.bf16` | A vector expression containing two `.f16x2` registers, with each register containing two `.f16` / `.bf16` elements from the matrix B. | b0, b1, b2, b3 |
    >
    > The layout of the fragments held by different threads is shown in [Figure 81](#mma-16816-b-f16).
    >
    > ![_images/mma-16816-B-f16.png](_images/mma-16816-B-f16.png)
    >
    >
    > Figure 81 MMA .m16n8k16 fragment layout for matrix B with `.f16` / `.bf16` type.[](#mma-16816-b-f16 "Permalink to this image")
    >
    > where the row and column of a matrix fragment can be computed as:
    >
    > ```
    > groupID = %laneid >> 2
    >
    > threadID_in_group = %laneid % 4
    >
    >
    >
    > row = (threadID_in_group * 2) + (i & 0x1) for bi where i < 2
    >
    >  (threadID_in_group * 2) + (i & 0x1) + 8 for bi where i >= 2
    >
    >
    >
    > col = groupID
    > ```
  + `.f64` :

    > | .atype | Fragment | Elements (low to high) |
    > | --- | --- | --- |
    > | `.f64` | A vector expression containing four `.f64` registers, with each register containing one `.f64` element from the matrix B. | b0, b1, b2, b3 |
    >
    > The layout of the fragments held by different threads is shown in [Figure 82](#mma-16816-b-f64).
    >
    > ![_images/sparse-mma-16816-tf32-B.png](_images/sparse-mma-16816-tf32-B.png)
    >
    >
    > Figure 82 MMA .m16n8k16 fragment layout for matrix B with `.f64` type.[](#mma-16816-b-f64 "Permalink to this image")
    >
    > The row and column of a matrix fragment can be computed as:
    >
    > ```
    > groupID = %laneid >> 2
    >
    > threadID_in_group = %laneid % 4
    >
    >
    >
    > row = threadID_in_group + (i * 4) for bi where i < 4
    >
    >
    >
    > col = groupID
    > ```
* Accumulators (C or D):

  | .ctype / .dtype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.f64` | A vector expression containing four `.f64` registers containing `.f64` elements from the matrix C (or D). | c0, c1, c2, c3 |
  | `.f32` | A vector expression containing four `.f32` registers containing four `.f32` elements from the matrix C (or D). |
  | `.f16` | A vector expression containing two `.f16x2` registers, with each register containing two `.f16` elements from the matrix C (or D). |

  The layout of the fragments held by different threads is shown in [Figure 83](#mma-16816-c).

  ![_images/mma-16816-C-f16.png](_images/mma-16816-C-f16.png)


  Figure 83 MMA .m16n8k16 fragment layout for accumulator matrix matrix C/D.[](#mma-16816-c "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID for ci where i < 2

   groupID + 8 for ci where i >= 2



  col = (threadID_in_group * 2) + (i & 0x1) for ci where i = {0,..,3}
  ```

##### 9.7.14.5.9. [Matrix Fragments for `mma.m16n8k16` with integer type](#warp-level-matrix-fragment-mma-16816-i8-f8)[](#warp-level-matrix-fragment-mma-16816-i8-f8 "Permalink to this headline")

A warp executing `mma.m16n8k16` will compute an MMA operation of shape `.m16n8k16`.

Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.

* Multiplicand A:

  | .atype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.u8` / `.s8` | A vector expression containing two `.b32` registers, with each register containing four `.u8` / `.s8` elements from the matrix A. | a0, a1, a2, a3, a4, a5, a6, a7 |
  | `.e4m3` / `.e5m2` | A vector expression containing two `.b32` registers, with each register containing four `.e4m3` / `.e5m2` elements from the matrix A. | a0, a1, a2, a3, a4, a5, a6, a7 |

  The layout of the fragments held by different threads is shown in [Figure 84](#mma-16816-a-i8).

  ![_images/mma-16816-A-i8.png](_images/mma-16816-A-i8.png)


  Figure 84 MMA .m16n8k16 fragment layout for matrix A with `.u8` / `.s8` type.[](#mma-16816-a-i8 "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID for ai where i < 4

   groupID + 8 for ai where i >= 4



  col = (threadID_in_group * 4) + (i & 0x3) for ai where i = {0,..,7}
  ```
* Multiplicand B:

  | .btype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.u8` / `.s8` | A vector expression containing a single `.b32` register, containing four `.u8` / `.s8` elements from the matrix B. | b0, b1, b2, b3 |
  | `.e4m3` / `.e5m2` | A vector expression containing a single `.b32` register, containing four `.e4m3` / `.e5m2` elements from the matrix B. | b0, b1. b2. b3 |

  The layout of the fragments held by different threads is shown in [Figure 85](#mma-16816-b-i8).

  ![_images/mma-16816-B-i8.png](_images/mma-16816-B-i8.png)


  Figure 85 MMA .m16n8k16 fragment layout for matrix B with `.u8` / `.s8` type.[](#mma-16816-b-i8 "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = (threadID_in_group * 4) + i for bi where i = {0,..,3}



  col = groupID
  ```
* Accumulators (C or D):

  | .ctype / .dtype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.s32` | A vector expression containing four `.s32` registers, containing four `.s32` elements from the matrix C (or D). | c0, c1, c2, c3 |
  | `.f32` | A vector expression containing four `.f32` registers, containing four `.f32` elements from the matrix C (or D). | c0, c1, c2, c3 |
  | `.f16` | A vector expression containing two `.f16x2` registers, with each register containing two `.f16` elements from the matrix C (or D). | c0, c1, c1, c2 |

  The layout of the fragments held by different threads is shown in [Figure 86](#mma-16816-c-i8).

  ![_images/mma-16816-C-i8.png](_images/mma-16816-C-i8.png)


  Figure 86 MMA .m16n8k16 fragment layout for accumulator matrix C/D with `.s32` type.[](#mma-16816-c-i8 "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID for ci where i < 2

   groupID + 8 for ci where i >= 2



  col = (threadID_in_group * 2) + (i & 0x1) for ci where i = {0,..,3}
  ```

##### 9.7.14.5.10. [Matrix Fragments for `mma.m16n8k32`](#warp-level-matrix-fragment-mma-16832)[](#warp-level-matrix-fragment-mma-16832 "Permalink to this headline")

A warp executing `mma.m16n8k32` will compute an MMA operation of shape `.m16n8k32`.

Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.

* Multiplicand A:

  + `.s4` or `.u4` :

    > | .atype | Fragment | Elements (low to high) |
    > | --- | --- | --- |
    > | `.s4` / `.u4` | A vector expression containing two `.b32` registers, with each register containing eight `.u4` / `.s4` elements from the matrix A. | a0, a1, …, a14, a15 |
    >
    > The layout of the fragments held by different threads is shown in [Figure 87](#mma-16832-a-i4).
    >
    > ![_images/mma-16832-A-i4.png](_images/mma-16832-A-i4.png)
    >
    >
    > Figure 87 MMA .m16n8k32 fragment layout for matrix A with `.u4` / `.s4` type.[](#mma-16832-a-i4 "Permalink to this image")
    >
    > The row and column of a matrix fragment can be computed as:
    >
    > ```
    > groupID = %laneid >> 2
    >
    > threadID_in_group = %laneid % 4
    >
    >
    >
    > row = groupID for ai where i < 8
    >
    >  groupID + 8 for ai where i >= 8
    >
    >
    >
    > col = (threadID_in_group * 8) + (i & 0x7) for ai where i = {0,..,15}
    > ```
  + `.s8` or `.u8` or `.e4m3` or `.e5m2` or `.e3m2` or `.e2m3` or `.e2m1`:

    > | .atype | Fragment | Elements (low to high) |
    > | --- | --- | --- |
    > | `.s8` / `.u8` | A vector expression containing four `.b32` registers, with each register containing four `.s8` / `.u8` elements from the matrix A. | a0, a1, .., a14, a15 |
    > | `.e4m3` / `.e5m2` / `.e3m2` / `.e2m3` / `.e2m1` | A vector expression containing four `.b32` registers, with each register containing four `.e4m3` / `.e5m2` / `.e3m2` / `.e2m3` / `.e2m1` elements from the matrix A. | a0, a1, …, a14, a15 |
    >
    > The layout of the fragments held by different threads is shown in [Figure 88](#mma-16832-a-i8).
    >
    > ![_images/mma-16832-A-i8.png](_images/mma-16832-A-i8.png)
    >
    >
    > Figure 88 MMA .m16n8k32 fragment layout for matrix A with `.u8` / `.s8` / `.e4m3` / `.e5m2` / `.e3m2` / `.e2m3` / `.e2m1` type.[](#mma-16832-a-i8 "Permalink to this image")
    >
    > The row and column of a matrix fragment can be computed as:
    >
    > ```
    > groupID = %laneid >> 2
    >
    > threadID_in_group = %laneid % 4
    >
    >
    >
    > row = groupID for ai where 0 <= i < 4 || 8 <= i < 12
    >
    >  groupID + 8 otherwise
    >
    >
    >
    > col = (threadID_in_group * 4) + (i & 0x3) for ai where i < 8
    >
    >  (threadID_in_group * 4) + (i & 0x3) + 16 for ai where i >= 8
    > ```
* Multiplicand B:

  + `.s4` or `.u4` :

    > | .btype | Fragment | Elements (low to high) |
    > | --- | --- | --- |
    > | `.s4` / `.u4` | A vector expression containing a single `.b32` register, containing eight `.s4` / `.u4` elements from the matrix B. | b0, b1, b2, b3, b4, b5, b6, b7 |
    >
    > The layout of the fragments held by different threads is shown in [Figure 89](#mma-16832-b-i4).
    >
    > ![_images/mma-16832-B-i4.png](_images/mma-16832-B-i4.png)
    >
    >
    > Figure 89 MMA .m16n8k32 fragment layout for matrix B with `.u4` / `.s4` type.[](#mma-16832-b-i4 "Permalink to this image")
    >
    > The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = (threadID_in_group * 8) + (i & 0x7) for bi where i = {0,..,7}

  col = groupID
  ```

  + `.s8` or `.u8` or `.e4m3` or `.e5m2` or `.e3m2` or `.e2m3` or `.e2m1`:

    > | .btype | Fragment | Elements (low to high) |
    > | --- | --- | --- |
    > | `.s8` / `.u8` | A vector expression containing two `.b32` registers, with each register containing four `.s8` / `.u8` elements from the matrix B. | b0, b1, b2, b3, b4, b5, b6, b7 |
    > | `.e4m3` / `.e5m2` / `.e3m2` / `.e2m3` / `.e2m1` | A vector expression containing two `.b32` registers, with each register containing four `.e4m3` / `.e5m2` / `.e3m2` / `.e2m3` / `.e2m1` elements from the matrix B. | b0, b1, b2, b3, b4, b5, b6, b7 |
    >
    > The layout of the fragments held by different threads is shown in [Figure 90](#mma-16832-b-i8-1) and
    > [Figure 91](#mma-16832-b-i8-2).
    >
    > ![_images/mma-16832-B-i8_1.png](_images/mma-16832-B-i8_1.png)
    >
    >
    > Figure 90 MMA .m16n8k32 fragment layout for rows 0–15 of matrix B with `.u8` / `.s8` / `.e4m3` / `.e5m2` / `.e3m2` / `.e2m3` / `.e2m1` type.[](#mma-16832-b-i8-1 "Permalink to this image")
    >
    >
    > ![_images/mma-16832-B-i8_2.png](_images/mma-16832-B-i8_2.png)
    >
    >
    > Figure 91 MMA .m16n8k32 fragment layout for rows 16–31 of matrix B with `.u8` / `.s8` / `.e4m3` / `.e5m2` / `.e3m2` / `.e2m3` / `.e2m1` type.[](#mma-16832-b-i8-2 "Permalink to this image")
    >
    > The row and column of a matrix fragment can be computed as:
    >
    > ```
    > groupID = %laneid >> 2
    >
    > threadID_in_group = %laneid % 4
    >
    >
    >
    > row = (threadID_in_group * 4) + (i & 0x3) for bi where i < 4
    >
    >  (threadID_in_group * 4) + (i & 0x3) + 16 for bi where i >= 4
    >
    >
    >
    > col = groupID
    > ```
* Accumulators (C or D):

  | .ctype / .dtype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.s32` | A vector expression containing four `.s32` registers, containing four `.s32` elements from the matrix C (or D). | c0, c1, c2, c3 |
  | `.f32` | A vector expression containing four `.f32` registers, containing four `.f32` elements from the matrix C (or D). | c0, c1, c2, c3 |
  | `.f16` | A vector expression containing two `.f16x2` registers, with each register containing two `.f16` elements from the matrix C (or D). | c0, c1, c2, c3 |

  The layout of the fragments held by different threads is shown in [Figure 92](#mma-16832-c).

  ![_images/mma-16832-C.png](_images/mma-16832-C.png)


  Figure 92 MMA .m16n8k32 fragment layout for accumulator matrix C/D with `.s32` / `.f32` / `.f16` type.[](#mma-16832-c "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID for ci where i < 2

   groupID + 8 for ci where i >= 2



  col = (threadID_in_group * 2) + (i & 0x1) for ci where i = {0,..,3}
  ```

##### 9.7.14.5.11. [Matrix Fragments for `mma.m16n8k64`](#warp-level-matrix-fragment-mma-16864)[](#warp-level-matrix-fragment-mma-16864 "Permalink to this headline")

A warp executing `mma.m16n8k64` will compute an MMA operation of shape `.m16n8k64`.

Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.

* Multiplicand A:

  | .atype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.s4` / `.u4` | A vector expression containing four `.b32` registers, with each register containing eight `.s4` / `.u4` elements from the matrix A. | a0, a1, …, a30, a31 |
  | `.e2m1` | A vector expression containing four `.b32` registers, with each register containing eight `.e2m1` elements from the matrix A. | a0, a1, …, a30, a31 |

  The layout of the fragments held by different threads is shown in [Figure 93](#mma-16864-a).

  ![_images/mma-16864-A.png](_images/mma-16864-A.png)


  Figure 93 MMA .m16n8k64 fragment layout for matrix A with `.u4` / `.s4` / `.e2m1` type.[](#mma-16864-a "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID for ai where 0 <= i < 8 || 16 <= i < 24

   groupID + 8 otherwise



  col = (threadID_in_group * 8) + (i & 0x7) for ai where i < 16

   (threadID_in_group * 8) + (i & 0x7) + 32 for ai where i >= 16
  ```
* Multiplicand B:

  | .btype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.s4` / `.u4` | A vector expression containing two `.b32` registers, with each register containing eight `.s4` / `.u4` elements from the matrix B. | b0, b1, …, b14, b15 |
  | `.e2m1` | A vector expression containing two `.b32` registers, with each register containing eight `.e2m1` elements from the matrix B. | b0, b1, …, b14, b15 |

  The layout of the fragments held by different threads is shown in [Figure 94](#mma-16864-b-1)
  and [Figure 95](#mma-16864-b-2).

  ![_images/mma-16864-B_1.png](_images/mma-16864-B_1.png)


  Figure 94 MMA .m16n8k64 fragment layout for rows 0–31 of matrix B with `.u4` / `.s4` / `.e2m1` type.[](#mma-16864-b-1 "Permalink to this image")


  ![_images/mma-16864-B_2.png](_images/mma-16864-B_2.png)


  Figure 95 MMA .m16n8k64 fragment layout for rows 32–63 of matrix B with `.u4` / `.s4` / `.e2m1` type.[](#mma-16864-b-2 "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = (threadID_in_group * 8) + (i & 0x7) for bi where i < 8

   (threadID_in_group * 8) + (i & 0x7) + 32 for bi where i >= 8



  col = groupID
  ```
* Accumulators (C or D):

  | .ctype / .dtype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.s32` | A vector expression containing four `.s32` registers, containing four `.s32` elements from the matrix C (or D). | c0, c1, c2, c3 |
  | `.f32` | A vector expression containing four `.f32` registers, containing four `.f32` elements from the matrix C (or D). | c0, c1, c2, c3 |

  The layout of the fragments held by different threads is shown in [Figure 96](#mma-16864-c).

  ![_images/mma-16864-C.png](_images/mma-16864-C.png)


  Figure 96 MMA .m16n8k64 fragment layout for accumulator matrix C/D with `.s32` / `.f32` type.[](#mma-16864-c "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID for ci where i < 2

   groupID + 8 for ci where i >= 2



  col = (threadID_in_group * 2) + (i & 0x1) for ci where i = {0,..,3}
  ```

##### 9.7.14.5.12. [Matrix Fragments for `mma.m16n8k128`](#warp-level-matrix-fragment-mma-168128)[](#warp-level-matrix-fragment-mma-168128 "Permalink to this headline")

A warp executing `mma.m16n8k128` will compute an MMA operation of shape `.m16n8k128`.

Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.

* Multiplicand A:

  | .atype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.b1` | A vector expression containing two `.b32` registers, with each register containing thirty two `.b1` elements from the matrix A. | a0, a1, …, a62, a63 |

  The layout of the fragments held by different threads is shown in [Figure 97](#mma-168128-a).

  ![_images/mma-168128-A.png](_images/mma-168128-A.png)


  Figure 97 MMA .m16n8k128 fragment layout for matrix A with `.b1` type.[](#mma-168128-a "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID for ai where i < 32

   groupID + 8 for ai where i >= 32



  col = (threadID_in_group * 32) + (i & 0x1F) for ai where i = {0, ...,63}
  ```
* Multiplicand B:

  | .btype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.b1` | A vector expression containing a single `.b32` register containing thirty two `.b1` elements from the matrix B. | b0, b1, … , b30, b31 |

  The layout of the fragments held by different threads is shown in [Figure 98](#mma-168128-b).

  ![_images/mma-168128-B.png](_images/mma-168128-B.png)


  Figure 98 MMA .m16n8k128 fragment layout for matrix B with `.b1` type.[](#mma-168128-b "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = (threadID_in_group * 32) + i for bi where i = {0,...,31}

  col = groupID
  ```
* Accumulators (C or D):

  | .ctype / .dtype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.s32` | A vector expression containing four `.s32` registers, containing four `.s32` elements from the matrix C (or D). | c0, c1, c2, c3 |

  The layout of the fragments held by different threads is shown in [Figure 99](#mma-168128-c).

  ![_images/mma-168128-C.png](_images/mma-168128-C.png)


  Figure 99 MMA .m16n8k128 fragment layout for accumulator matrix C/D with `.s32` type.[](#mma-168128-c "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID for ci where i < 2

   groupID + 8 for ci where i >= 2



  col = (threadID_in_group * 2) + (i & 0x1) for ci where i = {0, 1, 2, 3}
  ```

##### 9.7.14.5.13. [Matrix Fragments for `mma.m16n8k256`](#warp-level-matrix-fragment-mma-168256)[](#warp-level-matrix-fragment-mma-168256 "Permalink to this headline")

A warp executing `mma.m16n8k256` will compute an MMA operation of shape `.m16n8k256`.

Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.

* Multiplicand A:

  | .atype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.b1` | A vector expression containing four `.b32` registers, with each register containing thirty two `.b1` elements from the matrix A. | a0, a1, …, a126, a127 |

  The layout of the fragments held by different threads is shown in [Figure 100](#mma-168256-a).

  ![_images/mma-168256-A.png](_images/mma-168256-A.png)


  Figure 100 MMA .m16n8k256 fragment layout for matrix A with `.b1` type.[](#mma-168256-a "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID for ai where 0 <= i < 32 || 64 <= i < 96

   groupID + 8 otherwise



  col = (threadID_in_group * 32) + i for ai where i < 64

   (threadID_in_group * 32) + (i & 0x1F) + 128 for ai where i >= 64
  ```
* Multiplicand B:

  | .btype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.b1` | A vector expression containing two `.b32` registers, with each register containing thirty two `.b1` elements from the matrix B. | b0, b1, …, b62, b63 |

  The layout of the fragments held by different threads is shown in [Figure 101](#mma-168256-b-1) and
  [Figure 102](#mma-168256-b-2).

  ![_images/mma-168256-B_1.png](_images/mma-168256-B_1.png)


  Figure 101 MMA .m16n8k256 fragment layout for rows 0–127 of matrix B with `.b1` type.[](#mma-168256-b-1 "Permalink to this image")


  ![_images/mma-168256-B_2.png](_images/mma-168256-B_2.png)


  Figure 102 MMA .m16n8k256 fragment layout for rows 128–255 of matrix B with `.b1` type.[](#mma-168256-b-2 "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = (threadID_in_group * 32) + (i & 0x1F) for bi where i < 32

   (threadID_in_group * 32) + (i & 0x1F) + 128 for bi where i >= 32



  col = groupID
  ```
* Accumulators (C or D):

  | .ctype / .dtype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.s32` | A vector expression containing four `.s32` registers, containing four `.s32` elements from the matrix C (or D). | c0, c1, c2, c3 |

  The layout of the fragments held by different threads is shown in [Figure 103](#mma-168256-c).

  ![_images/mma-168256-C.png](_images/mma-168256-C.png)


  Figure 103 MMA .m16n8k256 fragment layout for accumulator matrix C/D with `.s32` type.[](#mma-168256-c "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID for ci where i < 2

   groupID + 8 for ci where i >= 2



  col = (threadID_in_group * 2) + (i & 0x1) for ci where i = {0, 1, 2, 3}
  ```

##### 9.7.14.5.14. [Multiply-and-Accumulate Instruction: `mma`](#warp-level-matrix-instructions-mma)[](#warp-level-matrix-instructions-mma "Permalink to this headline")

`mma`

Perform matrix multiply-and-accumulate operation

Syntax

Half precision floating point type:

```
mma.sync.aligned.m8n8k4.alayout.blayout.dtype.f16.f16.ctype  d, a, b, c;

mma.sync.aligned.m16n8k8.row.col.dtype.f16.f16.ctype  d, a, b, c;

mma.sync.aligned.m16n8k16.row.col.dtype.f16.f16.ctype d, a, b, c;



.alayout = {.row, .col};

.blayout = {.row, .col};

.ctype   = {.f16, .f32};

.dtype   = {.f16, .f32};
```

Alternate floating point type:

```
mma.sync.aligned.m16n8k4.row.col.f32.tf32.tf32.f32        d, a, b, c;

mma.sync.aligned.m16n8k8.row.col.f32.atype.btype.f32      d, a, b, c;

mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32       d, a, b, c;

mma.sync.aligned.shape.row.col.dtype.f8type.f8type.ctype  d, a, b, c;

mma.sync.aligned.m16n8k32.row.col.kind.dtype.f8f6f4type.f8f6f4type.ctype d, a, b, c;



.atype      = {.bf16, .tf32};

.btype      = {.bf16, .tf32};

.f8type     = {.e4m3, .e5m2};

.f8f6f4type = {.e4m3, .e5m2, .e3m2, .e2m3, .e2m1};

.ctype      = {.f16, .f32};

.dtype      = {.f16, .f32};

.shape      = {.m16n8k16, .m16n8k32};

.kind       = {.kind::f8f6f4};
```

Alternate floating point type with block scaling:

```
mma.sync.aligned.m16n8k64.row.col.kind.block_scale{.scale_vec_size}.f32.e2m1.e2m1.f32.stype d, a, b, c, scale-a-data, {byte-id-a, thread-id-a}, scale-b-data, {byte-id-b, thread-id-b};



.kind           = {.kind::mxf4};

.scale_vec_size = {.scale_vec::2X};

.stype          = {.ue8m0};



mma.sync.aligned.m16n8k64.row.col.kind.block_scale.scale_vec_size.f32.e2m1.e2m1.f32.stype d, a, b, c, scale-a-data, {byte-id-a, thread-id-a}, scale-b-data, {byte-id-b, thread-id-b};



.kind           = {.kind::mxf4nvf4};

.scale_vec_size = {.scale_vec::2X, .scale_vec::4X};

.stype          = {.ue8m0, .ue4m3};



mma.sync.aligned.m16n8k32.row.col.kind.block_scale{.scale_vec_size}.f32.f8f6f4type.f8f6f4type.f32.stype d, a, b, c, scale-a-data, {byte-id-a, thread-id-a}, scale-b-data, {byte-id-b, thread-id-b};



.kind           = {.kind::mxf8f6f4};

.scale_vec_size = {.scale_vec::1X};

.f8f6f4type     = {.e4m3, .e5m2, .e3m2, .e2m3, .e2m1};

.stype          = {.ue8m0};
```

Double precision floating point type:

```
mma.sync.aligned.shape.row.col.f64.f64.f64.f64 d, a, b, c;



.shape   = {.m8n84, .m16n8k4, .m16n8k8, .m16n8k16};
```

Integer type:

```
mma.sync.aligned.shape.row.col{.satfinite}.s32.atype.btype.s32 d, a, b, c;



.shape   = {.m8n8k16, .m16n8k16, .m16n8k32}

.atype   = {.u8, .s8};

.btype   = {.u8, .s8};



mma.sync.aligned.shape.row.col{.satfinite}.s32.atype.btype.s32 d, a, b, c;



.shape   = {.m8n8k32, .m16n8k32, .m16n8k64}

.atype   = {.u4, .s4};

.btype   = {.u4, .s4};
```

Single bit:

```
mma.sync.aligned.shape.row.col.s32.b1.b1.s32.bitOp.popc d, a, b, c;



.bitOp = {.xor, .and}

.shape = {.m8n8k128, .m16n8k128, .m16n8k256}
```

Description

Perform a `MxNxK` matrix multiply and accumulate operation, `D = A*B+C`, where the A matrix is
`MxK`, the B matrix is `KxN`, and the C and D matrices are `MxN`.

Qualifier `.block_scale` specifies that the matrices A and B are scaled with `scale_A` and
`scale_B` matrices respectively before performing the matrix multiply and accumulate operation
as specified in the section [Block Scaling](#warp-level-block-scaling). The data type
corresponding to each of the element within `scale_A` and `Scale_B` matrices is specified
by `.stype`. Qualifier `.scale_vec_size` specifies the number of columns of `scale_A` matrix
and number of rows in the matrix `scale_B`.

The valid combinations of `.kind`, `.stype` and `.scale_vec_size` are described in
[Table 36](#mma-scaling-kind-type-valid-combination). For `mma` with `.kind::mxf4` when the
qualifier `.scale_vec_size` is not specified, then it defaults to `2X`. In contrast, when
`.kind` is specified as `.kind::mxf8f6f4` then the qualifier `.scale_vec_size` defaults
to `1X`. However, for `.kind::mxf4nvf4`, it is mandatory to provide valid `.scale_vec_size`.

A warp executing `mma.sync.m8n8k4` instruction computes 4 matrix multiply and accumulate
operations. Rest of the `mma.sync` operations compute a single matrix mutliply and accumulate
operation per warp.

For single-bit `mma.sync`, multiplication is replaced by a sequence of logical operations;
specifically, `mma.xor.popc` and `mma.and.popc` computes the XOR, AND respectively of a k-bit
row of A with a k-bit column of B, then counts the number of set bits in the result (`popc`). This
result is added to the corresponding element of C and written into D.

Operands `a` and `b` represent two multiplicand matrices A and B, while `c` and `d`
represent the accumulator and destination matrices, distributed across the threads in warp.
When `.block_scale` qualifier is specified, operand `scale-a-data`, `scale-b-data` represents
the scale matrix metadata corresponding to `scale_A` and `scale_B` matrices respectively. The
tuple `{byte-id-a, thread-id-a}` and `{byte-id-b, thread-id-b}` represent selectors for matrices
`scale_A` and `scale_B` respectively from their corresponding metadata arguments `scale-a-data`,
`scale-b-data`. The operands `scale-a-data`, `scale-b-data` are of type `.b32`. The operands
`byte-id-a`, `thread-id-a`, `byte-id-b`, `thread-id-b` are unsigned 16-bit integer values.
For more details on selector arguments refer [Block Scaling](#warp-level-block-scaling) section.

The registers in each thread hold a fragment of matrix as described in
[Matrix multiply-accumulate operation using mma instruction](#warp-level-matrix-instructions-for-mma).

The qualifiers `.dtype`, `.atype`, `.btype` and `.ctype` indicate the data-type of the
elements in the matrices D, A, B and C respectively. The qualifier `.stype` indicate the data-type
of the elements in the matrices `scale_A` and `scale_B`. Specific shapes have type restrictions :

* `.m8n8k4` : When `.ctype` is `.f32`, `.dtype` must also be `.f32`.
* `.m16n8k8` :

  + `.dtype` must be the same as `.ctype`.
  + `.atype` must be the same as `.btype`.

The qualifiers `.alayout` and `.blayout` indicate the row-major or column-major layouts of
matrices A and B respectively.

When `.kind` is either of `.kind::mxf8f6f4` or `.kind::f8f6f4`, the individual 4-bit and the
6-bit floating point type elements must be packed in an 8-bit container. The matrix element of type
`.e2m1` resides in central 4 bits of the 8-bit container with padding in the upper 2 bits and
lower 2 bits of the container. When the matrix element is of type `.e3m2` or `.e2m3`, the
matrix element resides in the lower 6 bits of the 8-bit container with padding in the upper 2 bits
of the container. In contrast, note that when using `mma` with `.kind::mxf4` or
`.kind::mxf4nvf4`, no explicit padding is necessary even though matrix elements are of type `.e2m1`.

Precision and rounding :
:   * `.f16` floating point operations:

      Element-wise multiplication of matrix A and B is performed with at least single
      precision. When `.ctype` or `.dtype` is `.f32`, accumulation of the intermediate values
      is performed with at least single precision. When both `.ctype` and `.dtype` are specified
      as `.f16`, the accumulation is performed with at least half precision.

      The accumulation order, rounding and handling of subnormal inputs are unspecified.
    * `.e4m3`, `.e5m2`, `.e3m2`, `.e2m3`, `.e2m1` floating point operations :

      Element-wise multiplication of matrix A and B is performed with specified precision. Accumulation
      of the intermediate values is performed with at least single precision.

      The accumulation order, rounding, and handling of subnormal inputs are unspecified.
    * `.bf16` and `.tf32` floating point operations :

      Element-wise multiplication of matrix A and B is performed with specified
      precision. Accumulation of the intermediate values is performed with at least single
      precision.

      The accumulation order, rounding, and handling of subnormal inputs are unspecified.
    * `.f64` floating point operations :

      Precision of the element-wise multiplication and addition operation is identical to that of `.f64`
      precision fused multiply-add. Supported rounding modifiers are :

      + `.rn` : mantissa LSB rounds to nearest even. This is the default.
      + `.rz` : mantissa LSB rounds towards zero.
      + `.rm` : mantissa LSB rounds towards negative infinity.
      + `.rp` : mantissa LSB rounds towards positive infinity.
    * Integer operations :

      The integer `mma` operation is performed with `.s32` accumulators. The `.satfinite`
      qualifier indicates that on overflow, the accumulated value is limited to the range
      *MIN\_INT32*.. *MAX\_INT32* (where the bounds are defined as the minimum negative signed 32-bit
      integer and the maximum positive signed 32-bit integer respectively).

      If `.satfinite` is not specified, the accumulated value is wrapped instead.

The mandatory `.sync` qualifier indicates that `mma` instruction causes the executing thread to
wait until all threads in the warp execute the same `mma` instruction before resuming execution.

The mandatory `.aligned` qualifier indicates that all threads in the warp must execute the same
`mma` instruction. In conditionally executed code, a `mma` instruction should only be used if it
is known that all threads in the warp evaluate the condition identically, otherwise behavior is
undefined.

The behavior of `mma` instruction is undefined if all threads in the same warp do not use the same
qualifiers, or if any thread in the warp has exited.

Notes

Programs using double precision floating point `mma` instruction with shapes `.m16n8k4`,
`.m16n8k8`, and `.m16n8k16` require at least 64 registers for compilation.

PTX ISA Notes

Introduced in PTX ISA version 6.4.

`.f16` floating point type `mma` operation with `.m8n8k4` shape introduced in PTX ISA version
6.4.

`.f16` floating point type `mma` operation with `.m16n8k8` shape introduced in PTX ISA version
6.5.

`.u8/.s8` integer type `mma` operation with `.m8n8k16` shape introduced in PTX ISA version
6.5.

`.u4/.s4` integer type `mma` operation with `.m8n8k32` shape introduced in PTX ISA version
6.5.

`.f64` floating point type `mma` operation with `.m8n8k4` shape introduced in PTX ISA version
7.0.

`.f16` floating point type `mma` operation with `.m16n8k16` shape introduced in PTX ISA
version 7.0.

`.bf16` alternate floating point type `mma` operation with `.m16n8k8` and `.m16n8k16` shapes
introduced in PTX ISA version 7.0.

`.tf32` alternate floating point type `mma` operation with `.m16n8k4` and `.m16n8k8` shapes
introduced in PTX ISA version 7.0.

`.u8/.s8` integer type `mma` operation with `.m16n8k16` and `.m16n8k32` shapes introduced in
PTX ISA version 7.0.

`.u4/.s4` integer type `mma` operation with `.m16n8k32` and `.m16n8k64` shapes introduced in
PTX ISA version 7.0.

`.b1` single-bit integer type `mma` operation with `.m8n8k128`, `.m16n8k128` and
`.m16n8k256` shapes introduced in PTX ISA version 7.0.

Support for `.and` operation in single-bit `mma` introduced in PTX ISA version 7.1.

`.f64` floating point type `mma` operation with `.m16n8k4`, `.m16n8k8`, and `.m16n8k16`
shapes introduced in PTX ISA version 7.8.

Support for `.e4m3` and `.e5m2` alternate floating point type `mma` operation introduced in
PTX ISA version 8.4.

Support for shape `.m16n8k16` and `.f16` `dtype`/`ctype` with `.e4m3`/`.e5m2` alternate
floating point type mma operation introduced in PTX ISA version 8.7.

Support for `.e3m2`, `.e2m3`, `.e2m1` alternate floating point type `mma` operation introduced
in PTX ISA version 8.7.

Support for `.kind`, `.block_scale`, `.scale_vec_size` qualifier introduced in PTX ISA version 8.7.

Target ISA Notes

Requires `sm_70` or higher.

`.f16` floating point type `mma` operation with `.m8n8k4` shape requires `sm_70` or higher.

Note

`mma.sync.m8n8k4` is optimized for target architecture `sm_70` and may have substantially
reduced performance on other target architectures.

`.f16` floating point type `mma` operation with `.m16n8k8` shape requires `sm_75` or higher.

`.u8/.s8` integer type `mma` operation with `.m8n8k16` shape requires `sm_75` or higher.

`.u4/.s4` integer type `mma` operation with `.m8n8k32` shape `sm_75` or higher.

`.b1` single-bit integer type `mma` operation with `.m8n8k128` shape `sm_75` or higher.

`.f64` floating point type `mma` operation with `.m8n8k4` shape requires `sm_80` or higher.

`.f16` floating point type `mma` operation with `.m16n8k16` shape requires `sm_80` or
higher.

`.bf16` alternate floating point type `mma` operation with `.m16n8k8` and `.m16n8k16` shapes
requires `sm_80` or higher.

`.tf32` alternate floating point type `mma` operation with `.m16n8k4` and `.m16n8k8` shapes
requires `sm_80` or higher.

`.u8/.s8` integer type `mma` operation with `.m16n8k16` and `.m16n8k32` shapes requires
`sm_80` or higher.

`.u4/.s4` integer type `mma` operation with `.m16n8k32` and `.m16n8k64` shapes requires
`sm_80` or higher.

`.b1` single-bit integer type `mma` operation with `.m16n8k128` and `.m16n8k256` shapes
requires `sm_80` or higher.

`.and` operation in single-bit `mma` requires `sm_80` or higher.

`.f64` floating point type `mma` operation with `.m16n8k4`, `.m16n8k8`, and `.m16n8k16`
shapes require `sm_90` or higher.

`.e4m3` and `.e5m2` alternate floating point type `mma` operation requires `sm_89` or higher.

`.e3m2`, `.e2m3` and `.e2m1` alternate floating point type `mma` operation requires `sm_120a`
and is supported on `sm_120f` from PTX ISA version 8.8.

Support for `.kind`, `.block_scale`, `.scale_vec_size` qualifier requires `sm_120a` and are
supported on `sm_120f` or higher in the same family from PTX ISA version 8.8.

Examples of half precision floating point type

```
// f16 elements in C and D matrix

.reg .f16x2 %Ra<2> %Rb<2> %Rc<4> %Rd<4>

mma.sync.aligned.m8n8k4.row.col.f16.f16.f16.f16

{%Rd0, %Rd1, %Rd2, %Rd3},

{%Ra0, %Ra1},

{%Rb0, %Rb1},

{%Rc0, %Rc1, %Rc2, %Rc3};





// f16 elements in C and f32 elements in D

.reg .f16x2 %Ra<2> %Rb<2> %Rc<4>

.reg .f32 %Rd<8>

mma.sync.aligned.m8n8k4.row.col.f32.f16.f16.f16

{%Rd0, %Rd1, %Rd2, %Rd3, %Rd4, %Rd5, %Rd6, %Rd7},

{%Ra0, %Ra1},

{%Rb0, %Rb1},

{%Rc0, %Rc1, %Rc2, %Rc3};



 // f32 elements in C and D

.reg .f16x2 %Ra<2>, %Rb<1>;

.reg .f32 %Rc<4>, %Rd<4>;

mma.sync.aligned.m16n8k8.row.col.f32.f16.f16.f32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1},

  {%Rb0},

  {%Rc0, %Rc1, %Rc2, %Rc3};



.reg .f16x2 %Ra<4>, %Rb<2>, %Rc<2>, %Rd<2>;

mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16

  {%Rd0, %Rd1},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1};



.reg .f16 %Ra<4>, %Rb<2>;

.reg .f32 %Rc<2>, %Rd<2>;

mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1, %Rc2, %Rc3};
```

Examples of alternate floating point type

```
.reg .b32 %Ra<2>, %Rb<1>;

.reg .f32 %Rc<4>, %Rd<4>;

mma.sync.aligned.m16n8k4.row.col.f32.tf32.tf32.f32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1},

  {%Rb0},

  {%Rc0, %Rc1, %Rc2, %Rc3};



.reg .f16x2 %Ra<2>, %Rb<1>;

.reg .f32 %Rc<4>, %Rd<4>;

mma.sync.aligned.m16n8k8.row.col.f32.bf16.bf16.f32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1},

  {%Rb0},

  {%Rc0, %Rc1, %Rc2, %Rc3};



.reg .b32 %Ra<2>, %Rb<1>;

.reg .f32 %Rc<4>, %Rd<4>;

mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Rb2, %Rb3},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1, %Rc2, %Rc3};



.reg .f16x2 %Ra<2>, %Rb<1>;

.reg .f32 %Rc<4>, %Rd<4>;

mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1, %Rc2, %Rc3};



.reg .b32 %Ra<4>, %Rb<4>;

.reg .f32 %Rc<4>, %Rd<4>;

mma.sync.aligned.m16n8k32.row.col.f32.e4m3.e5m2.f32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1, %Rc2, %Rc3};



.reg .b32 %Ra<4>, %Rb<4>;

.reg .f32 %Rc<4>, %Rd<4>;

mma.sync.aligned.m16n8k16.row.col.f32.e5m2.e4m3.f32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1},

  {%Rb0},

  {%Rc0, %Rc1, %Rc2, %Rc3};



.reg .b32 %Ra<4>, %Rb<4>;

.reg .b32 %Rc<4>, %Rd<4>;

mma.sync.aligned.m16n8k32.row.col.f16.e4m3.e5m2.f16

  {%Rd0, %Rd1},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1};



.reg .b32 %Ra<4>, %Rb<4>;

.reg .b32 %Rc<4>, %Rd<4>;

mma.sync.aligned.m16n8k16.row.col.f16.e5m2.e5m2.f16

  {%Rd0, %Rd1},

  {%Ra0, %Ra1},

  {%Rb0},

  {%Rc0, %Rc1};



.reg .b32 %Ra<4>, %Rb<4>;

.reg .f32 %Rc<4>, %Rd<4>;

mma.sync.aligned.m16n8k32.row.col.kind::f8f6f4.f32.e3m2.e2m3.f32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1, %Rc2, %Rc3};



.reg .b32 %Ra<4>, %Rb<4>;

.reg .b32 %Rc<4>, %Rd<4>;

mma.sync.aligned.m16n8k32.row.col.kind::f8f6f4.f16.e2m3.e2m1.f16

  {%Rd0, %Rd1},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1};
```

Examples of integer type

```
.reg .b32 %Ra, %Rb, %Rc<2>, %Rd<2>;



// s8 elements in A and u8 elements in B

mma.sync.aligned.m8n8k16.row.col.satfinite.s32.s8.u8.s32

  {%Rd0, %Rd1},

  {%Ra},

  {%Rb},

  {%Rc0, %Rc1};



// u4 elements in A and B matrix

mma.sync.aligned.m8n8k32.row.col.satfinite.s32.u4.u4.s32

  {%Rd0, %Rd1},

  {%Ra},

  {%Rb},

  {%Rc0, %Rc1};



// s8 elements in A and u8 elements in B

.reg .b32 %Ra<2>, %Rb, %Rc<4>, %Rd<4>;

mma.sync.aligned.m16n8k16.row.col.satfinite.s32.s8.u8.s32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1},

  {%Rb},

  {%Rc0, %Rc1, %Rc2, %Rc3};



// u4 elements in A and s4 elements in B

.reg .b32 %Ra<2>, %Rb, %Rc<4>, %Rd<4>;

mma.sync.aligned.m16n8k32.row.col.satfinite.s32.u4.s4.s32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1},

  {%Rb},

  {%Rc0, %Rc1, %Rc2, %Rc3};



// s8 elements in A and s8 elements in B

.reg .b32 %Ra<4>, %Rb<2>, %Rc<4>, %Rd<4>;

mma.sync.aligned.m16n8k32.row.col.satfinite.s32.s8.s8.s32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1, %Rc2, %Rc3};



// u8 elements in A and u8 elements in B

.reg .b32 %Ra<4>, %Rb<2>, %Rc<4>, %Rd<4>;

mma.sync.aligned.m16n8k64.row.col.satfinite.s32.u4.u4.s32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1 },

  {%Rc0, %Rc1, %Rc2, %Rc3};
```

Examples of single bit type

```
// b1 elements in A and B

.reg .b32 %Ra, %Rb, %Rc<2>, %Rd<2>;

mma.sync.aligned.m8n8k128.row.col.s32.b1.b1.s32.and.popc

  {%Rd0, %Rd1},

  {%Ra},

  {%Rb},

  {%Rc0, %Rc1};



// b1 elements in A and B

.reg .b32 %Ra, %Rb, %Rc<2>, %Rd<2>;

mma.sync.aligned.m8n8k128.row.col.s32.b1.b1.s32.xor.popc

  {%Rd0, %Rd1},

  {%Ra},

  {%Rb},

  {%Rc0, %Rc1};



.reg .b32 %Ra<2>, %Rb, %Rc<4>, %Rd<4>;

mma.sync.aligned.m16n8k128.row.col.s32.b1.b1.s32.xor.popc

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1},

  {%Rb},

  {%Rc0, %Rc1, %Rc2, %Rc3};



.reg .b32 %Ra<2>, %Rb, %Rc<4>, %Rd<4>;

mma.sync.aligned.m16n8k128.row.col.s32.b1.b1.s32.and.popc

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1},

  {%Rb},

  {%Rc0, %Rc1, %Rc2, %Rc3};



.reg .b32 %Ra<4>, %Rb<2>, %Rc<4>, %Rd<4>;

mma.sync.aligned.m16n8k256.row.col.s32.b1.b1.s32.xor.popc

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1, %Rc2, %Rc3};



.reg .b32 %Ra<4>, %Rb<2>, %Rc<4>, %Rd<4>;

mma.sync.aligned.m16n8k256.row.col.s32.b1.b1.s32.and.popc

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1, %Rc2, %Rc3};
```

Examples of `.f64` floating point type

```
.reg .f64 %Ra, %Rb, %Rc<2>, %Rd<2>;

mma.sync.aligned.m8n8k4.row.col.f64.f64.f64.f64

  {%Rd0, %Rd1},

  {%Ra},

  {%Rb},

  {%Rc0, %Rc1};



.reg .f64 %Ra<8>, %Rb<4>, %Rc<4>, %Rd<4>;

mma.sync.aligned.m16n8k4.row.col.f64.f64.f64.f64.rn

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1},

  {%Rb0},

  {%Rc0, %Rc1, %Rc2, %Rc3};



mma.sync.aligned.m16n8k8.row.col.f64.f64.f64.f64.rn

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1, %Rc2, %Rc3};



mma.sync.aligned.m16n8k16.row.col.f64.f64.f64.f64.rn

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2, %Ra3, %Ra4, %Ra5, %Ra6, %Ra7},

  {%Rb0, %Rb1, %Rb2, %Rb3},

  {%Rc0, %Rc1, %Rc2, %Rc3};
```

Examples of `mma` with block scale

```
.reg .b32 %Ra<4>, %Rb<4>;

.reg .f32 %Rc<4>, %Rd<4>;

.reg .b32 scaleAData, scaleBData;

mma.sync.aligned.m16n8k64.row.col.kind::mxf4.block_scale.f32.e2m1.e2m1.f32.ue8m0

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1, %Rc2, %Rc3},

  scaleAData, {2, 1}, scaleBData, {2, 3};



.reg .b32 %Ra<4>, %Rb<4>;

.reg .f32 %Rc<4>, %Rd<4>;

.reg .b32 scaleAData, scaleBData;

.reg .u16 bidA, bidB, tidA, tidB;

mma.sync.aligned.m16n8k64.row.col.kind::mxf4nvf4.block_scale.scale_vec::4X.f32.e2m1.e2m1.f32.ue4m3

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1, %Rc2, %Rc3},

  scaleAData, {bidA, tidA}, scaleBData, {bidB, tidB};



.reg .b32 %Ra<4>, %Rb<4>;

.reg .f32 %Rc<4>, %Rd<4>;

.reg .b32 scaleAData, scaleBData;

mma.sync.aligned.m16n8k32.row.col.kind::mxf8f6f4.block_scale.scale_vec::1X.f32.e3m2.e2m1.f32.ue8m0

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1, %Rc2, %Rc3},

  scaleAData, {0, 1}, scaleBData, {0, 1};



.reg .b32 %Ra<4>, %Rb<4>;

.reg .f32 %Rc<4>, %Rd<4>;

.reg .b32 scaleAData, scaleBData;

mma.sync.aligned.m16n8k32.row.col.kind::mxf8f6f4.block_scale.scale_vec::1X.f32.e4m3.e5m2.f32.ue8m0

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2,  %Ra3},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1, %Rc2, %Rc3},

  scaleAData, {0, 1}, scaleBData, {0, 0};
```

##### 9.7.14.5.15. [Warp-level matrix load instruction: `ldmatrix`](#warp-level-matrix-instructions-ldmatrix)[](#warp-level-matrix-instructions-ldmatrix "Permalink to this headline")

`ldmatrix`

Collectively load one or more matrices from shared memory for `mma` instruction

Syntax

```
ldmatrix.sync.aligned.shape.num{.trans}{.ss}.type r, [p];



ldmatrix.sync.aligned.m8n16.num{.ss}.dst_fmt.src_fmt        r, [p];

ldmatrix.sync.aligned.m16n16.num.trans{.ss}.dst_fmt.src_fmt r, [p];



.shape   = {.m8n8, .m16n16};

.num     = {.x1, .x2, .x4};

.ss      = {.shared{::cta}};

.type    = {.b16, .b8};

.dst_fmt = { .b8x16 };

.src_fmt = { .b6x16_p32, .b4x16_p64 };
```

Description

Collectively load one or more matrices across all threads in a warp from the location indicated by
the address operand `p`, from `.shared` state space into destination register `r`. If no state
space is provided, generic addressing is used, such that the address in `p` points into
`.shared` space. If the generic address doesn’t fall in `.shared` state space, then the behavior
is undefined.

The `.shape` qualifier indicates the dimensions of the matrices being loaded. Each matrix element
holds 16-bit or 8-bit or 6-bit or 4-bit data.

Following table shows the matrix load case for each `.shape`.

| .shape | Matrix shape | Element size |
| --- | --- | --- |
| `.m8n8` | 8x8 | 16-bit |
| `.m16n16` | 16x16 | 8-bit or 6-bit or 4-bit |
| `.m8n16` | 8x16 | 6-bit or 4-bit |

Following table shows the valid use of 6-bit or 4-bit data load.

| .src\_fmt | .shape | Source data | Padding | .dst\_fmt |
| --- | --- | --- | --- | --- |
| `.b6x16_p32` | `.m8n16` | 16 6-bit elements | 32 bits | `.b8x16` (16 8-bit elements) |
| `.m16n16` |
| `.b4x16_p64` | `.m8n16` | 16 4-bit elements | 64 bits |
| `.m16n16` |

For `.b6x16_p32` format source data is 16 unsigned 6-bit elements with 32 bits padding.
For `.b4x16_p64` format source data is 16 unsigned 4-bit elements with 64 bits padding.

The values `.x1`, `.x2` and `.x4` for `.num` indicate one, two or four matrices
respectively. When `.shape` is `.m16n16`, only `.x1` and `.x2` are valid values for `.num`.

The mandatory `.sync` qualifier indicates that `ldmatrix` causes the executing thread to wait
until all threads in the warp execute the same `ldmatrix` instruction before resuming execution.

The mandatory `.aligned` qualifier indicates that all threads in the warp must execute the same
`ldmatrix` instruction. In conditionally executed code, an `ldmatrix` instruction should only be
used if it is known that all threads in the warp evaluate the condition identically, otherwise the
behavior is undefined.

The behavior of `ldmatrix` is undefined if all threads do not use the same qualifiers, or if any
thread in the warp has exited.

The destination operand `r` is a brace-enclosed vector expression consisting of 1, 2, or 4 32-bit
registers as per the value of `.num`. Each component of the vector expression holds a fragment
from the corresponding matrix.

Supported addressing modes for `p` are described in [Addresses as Operands](#addresses-as-operands).

Consecutive instances of row need not be stored contiguously in memory. The eight addresses required
for each matrix are provided by eight threads, depending upon the value of `.num` as shown in the
following table. Each address corresponds to the start of a matrix row. Addresses addr0–addr7
correspond to the rows of the first matrix, addresses addr8–addr15 correspond to the rows of the
second matrix, and so on.

| `.num` | Threads 0–7 | Threads 8–15 | Threads 16–23 | Threads 24–31 |
| --- | --- | --- | --- | --- |
| `.x1` | addr0–addr7 | – | – | – |
| `.x2` | addr0–addr7 | addr8–addr15 | – | – |
| `.x4` | addr0–addr7 | addr8–addr15 | addr16–addr23 | addr24–addr31 |

Note

For .target `sm_75` or below, all threads must contain valid addresses. Otherwise, the behavior
is undefined. For `.num = .x1` and `.num = .x2`, addresses contained in lower threads can be
copied to higher threads to achieve the expected behavior.

When reading 8x8 matrices, a group of four consecutive threads loads 16 bytes. The matrix addresses
must be naturally aligned accordingly.

Each thread in a warp loads fragments of a row, with thread 0 receiving the first fragment in its
register `r`, and so on. A group of four threads loads an entire row of the matrix as shown in
[Figure 104](#mma-ldmatrix-fragments).

![_images/mma-ldmatrix-fragments.png](_images/mma-ldmatrix-fragments.png)


Figure 104 ldmatrix fragment layout for one 8x8 Matrix with 16-bit elements[](#mma-ldmatrix-fragments "Permalink to this image")

When `.num` = `.x2`, the elements of the second matrix are loaded in the next destination
register in each thread as per the layout in above table. Similarly, when `.num` = `.x4`,
elements of the third and fourth matrices are loaded in the subsequent destination registers in each
thread.

For matrix shape 16x16, two destination registers `r0` and `r1` of type `.b32` must be
specified and in each register four 8-bit elements are loaded. For 4-bit or 6-bit data, 8-bit
element will have 4 bits or 2 bits of padding respectively.
Refer [Optional Decompression](#tcgen05-optional-decompression) for more details
on these formats.

An entire row of the matrix can be loaded by a group of four consecutive and aligned threads.
Each thread in a warp loads 4 consecutive columns across 2 rows as shown in the
[Figure 105](#mma-ldmatrix-fragments-1616).

![_images/mma-ldmatrix-fragments-1616.png](_images/mma-ldmatrix-fragments-1616.png)


Figure 105 ldmatrix fragment layout for one 16x16 matrix with 8-bit elements[](#mma-ldmatrix-fragments-1616 "Permalink to this image")

For matrix shape 8x16, one destination register `r0` of type `.b32` must be specified where four
8-bit elements are loaded in the register. For 4-bit or 6-bit data, 8-bit element will have 4 bits
or 2 bits of padding respectively.

An entire row of the matrix can be loaded by a group of four consecutive and aligned threads.
Each thread in a warp loads 4 consecutive columns as shown in [Figure 106](#mma-ldmatrix-fragments-816).

![_images/mma-ldmatrix-fragments-816.png](_images/mma-ldmatrix-fragments-816.png)


Figure 106 ldmatrix fragment layout for one 8x16 matrix with 8-bit elements containing 4-bit/6-bit data[](#mma-ldmatrix-fragments-816 "Permalink to this image")

Optional qualifier `.trans` indicates that the matrix is loaded in column-major format. However,
for 16x16 matrices, `.trans` is mandatory.

The `ldmatrix` instruction is treated as a weak memory operation in the [Memory Consistency Model](#memory-consistency-model).

PTX ISA Notes

Introduced in PTX ISA version 6.5.

Support for `::cta` sub-qualifier introduced in PTX ISA version 7.8.

Support for `.m16n16`, `.m8n16` shapes introduced in PTX ISA version 8.6.

Support for `.b8` type with `ldmatrix` is introduced in PTX ISA version 8.6.

Support for `.src_fmt`, `.dst_fmt` qualifiers introduced in PTX ISA version 8.6.

Target ISA Notes

Requires `sm_75` or higher.

Shapes `.m16n16`, `.m8n16` are supported on following architectures:

* `sm_100a`
* `sm_101a` (Renamed to `sm_110a` from PTX ISA version 9.0)
* `sm_120a`
* And are supported on following family-specific architectures from PTX ISA version 8.8:

  > + `sm_100f` or higher in the same family
  > + `sm_101f` or higher in the same family (Renamed to `sm_110f` from PTX ISA version 9.0)
  > + `sm_120f` or higher in the same family
* `sm_110f` or higher in the same family

Type `.b8` with `ldmatrix` is supported on following architectures:

* `sm_100a`
* `sm_101a` (Renamed to `sm_110a` from PTX ISA version 9.0)
* `sm_120a`
* And are supported on following family-specific architectures from PTX ISA version 8.8:

  > + `sm_100f` or higher in the same family
  > + `sm_101f` or higher in the same family (Renamed to `sm_110f` from PTX ISA version 9.0)
  > + `sm_120f` or higher in the same family
* `sm_110f` or higher in the same family

Qualifiers `.src_fmt`, `.dst_fmt` are supported on following architectures:

* `sm_100a`
* `sm_101a` (Renamed to `sm_110a` from PTX ISA version 9.0)
* `sm_120a`
* And are supported on following family-specific architectures from PTX ISA version 8.8:

  > + `sm_100f` or higher in the same family
  > + `sm_101f` or higher in the same family (Renamed to `sm_110f` from PTX ISA version 9.0)
  > + `sm_120f` or higher in the same family
* `sm_110f` or higher in the same family

Examples

```
// Load a single 8x8 matrix using 64-bit addressing

.reg .b64 addr;

.reg .b32 d;

ldmatrix.sync.aligned.m8n8.x1.shared::cta.b16 {d}, [addr];



// Load two 8x8 matrices in column-major format

.reg .b64 addr;

.reg .b32 d<2>;

ldmatrix.sync.aligned.m8n8.x2.trans.shared.b16 {d0, d1}, [addr];



// Load four 8x8 matrices

.reg .b64 addr;

.reg .b32 d<4>;

ldmatrix.sync.aligned.m8n8.x4.b16 {d0, d1, d2, d3}, [addr];



// Load one 16x16 matrices of 64-bit elements and transpose them

.reg .b64 addr;

.reg .b32 d<2>;

ldmatrix.sync.aligned.m16n16.x1.trans.shared.b8 {d0, d1}, [addr];



// Load two 16x16 matrices of 64-bit elements and transpose them

.reg .b64 addr;

.reg .b32 d<4>;

ldmatrix.sync.aligned.m16n16.x2.trans.shared::cta.b8 {d0, d1, d2, d3}, [addr];



// Load two 16x16 matrices of 6-bit elements and transpose them

.reg .b64 addr;

.reg .b32 d<4>;

ldmatrix.sync.aligned.m16n16.x2.trans.shared::cta.b8x16.b6x16_p32 {d0, d1, d2, d3}, [addr];
```

##### 9.7.14.5.16. [Warp-level matrix store instruction: `stmatrix`](#warp-level-matrix-instructions-stmatrix)[](#warp-level-matrix-instructions-stmatrix "Permalink to this headline")

`stmatrix`

Collectively store one or more matrices to shared memory.

Syntax

```
stmatrix.sync.aligned.shape.num{.trans}{.ss}.type [p], r;



.shape  = {.m8n8, .m16n8};

.num    = {.x1, .x2, .x4};

.ss     = {.shared{::cta}};

.type   = {.b16, .b8};
```

Description

Collectively store one or more matrices across all threads in a warp to the location indicated by
the address operand `p`, in `.shared` state space. If no state space is provided, generic
addressing is used, such that the address in `p` points into `.shared` space. If the generic
address doesn’t fall in `.shared` state space, then the behavior is undefined.

The `.shape` qualifier indicates the dimensions of the matrices being loaded. Each matrix element
holds 16-bit or 8-bit data as indicated by the `.type` qualifier.

`.m16n8` shape is valid only for `.b8` type.

The values `.x1`, `.x2` and `.x4` for `.num` indicate one, two or four matrices
respectively.

The mandatory `.sync` qualifier indicates that `stmatrix` causes the executing thread to wait
until all threads in the warp execute the same `stmatrix` instruction before resuming execution.

The mandatory `.aligned` qualifier indicates that all threads in the warp must execute the same
`stmatrix` instruction. In conditionally executed code, an `stmatrix` instruction should only be
used if it is known that all threads in the warp evaluate the condition identically, otherwise the
behavior is undefined.

The behavior of `stmatrix` is undefined if all threads do not use the same qualifiers, or if any
thread in the warp has exited.

The source operand `r` is a brace-enclosed vector expression consisting of 1, 2, or 4 32-bit
registers as per the value of `.num`. Each component of the vector expression holds a fragment
from the corresponding matrix.

Supported addressing modes for `p` are described in [Addresses as Operands](#addresses-as-operands).

Consecutive instances of row need not be stored contiguously in memory. The eight addresses required
for each matrix are provided by eight threads, depending upon the value of `.num` as shown in the
following table. Each address corresponds to the start of a matrix row. Addresses addr0–addr7
correspond to the rows of the first matrix, addresses addr8–addr15 correspond to the rows of the
second matrix, and so on.

| `.num` | Threads 0–7 | Threads 8–15 | Threads 16–23 | Threads 24–31 |
| --- | --- | --- | --- | --- |
| `.x1` | addr0–addr7 | – | – | – |
| `.x2` | addr0–addr7 | addr8–addr15 | – | – |
| `.x4` | addr0–addr7 | addr8–addr15 | addr16–addr23 | addr24–addr31 |

When storing 8x8 matrices, a group of four consecutive threads stores 16 bytes. The matrix addresses
must be naturally aligned accordingly.

Each thread in a warp stores fragments of a row, with thread 0 storing the first fragment from its
register `r`, and so on. A group of four threads stores an entire row of the matrix as shown in
[Figure 107](#mma-stmatrix-fragments).

![_images/mma-stmatrix-fragments.png](_images/mma-stmatrix-fragments.png)


Figure 107 stmatrix fragment layout for one 8x8 matrix with 16-bit elements[](#mma-stmatrix-fragments "Permalink to this image")

When `.num` = `.x2`, the elements of the second matrix are storedd from the next source register
in each thread as per the layout in above table. Similarly, when `.num` = `.x4`, elements of the
third and fourth matrices are stored from the subsequent source registers in each thread.

For 16x8 matrix shape, each of the 32 threads in the warp provides four elements of data per matrix.

Each element in the source operand `r` is of type `.b32` and contains four 8 bit elements `e0`,
`e1`, `e2`, `e3` with `e0` and `e3` containing the LSB and MSB respectively of register `r`.

![_images/mma-stmatrix-fragments-168.png](_images/mma-stmatrix-fragments-168.png)


Figure 108 stmatrix fragment layout for one 16x8 matrix with 8 bit elements[](#mma-stmatrix-fragments-168 "Permalink to this image")

Optional qualifier `.trans` indicates that the matrix is stored in column-major format. However,
for 16x8 matrices, `.trans` is mandatory.

The `stmatrix` instruction is treated as a weak memory operation in the [Memory Consistency Model](#memory-consistency-model).

PTX ISA Notes

Introduced in PTX ISA version 7.8.

Support for `.m16n8` shape is introduced in PTX ISA version 8.6.

Support for `.b8` type with `stmatrix` is introduced in PTX ISA version 8.6.

Target ISA Notes

Requires `sm_90` or higher.

Shape `.m16n8` is supported on following architectures:

* `sm_100a`
* `sm_101a` (Renamed to `sm_110a` from PTX ISA version 9.0)
* `sm_120a`
* And is supported on following family-specific architectures from PTX ISA version 8.8:

  > + `sm_100f` or higher in the same family
  > + `sm_101f` or higher in the same family (Renamed to `sm_110f` from PTX ISA version 9.0)
  > + `sm_120f` or higher in the same family
* `sm_110f` or higher in the same family

Type `.b8` with `stmatrix` is supported on following architectures:

* `sm_100a`
* `sm_101a` (Renamed to `sm_110a` from PTX ISA version 9.0)
* `sm_120a`
* And is supported on following family-specific architectures from PTX ISA version 8.8:

  > + `sm_100f` or higher in the same family
  > + `sm_101f` or higher in the same family (Renamed to `sm_110f` from PTX ISA version 9.0)
  > + `sm_120f` or higher in the same family
* `sm_110f` or higher in the same family

Examples

```
// Store a single 8x8 matrix using 64-bit addressing

.reg .b64 addr;

.reg .b32 r;

stmatrix.sync.aligned.m8n8.x1.shared.b16 [addr], {r};



// Store two 8x8 matrices in column-major format

.reg .b64 addr;

.reg .b32 r<2>;

stmatrix.sync.aligned.m8n8.x2.trans.shared::cta.b16 [addr], {r0, r1};



// Store four 8x8 matrices

.reg .b64 addr;

.reg .b32 r<4>;

stmatrix.sync.aligned.m8n8.x4.b16 [addr], {r0, r1, r2, r3};



// Store a single 16x8 matrix using generic addressing

.reg .b64 addr;

.reg .b32 r;

stmatrix.sync.aligned.m16n8.x1.trans.shared.b8 [addr], {r};



// Store two 16x8 matrices

.reg .b64 addr;

.reg .b32 r<2>;

stmatrix.sync.aligned.m16n8.x2.trans.shared::cta.b8 [addr],{r0, r1};



// Store four 16x8 matrices

.reg .b64 addr;

.reg .b32 r<4>;

stmatrix.sync.aligned.m16n8.x4.b8 [addr], {r0, r1, r2, r3};
```

##### 9.7.14.5.17. [Warp-level matrix transpose instruction: `movmatrix`](#warp-level-matrix-instructions-movmatrix)[](#warp-level-matrix-instructions-movmatrix "Permalink to this headline")

`movmatrix`

Transpose a matrix in registers across the warp.

Syntax

```
movmatrix.sync.aligned.shape.trans.type d, a;



.shape  = {.m8n8};

.type   = {.b16};
```

Description

Move a row-major matrix across all threads in a warp, reading elements from source `a`, and
writing the transposed elements to destination `d`.

The `.shape` qualifier indicates the dimensions of the matrix being transposed. Each matrix
element holds 16-bit data as indicated by the `.type` qualifier.

The mandatory `.sync` qualifier indicates that `movmatrix` causes the executing thread to wait
until all threads in the warp execute the same `movmatrix` instruction before resuming execution.

The mandatory `.aligned` qualifier indicates that all threads in the warp must execute the same
`movmatrix` instruction. In conditionally executed code, a `movmatrix` instruction should only
be used if it is known that all threads in the warp evaluate the condition identically, otherwise
the behavior is undefined.

Operands `a` and `d` are 32-bit registers containing fragments of the input matrix and the
resulting matrix respectively. The mandatory qualifier `.trans` indicates that the resulting
matrix in `d` is a transpose of the input matrix specified by `a`.

Each thread in a warp holds a fragment of a row of the input matrix, with thread 0 holding the first
fragment in register `a`, and so on. A group of four threads holds an entire row of the input
matrix as shown in [Figure 109](#mma-movmatrix-fragments-src).

![_images/mma-movmatrix-fragments-src.png](_images/mma-movmatrix-fragments-src.png)


Figure 109 movmatrix source matrix fragment layout[](#mma-movmatrix-fragments-src "Permalink to this image")

Each thread in a warp holds a fragment of a column of the result matrix, with thread 0 holding the
first fragment in register `d`, and so on. A group of four threads holds an entire column of the
result matrix as shown in [Figure 110](#mma-movmatrix-fragments-dst).

![_images/mma-movmatrix-fragments-dst.png](_images/mma-movmatrix-fragments-dst.png)


Figure 110 movmatrix result matrix fragment layout[](#mma-movmatrix-fragments-dst "Permalink to this image")

PTX ISA Notes

Introduced in PTX ISA version 7.8.

Target ISA Notes

Requires `sm_75` or higher.

Examples

```
.reg .b32 d, a;

movmatrix.sync.aligned.m8n8.trans.b16 d, a;
```

#### 9.7.14.6. [Matrix multiply-accumulate operation using `mma.sp` instruction with sparse matrix A](#warp-level-matrix-instructions-for-sparse-mma)[](#warp-level-matrix-instructions-for-sparse-mma "Permalink to this headline")

This section describes warp-level `mma.sp{::ordered_metadata}` instruction with sparse matrix A.
This variant of the `mma` operation can be used when A is a structured sparse matrix with 50%
zeros in each row distributed in a shape-specific granularity. For an `MxNxK` sparse
`mma.sp{::ordered_metadata}` operation, the `MxK` matrix A is packed into `MxK/2` elements.
For each K-wide row of matrix A, 50% elements are zeros and the remaining K/2 non-zero elements
are packed in the operand representing matrix A. The mapping of these K/2 elements to the
corresponding K-wide row is provided explicitly as metadata.

##### 9.7.14.6.1. [Sparse matrix storage](#warp-level-sparse-matrix-storage)[](#warp-level-sparse-matrix-storage "Permalink to this headline")

Granularity of sparse matrix A is defined as the ratio of the number of non-zero elements in a
sub-chunk of the matrix row to the total number of elements in that sub-chunk where the size of the
sub-chunk is shape-specific. For example, in a `16x16` matrix A, sparsity is expected to be at 2:4
granularity, i.e. each 4-element vector (i.e. a sub-chunk of 4 consecutive elements) of a matrix row
contains 2 zeros. Index of each non-zero element in a sub-chunk is stored in the metadata
operand. Values `0b0000`, `0b0101`, `0b1010`, `0b1111` are invalid values for metadata and
will result in undefined behavior. In a group of four consecutive threads, one or more threads store
the metadata for the whole group depending upon the matrix shape. These threads are specified using
an additional *sparsity selector* operand.

[Figure 111](#sparse-mma-storage-example) shows an example of a 16x16 matrix A represented in sparse format and sparsity
selector indicating which thread in a group of four consecutive threads stores the metadata.

![_images/sparse-mma-storage-example.png](_images/sparse-mma-storage-example.png)


Figure 111 Sparse MMA storage example[](#sparse-mma-storage-example "Permalink to this image")

Granularities for different matrix shapes and data types are described below.

Sparse `mma.sp{::ordered_metadata}` with half-precision and `.bf16` type

For the `.m16n8k16` and `.m16n8k32` `mma.sp{::ordered_metadata}` operations, matrix A is
structured sparse at a granularity of 2:4. In other words, each chunk of four adjacent elements
in a row of matrix A has two zeros and two non-zero elements. Only the two non-zero elements are
stored in the operand representing matrix A and their positions in the four-wide chunk in matrix
A are indicated by two 2-bit indices in the metadata operand. For `mma.sp::ordered_metadata`,
`0b0100`, `0b1000`, `0b1001`, `0b1100`, `0b1101`, `0b1110` are the meaningful values
of indices; any other values result in an undefined behavior.

![_images/f16-metadata-example.png](_images/f16-metadata-example.png)


Figure 112 Sparse MMA metadata example for `.f16`/`.bf16` type.[](#f16-metadata-example "Permalink to this image")

The sparsity selector indicates the threads which contribute metadata as listed below:

* `m16n8k16`: One thread within a group of four consecutive threads contributes the metadata for
  the entire group. This thread is indicated by a value in {0, 1, 2, 3}.
* `m16n8k32`: A thread-pair within a group of four consecutive threads contributes the sparsity
  metadata. Hence, the sparsity selector must be either 0 (threads T0, T1) or 1 (threads T2, T3);
  any other value results in an undefined behavior.

Sparse `mma.sp{::ordered_metadata}` with `.tf32` type

When matrix A has `.tf32` elements, matrix A is structured sparse at a granularity of 1:2. In
other words, each chunk of two adjacent elements in a row of matrix A has one zero and one non-zero
element. Only the non-zero elements are stored in the operand for matrix A and their positions in a
two-wide chunk in matrix A are indicated by the 4-bit index in the metadata. `0b1110` and
`0b0100` are the only meaningful index values; any other values result in an undefined behavior.

![_images/tf32-metadata-example.png](_images/tf32-metadata-example.png)


Figure 113 Sparse MMA metadata example for `.tf32` type.[](#tf32-metadata-example "Permalink to this image")

The sparsity selector indicates the threads which contribute metadata as listed below:

* `m16n8k8`: One thread within a group of four consecutive threads contributes the metadata for
  the entire group. This thread is indicated by a value in {0, 1, 2, 3}.
* `m16n8k16`: A thread-pair within a group of four consecutive threads contributes the sparsity
  metadata. Hence, the sparsity selector must be either 0 (threads T0, T1) or 1 (threads T2, T3);
  any other value results in an undefined behavior.

Sparse `mma.sp{::ordered_metadata}` with integer type

When matrices A and B have `.u8`/`.s8` elements, matrix A is structured sparse at a granularity
of 2:4. In other words, each chunk of four adjacent elements in a row of matrix A have two zeroes
and two non-zero elements. Only the two non-zero elements are stored in sparse matrix and their
positions in the four-wide chunk are indicated by two 2-bit indices in the metadata. For
`mma.sp::ordered_metadata`, `0b0100`, `0b1000`, `0b1001`, `0b1100`, `0b1101`, `0b1110`
are the meaningful values of indices; any other values result in an undefined behavior.

![_images/u8s8-metadata-example.png](_images/u8s8-metadata-example.png)


Figure 114 Sparse MMA metadata example for `.u8`/`.s8` type.[](#u8s8-metadata-example "Permalink to this image")

when matrices A and B have `.u4`/`.s4` elements, matrix A is pair-wise structured sparse at a
granularity of 4:8. In other words, each chunk of eight adjacent elements in a row of matrix A has
four zeroes and four non-zero values. Further, the zero and non-zero values are clustered in
sub-chunks of two elements each within the eight-wide chunk. i.e., each two-wide sub-chunk within
the eight-wide chunk must be all zeroes or all non-zeros. Only the four non-zero values are stored
in sparse matrix and the positions of the two two-wide sub-chunks with non-zero values in the
eight-wide chunk of a row of matrix A are indicated by two 2-bit indices in the metadata. For
`mma.sp::ordered_metadata`, `0b0100`, `0b1000`, `0b1001`, `0b1100`, `0b1101`, `0b1110`
are the meaningful values of indices; any other values result in an undefined behavior.

![_images/u4s4-metadata-example.png](_images/u4s4-metadata-example.png)


Figure 115 Sparse MMA metadata example for `.u4`/`.s4` type.[](#u4s4-metadata-example "Permalink to this image")

The sparsity selector indicates the threads which contribute metadata as listed below:

* `m16n8k32` with `.u8`/`.s8` type and `m16n8k64` with `.u4`/`.s4` type: A thread-pair
  within a group of four consecutive threads contributes the sparsity metadata. Hence, the sparsity
  selector must be either 0 (threads T0, T1) or 1 (threads T2, T3); any other value results in an
  undefined behavior.
* `m16n8k64` with `.u8`/`.s8` type and `m16n8k128` with `.u4`/`.s4` type: All threads
  within a group of four consecutive threads contribute the sparsity metadata. Hence, the sparsity
  selector in this case must be 0. Any other value of sparsity selector results in an undefined
  behavior.

Sparse `mma.sp{::ordered_metadata}` operating on `.e4m3`/`.e5m2`/`.e3m2`/`.e2m3`/`.e2m1`
type with `.kind::f8f6f4` or `.kind::mxf8f6f4`

When matrices A and B have `.e4m3`/`.e5m2`/`.e3m2`/`.e2m3`/`.e2m1` elements, matrix A is
structured sparse at a granularity of 2:4. In other words, each chunk of four adjacent elements in a
row of matrix A have two zeroes and two non-zero elements. Only the two non-zero elements are stored
in sparse matrix and their positions in the four-wide chunk are indicated by two 2-bit indices in the
metadata. `0b0100`, `0b1000`, `0b1001`, `0b1100`, `0b1101`, `0b1110` are the meaningful
values of indices; any other values result in an undefined behavior.

![_images/fp8-metadata-example.png](_images/fp8-metadata-example.png)


Figure 116 Sparse MMA metadata example for `.e4m3`/`.e5m2`/`.e3m2`/`.e2m3`/`.e2m1` type.[](#fp8-metadata-example "Permalink to this image")

The sparsity selector indicates the threads which contribute metadata as listed below:

* `m16n8k64`: All threads within a group of four consecutive threads contribute the sparsity metadata.
  Hence, the sparsity selector in this case must be 0. Any other value of sparsity selector results in
  an undefined behavior.

Sparse `mma.sp::ordered_metadata` operating on `.e2m1` type with `.kind::mxf4` or `.kind::mxf4nvf4`

When matrices A and B have `.e2m1` elements, matrix A is pair-wise structured sparse at a granularity
of 4:8. In other words, each chunk of eight adjacent elements in a row of matrix A has four zeroes and
four non-zero values. Further, the zero and non-zero values are clustered in sub-chunks of two elements
each within the eight-wide chunk. i.e., each two-wide sub-chunk within the eight-wide chunk must be all
zeroes or all non-zeros. Only the four non-zero values are stored in sparse matrix and the positions of
the two two-wide sub-chunks with non-zero values in the eight-wide chunk of a row of matrix A are
indicated by two 2-bit indices in the metadata. `0b0100`, `0b1000`, `0b1001`, `0b1100`, `0b1101`,
`0b1110` are the meaningful values of indices; any other values result in an undefined behavior.

![_images/fp4-metadata-example.png](_images/fp4-metadata-example.png)


Figure 117 Sparse MMA metadata example for `.e2m1` type with `.kind::mxf4` or `.kind::mxf4nvf4`[](#fp4-metadata-example "Permalink to this image")

The sparsity selector indicates the threads which contribute metadata as listed below:

* `m16n8k128`: All threads within a group of four consecutive threads contribute the sparsity metadata.
  Hence, the sparsity selector in this case must be 0. Any other value of sparsity selector results in
  an undefined behavior.

##### 9.7.14.6.2. [Matrix fragments for multiply-accumulate operation with sparse matrix A](#warp-level-matrix-fragments-for-sparse-mma)[](#warp-level-matrix-fragments-for-sparse-mma "Permalink to this headline")

In this section we describe how the contents of thread registers are associated with fragments of
various matrices and the sparsity metadata. The following conventions are used throughout this
section:

* For matrix A, only the layout of a fragment is described in terms of register vector sizes and
  their association with the matrix data.
* For matrix B, when the combination of matrix dimension and the supported data type is not already
  covered in [Matrix multiply-accumulate operation using mma instruction](#warp-level-matrix-instructions-for-mma), a pictorial representation of matrix
  fragments is provided.
* For matrices C and D, since the matrix dimension - data type combination is the same for all
  supported shapes, and is already covered in
  [Matrix multiply-accumulate operation using mma instruction](#warp-level-matrix-instructions-for-mma), the pictorial representations
  of matrix fragments are not included in this section.
* For the metadata operand, pictorial representations of the association between indices of the
  elements of matrix A and the contents of the metadata operand are included. `Tk: [m..n]` present
  in cell `[x][y..z]` indicates that bits `m` through `n` (with `m` being higher) in the
  metadata operand of thread with `%laneid=k` contains the indices of the non-zero elements from
  the chunk `[x][y]..[x][z]` of matrix A.

###### 9.7.14.6.2.1. [Matrix Fragments for sparse `mma.m16n8k16` with `.f16` and `.bf16` types](#warp-level-matrix-fragment-sparse-mma-16816-f16bf16)[](#warp-level-matrix-fragment-sparse-mma-16816-f16bf16 "Permalink to this headline")

A warp executing sparse `mma.m16n8k16` with `.f16` / `.bf16` floating point type will compute
an MMA operation of shape `.m16n8k16`.

Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.

* Multiplicand A:

  | .atype | Fragment | Elements |
  | --- | --- | --- |
  | `.f16` / `.bf16` | A vector expression containing two `.b32` registers, with each register containing two non-zero `.f16` / `.bf16` elements out of 4 consecutive elements from matrix A. | Mapping of the non-zero elements is as described in [Sparse matrix storage](#warp-level-sparse-matrix-storage). |

  The layout of the fragments held by different threads is shown in [Figure 118](#sparse-mma-16816-f16-bf16-a).

  ![_images/sparse-mma-16816-f16-bf16-A.png](_images/sparse-mma-16816-f16-bf16-A.png)


  Figure 118 Sparse MMA .m16n8k16 fragment layout for matrix A with `.f16`/`.bf16` type.[](#sparse-mma-16816-f16-bf16-a "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID for a0 and a1

   groupID + 8 for a2 and a3



  col = [firstcol ... lastcol] // As per the mapping of non-zero elements

   // as described in Sparse matrix storage



  Where

  firstcol = threadID_in_group * 4

  lastcol = firstcol + 3
  ```
* Matrix fragments for multiplicand B and accumulators C and D are the same as in case of
  [Matrix Fragments for mma.m16n8k16 with floating point type](#warp-level-matrix-fragment-mma-16816-float) for `.f16`/`.b16` formats.
* Metadata: A `.b32` register containing 16 2-bit vectors each storing the index of a non-zero
  element of a 4-wide chunk of matrix A as shown in [Figure 119](#sparse-mma-metadata-16816-f16bf16).

  > ![_images/sparse-mma-metadata-16816-f16bf16.png](_images/sparse-mma-metadata-16816-f16bf16.png)
  >
  >
  > Figure 119 Sparse MMA .m16n8k16 metadata layout for `.f16`/`.bf16` type.[](#sparse-mma-metadata-16816-f16bf16 "Permalink to this image")

###### 9.7.14.6.2.2. [Matrix Fragments for sparse `mma.m16n8k32` with `.f16` and `.bf16` types](#warp-level-matrix-fragment-sparse-mma-16832-f16bf16)[](#warp-level-matrix-fragment-sparse-mma-16832-f16bf16 "Permalink to this headline")

A warp executing sparse `mma.m16n8k32` with `.f16` / `.bf16` floating point type will compute
an MMA operation of shape `.m16n8k32`.

Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.

* Multiplicand A:

  | .atype | Fragment | Elements |
  | --- | --- | --- |
  | `.f16` / `.bf16` | A vector expression containing four `.b32` registers, with each register containing two non-zero `.f16` / `.bf16` elements out of 4 consecutive elements from matrix A. | Mapping of the non-zero elements is as described in [Sparse matrix storage](#warp-level-sparse-matrix-storage). |

  The layout of the fragments held by different threads is shown in [Figure 120](#sparse-mma-16832-f16-bf16-a).

  ![_images/sparse-mma-16832-f16-bf16-A.png](_images/sparse-mma-16832-f16-bf16-A.png)


  Figure 120 Sparse MMA .m16n8k32 fragment layout for matrix A with `.f16`/`.bf16` type.[](#sparse-mma-16832-f16-bf16-a "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID for ai where 0 <= i < 2 || 4 <= i < 6

   groupID + 8 Otherwise



  col = [firstcol ... lastcol] // As per the mapping of non-zero elements

   // as described in Sparse matrix storage



  Where

  firstcol = threadID_in_group * 4 For ai where i < 4

   (threadID_in_group * 4) + 16 for ai where i >= 4

  lastcol = firstcol + 3
  ```
* Multiplicand B:

  | .atype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.f16` / `.bf16` | A vector expression containing four `.b32` registers, each containing two `.f16` / `.bf16` elements from matrix B. | b0, b1, b2, b3 |

  The layout of the fragments held by different threads is shown in [Figure 121](#sparse-mma-16832-f16bf16-b).

  ![_images/sparse-mma-16832-f16bf16-B.png](_images/sparse-mma-16832-f16bf16-B.png)


  Figure 121 Sparse MMA .m16n8k32 fragment layout for matrix B with `.f16`/`.bf16` type.[](#sparse-mma-16832-f16bf16-b "Permalink to this image")
* Matrix fragments for accumulators C and D are the same as in case of
  [Matrix Fragments for mma.m16n8k16 with floating point type](#warp-level-matrix-fragment-mma-16816-float)
  for `.f16`/`.b16` formats.
* Metadata: A `.b32` register containing 16 2-bit vectors with each pair of 2-bit vectors storing
  the indices of two non-zero element from a 4-wide chunk of matrix A as shown in
  [Figure 122](#sparse-mma-metadata-16832-f16bf16).

  > ![_images/sparse-mma-metadata-16832-f16bf16.png](_images/sparse-mma-metadata-16832-f16bf16.png)
  >
  >
  > Figure 122 Sparse MMA .m16n8k32 metadata layout for `.f16`/`.bf16` type.[](#sparse-mma-metadata-16832-f16bf16 "Permalink to this image")

###### 9.7.14.6.2.3. [Matrix Fragments for sparse `mma.m16n8k16` with `.tf32` floating point type](#warp-level-matrix-fragment-sparse-mma-16816-tf32)[](#warp-level-matrix-fragment-sparse-mma-16816-tf32 "Permalink to this headline")

A warp executing sparse `mma.m16n8k16` with `.tf32` floating point type will compute an MMA
operation of shape `.m16n8k16`.

Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.

* Multiplicand A:

  | .atype | Fragment | Elements |
  | --- | --- | --- |
  | `.tf32` | A vector expression containing four `.b32` registers, with each register containing one non-zero `.tf32` element out of 2 consecutive elements from matrix A. | Mapping of the non-zero elements is as described in [Sparse matrix storage](#warp-level-sparse-matrix-storage). |

  The layout of the fragments held by different threads is shown in [Figure 123](#sparse-mma-16816-tf32-a).

  ![_images/sparse-mma-16816-tf32-A.png](_images/sparse-mma-16816-tf32-A.png)


  Figure 123 Sparse MMA .m16n8k16 fragment layout for matrix A with `.tf32` type.[](#sparse-mma-16816-tf32-a "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID for a0 and a2

   groupID + 8 for a1 and a3



  col = [firstcol ... lastcol] // As per the mapping of non-zero elements

   // as described in Sparse matrix storage



  Where

  firstcol = threadID_in_group * 2 for a0 and a1

   (threadID_in_group * 2) + 8 for a2 and a3

  lastcol = firstcol + 1
  ```
* Multiplicand B:

  | .atype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.tf32` | A vector expression containing four `.b32` registers, each containing four `.tf32` elements from matrix B. | b0, b1, b2, b3 |

  The layout of the fragments held by different threads is shown in [Figure 124](#sparse-mma-16816-tf32-b).

  ![_images/sparse-mma-16816-tf32-B.png](_images/sparse-mma-16816-tf32-B.png)


  Figure 124 Sparse MMA .m16n8k16 fragment layout for matrix B with `.tf32` type.[](#sparse-mma-16816-tf32-b "Permalink to this image")
* Matrix fragments for accumulators C and D are the same as in case of
  [Matrix Fragments for mma.m16n8k16 with floating point type](#warp-level-matrix-fragment-mma-16816-float).
* Metadata: A `.b32` register containing 8 4-bit vectors each storing the index of a non-zero
  element of a 2-wide chunk of matrix A as shown in [Figure 125](#sparse-mma-metadata-16816-tf32).

  > ![_images/sparse-mma-metadata-16816-tf32.png](_images/sparse-mma-metadata-16816-tf32.png)
  >
  >
  > Figure 125 Sparse MMA .m16n8k16 metadata layout for `.tf32` type.[](#sparse-mma-metadata-16816-tf32 "Permalink to this image")

###### 9.7.14.6.2.4. [Matrix Fragments for sparse `mma.m16n8k8` with `.tf32` floating point type](#warp-level-matrix-fragment-sparse-mma-1688-tf32)[](#warp-level-matrix-fragment-sparse-mma-1688-tf32 "Permalink to this headline")

A warp executing sparse `mma.m16n8k8` with `.tf32` floating point type will compute an MMA
operation of shape `.m16n8k8`.

Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.

* Multiplicand A:

  | .atype | Fragment | Elements |
  | --- | --- | --- |
  | `.tf32` | A vector expression containing two `.b32` registers, each containing one non-zero `.tf32` element out of 2 consecutive elements from matrix A. | Mapping of the non-zero elements is as described in [Sparse matrix storage](#warp-level-sparse-matrix-storage). |

  The layout of the fragments held by different threads is shown in [Figure 126](#sparse-mma-1688-tf32).

  ![_images/sparse-mma-1688-tf32-A.png](_images/sparse-mma-1688-tf32-A.png)


  Figure 126 Sparse MMA .m16n8k8 fragment layout for matrix A with `.tf32` type.[](#sparse-mma-1688-tf32 "Permalink to this image")

  The row and column of a matrix fragment can be computed as:

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID for a0

   groupID + 8 for a1



  col = [firstcol ... lastcol] // As per the mapping of non-zero elements

   // as described in Sparse matrix storage



  Where

  firstcol = threadID_in_group * 2

  lastcol = firstcol + 1
  ```
* Matrix fragments for multiplicand B and accumulators C and D are the same as in case of
  [Matrix Fragments for mma.m16n8k8](#warp-level-matrix-fragment-mma-1688) for `.tf32`
  format.
* Metadata: A `.b32` register containing 8 4-bit vectors each storing the index of a non-zero
  element of a 2-wide chunk of matrix A as shown in [Figure 127](#sparse-mma-metadata-1688-tf32).

  > ![_images/sparse-mma-metadata-1688-tf32.png](_images/sparse-mma-metadata-1688-tf32.png)
  >
  >
  > Figure 127 Sparse MMA .m16n8k8 metadata layout for `.tf32` type.[](#sparse-mma-metadata-1688-tf32 "Permalink to this image")

###### 9.7.14.6.2.5. [Matrix Fragments for sparse `mma.m16n8k32` with `.u8` / `.s8` integer type](#warp-level-matrix-fragment-sparse-mma-16832-u8s8)[](#warp-level-matrix-fragment-sparse-mma-16832-u8s8 "Permalink to this headline")

A warp executing sparse `mma.m16n8k32` with `.u8` / `.s8` integer type will compute an MMA
operation of shape `.m16n8k32`.

Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.

* Multiplicand A:

  | .atype | Fragment | Elements |
  | --- | --- | --- |
  | `.u8` / `.s8` | A vector expression containing two `.b32` registers, with each register containing four non-zero `.u8` / `.s8` elements out of 8 consecutive elements from matrix A. | Mapping of the non-zero elements is as described in [Sparse matrix storage](#warp-level-sparse-matrix-storage). |

  The layout of the fragments held by different threads is shown in [Figure 128](#sparse-mma-16832-u8s8-a).

  ![_images/sparse-mma-16832-u8s8-A.png](_images/sparse-mma-16832-u8s8-A.png)


  Figure 128 Sparse MMA .m16n8k32 fragment layout for matrix A with `.u8`/`.s8` type.[](#sparse-mma-16832-u8s8-a "Permalink to this image")

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID for ai where 0 <= i < 4

   groupID + 8 Otherwise



  col = [firstcol ... lastcol] // As per the mapping of non-zero elements

   // as described in Sparse matrix storage



  Where

  firstcol = threadID_in_group * 8

  lastcol = firstcol + 7
  ```
* Matrix fragments for multiplicand B and accumulators C and D are the same as in case of
  [Matrix Fragments for mma.m16n8k32](#warp-level-matrix-fragment-mma-16832).
* Metadata: A `.b32` register containing 16 2-bit vectors with each pair of 2-bit vectors storing
  the indices of two non-zero elements from a 4-wide chunk of matrix A as shown in
  [Figure 129](#sparse-mma-metadata-16832-u8s8).

  > ![_images/sparse-mma-metadata-16832-u8s8.png](_images/sparse-mma-metadata-16832-u8s8.png)
  >
  >
  > Figure 129 Sparse MMA .m16n8k32 metadata layout for `.u8`/`.s8` type.[](#sparse-mma-metadata-16832-u8s8 "Permalink to this image")

###### 9.7.14.6.2.6. [Matrix Fragments for sparse `mma.m16n8k64` with `.u8` / `.s8` / `.e4m3` / `.e5m2` type](#warp-level-matrix-fragment-sparse-mma-16864-u8s8-fp8)[](#warp-level-matrix-fragment-sparse-mma-16864-u8s8-fp8 "Permalink to this headline")

A warp executing sparse `mma.m16n8k64` with `.u8` / `.s8`/ `.e4m3`/ `.e5m2` /
`.e3m2` / `.e2m3` / `.e2m1` type will compute an MMA operation of shape `.m16n8k64`.

Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.

* Multiplicand A:

  | .atype | Fragment | Elements |
  | --- | --- | --- |
  | `.u8` / `.s8` | A vector expression containing four `.b32` registers, with each register containing four non-zero `.u8` / `.s8` elements out of 8 consecutive elements from matrix A. | Mapping of the non-zero elements is as described in [Sparse matrix storage](#warp-level-sparse-matrix-storage). |
  | `.e4m3` / `.e5m2` / `.e3m2` / `.e2m3` / `.e2m1` | A vector expression containing four `.b32` registers, with each register containing four non-zero `.e4m3` / `.e5m2` / `.e3m2` / `.e2m3` / `.e2m1` elements out of 8 consecutive elements from matrix A. |

  The layout of the fragments held by different threads is shown in [Figure 130](#sparse-mma-16864-u8s8-a-first32col)
  and [Figure 131](#sparse-mma-16864-u8s8-a-last32col).

  ![_images/sparse-mma-16864-u8s8-A-first32col.png](_images/sparse-mma-16864-u8s8-A-first32col.png)


  Figure 130 Sparse MMA .m16n8k64 fragment layout for columns 0–31 of matrix A with `.u8`/`.s8`/`.e4m3`/`.e5m2`/`.e3m2`/`.e2m3`/`.e2m1` type.[](#sparse-mma-16864-u8s8-a-first32col "Permalink to this image")


  ![_images/sparse-mma-16864-u8s8-A-last32col.png](_images/sparse-mma-16864-u8s8-A-last32col.png)


  Figure 131 Sparse MMA .m16n8k64 fragment layout for columns 32–63 of matrix A with `.u8`/`.s8`/`.e4m3`/`.e5m2`/`.e3m2`/`.e2m3`/`.e2m1` type.[](#sparse-mma-16864-u8s8-a-last32col "Permalink to this image")

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID for ai where 0 <= i < 4 || 8 <= i < 12

   groupID + 8 Otherwise



  col = [firstcol ... lastcol] // As per the mapping of non-zero elements

   // as described in Sparse matrix storage



  Where

  firstcol = threadID_in_group * 8 For ai where i < 8

   (threadID_in_group * 8) + 32 For ai where i >= 8

  lastcol = firstcol + 7
  ```
* Multiplicand B:

  | .btype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.u8` / `.s8` | A vector expression containing four `.b32` registers, each containing four `.u8` / `.s8` elements from matrix B. | b0, b1, b2, b3, …, b15 |
  | `.e4m3` / `.e5m2` / `.e3m2` / `.e2m3` / `.e2m1` | A vector expression containing four `.b32` registers, each containing four `.e4m3` / `.e5m2` / `.e3m2` / `.e2m3` / `.e2m1` elements from matrix B. |

  The layout of the fragments held by different threads is shown in [Figure 132](#sparse-mma-16864-u8s8-b1),
  [Figure 133](#sparse-mma-16864-u8s8-b2), [Figure 134](#sparse-mma-16864-u8s8-b3) and [Figure 135](#sparse-mma-16864-u8s8-b4).

  ![_images/sparse-mma-16864-u8s8-B1.png](_images/sparse-mma-16864-u8s8-B1.png)


  Figure 132 Sparse MMA .m16n8k64 fragment layout for rows 0–15 of matrix B with `.u8`/`.s8`/`.e4m3`/`.e5m2`/`.e3m2`/`.e2m3`/`.e2m1` type.[](#sparse-mma-16864-u8s8-b1 "Permalink to this image")


  ![_images/sparse-mma-16864-u8s8-B2.png](_images/sparse-mma-16864-u8s8-B2.png)


  Figure 133 Sparse MMA .m16n8k64 fragment layout for rows 16–31 of matrix B with `.u8`/`.s8`/`.e4m3`/`.e5m2`/`.e3m2`/`.e2m3`/`.e2m1` type.[](#sparse-mma-16864-u8s8-b2 "Permalink to this image")


  ![_images/sparse-mma-16864-u8s8-B3.png](_images/sparse-mma-16864-u8s8-B3.png)


  Figure 134 Sparse MMA .m16n8k64 fragment layout for rows 32–47 of matrix B with `.u8`/`.s8`/`.e4m3`/`.e5m2`/`.e3m2`/`.e2m3`/`.e2m1` type.[](#sparse-mma-16864-u8s8-b3 "Permalink to this image")


  ![_images/sparse-mma-16864-u8s8-B4.png](_images/sparse-mma-16864-u8s8-B4.png)


  Figure 135 Sparse MMA .m16n8k64 fragment layout for rows 48–63 of matrix B with `.u8`/`.s8`/`.e4m3`/`.e5m2`/`.e3m2`/`.e2m3`/`.e2m1` type.[](#sparse-mma-16864-u8s8-b4 "Permalink to this image")
* Matrix fragments for accumulators C and D are the same as in case of
  [Matrix Fragments for mma.m16n8k16 with integer type](#warp-level-matrix-fragment-mma-16816-i8-f8).
* Metadata: A `.b32` register containing 16 2-bit vectors with each pair of 2-bit vectors storing
  the indices of two non-zero elements from a 4-wide chunk of matrix A as shown in
  [Figure 136](#sparse-mma-metadata-16864-u8s8-first32col) and [Figure 137](#sparse-mma-metadata-16864-u8s8-last32col).

  > ![_images/sparse-mma-metadata-16864-u8s8-first32col.png](_images/sparse-mma-metadata-16864-u8s8-first32col.png)
  >
  >
  > Figure 136 Sparse MMA .m16n8k64 metadata layout for columns 0–31 for `.u8`/`.s8`/`.e4m3`/`.e5m2`/`.e3m2`/`.e2m3`/`.e2m1` type.[](#sparse-mma-metadata-16864-u8s8-first32col "Permalink to this image")
  >
  >
  > ![_images/sparse-mma-metadata-16864-u8s8-last32col.png](_images/sparse-mma-metadata-16864-u8s8-last32col.png)
  >
  >
  > Figure 137 Sparse MMA .m16n8k64 metadata layout for columns 32–63 for `.u8`/`.s8`/`.e4m3`/`.e5m2`/`.e3m2`/`.e2m3`/`.e2m1` type.[](#sparse-mma-metadata-16864-u8s8-last32col "Permalink to this image")

###### 9.7.14.6.2.7. [Matrix Fragments for sparse `mma.m16n8k64` with `.u4` / `.s4` integer type](#warp-level-matrix-fragment-sparse-mma-16864-u4s4)[](#warp-level-matrix-fragment-sparse-mma-16864-u4s4 "Permalink to this headline")

A warp executing sparse `mma.m16n8k64` with `.u4` / `.s4` integer type will compute an MMA
operation of shape `.m16n8k64`.

Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.

* Multiplicand A:

  | .atype | Fragment | Elements |
  | --- | --- | --- |
  | `.u4` / `.s4` | A vector expression containing two `.b32` registers, with each register containing eight non-zero `.u4` / `.s4` elements out of 16 consecutive elements from matrix A. | Mapping of the non-zero elements is as described in [Sparse matrix storage](#warp-level-sparse-matrix-storage). |

  The layout of the fragments held by different threads is shown in [Figure 138](#sparse-mma-16864-u4s4-a).

  ![_images/sparse-mma-16864-u4s4-A.png](_images/sparse-mma-16864-u4s4-A.png)


  Figure 138 Sparse MMA .m16n8k64 fragment layout for matrix A with `.u4`/`.s4` type.[](#sparse-mma-16864-u4s4-a "Permalink to this image")

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID for ai where 0 <= i < 8

   groupID + 8 Otherwise



  col = [firstcol ... lastcol] // As per the mapping of non-zero elements

   // as described in Sparse matrix storage



  Where

  firstcol = threadID_in_group * 16

  lastcol = firstcol + 15
  ```
* Matrix fragments for multiplicand B and accumulators C and D are the same as in case of
  [Matrix Fragments for mma.m16n8k64](#warp-level-matrix-fragment-mma-16864).
* Metadata: A `.b32` register containing 16 2-bit vectors with each pair of 2-bit vectors storing
  the indices of four non-zero elements from a 8-wide chunk of matrix A as shown in
  [Figure 139](#sparse-mma-metadata-16864-u4s4).

  > ![_images/sparse-mma-metadata-16864-u4s4.png](_images/sparse-mma-metadata-16864-u4s4.png)
  >
  >
  > Figure 139 Sparse MMA .m16n8k64 metadata layout for `.u4`/`.s4` type.[](#sparse-mma-metadata-16864-u4s4 "Permalink to this image")

###### 9.7.14.6.2.8. [Matrix Fragments for sparse `mma.m16n8k128` with `.u4` / `.s4` integer type](#warp-level-matrix-fragment-sparse-mma-168128-u4s4)[](#warp-level-matrix-fragment-sparse-mma-168128-u4s4 "Permalink to this headline")

A warp executing sparse `mma.m16n8k128` with `.u4` / `.s4` / `.e2m1` integer type will compute an MMA
operation of shape `.m16n8k128`.

Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.

* Multiplicand A:

  | .atype | Fragment | Elements |
  | --- | --- | --- |
  | `.u4` / `.s4` | A vector expression containing four `.b32` registers, with each register containing eight non-zero `.u4` / `.s4` elements out of 16 consecutive elements from matrix A. | Mapping of the non-zero elements is as described in [Sparse matrix storage](#warp-level-sparse-matrix-storage). |
  | `.e2m1` | A vector expression containing four `.b32` registers, with each register containing eight non-zero `.e2m1` elements out of 16 consecutive elements from matrix A. |

  The layout of the fragments held by different threads is shown in [Figure 140](#sparse-mma-168128-u4s4-a-first64col)
  and [Figure 141](#sparse-mma-168128-u4s4-a-last64col).

  ![_images/sparse-mma-168128-u4s4-A-first64col.png](_images/sparse-mma-168128-u4s4-A-first64col.png)


  Figure 140 Sparse MMA .m16n8k128 fragment layout for columns 0–63 of matrix A with `.u4`/`.s4`/`.e2m1` type.[](#sparse-mma-168128-u4s4-a-first64col "Permalink to this image")


  ![_images/sparse-mma-168128-u4s4-A-last64col.png](_images/sparse-mma-168128-u4s4-A-last64col.png)


  Figure 141 Sparse MMA .m16n8k128 fragment layout for columns 64–127 of matrix A with `.u4`/`.s4`/`.e2m1` type.[](#sparse-mma-168128-u4s4-a-last64col "Permalink to this image")

  ```
  groupID = %laneid >> 2

  threadID_in_group = %laneid % 4



  row = groupID for ai where 0 <= i < 8 || 16 <= i < 24

   groupID + 8 Otherwise



  col = [firstcol ... lastcol] // As per the mapping of non-zero elements

   // as described in Sparse matrix storage



  Where

  firstcol = threadID_in_group * 16 For ai where i < 16

   (threadID_in_group * 16) + 64 For ai where i >= 16

  lastcol = firstcol + 15
  ```
* Multiplicand B:

  | .atype | Fragment | Elements (low to high) |
  | --- | --- | --- |
  | `.u4` / `.s4` | A vector expression containing four `.b32` registers, each containing eight `.u4` / `.s4` elements from matrix B. | b0, b1, b2, b3, …, b31 |
  | `.e2m1` | A vector expression containing four `.b32` registers, each containing eight `.e2m1` elements from matrix B. |

  The layout of the fragments held by different threads is shown in [Figure 142](#sparse-mma-168128-u4s4-b1),
  [Figure 143](#sparse-mma-168128-u4s4-b2), [Figure 144](#sparse-mma-168128-u4s4-b3), [Figure 145](#sparse-mma-168128-u4s4-b4).

  ![_images/sparse-mma-168128-u4s4-B1.png](_images/sparse-mma-168128-u4s4-B1.png)


  Figure 142 Sparse MMA .m16n8k128 fragment layout for rows 0–31 of matrix B with `.u4`/`.s4`/`.e2m1` type.[](#sparse-mma-168128-u4s4-b1 "Permalink to this image")


  ![_images/sparse-mma-168128-u4s4-B2.png](_images/sparse-mma-168128-u4s4-B2.png)


  Figure 143 Sparse MMA .m16n8k128 fragment layout for rows 32–63 of matrix B with `.u4`/`.s4`/`.e2m1` type.[](#sparse-mma-168128-u4s4-b2 "Permalink to this image")


  ![_images/sparse-mma-168128-u4s4-B3.png](_images/sparse-mma-168128-u4s4-B3.png)


  Figure 144 Sparse MMA .m16n8k128 fragment layout for rows 64–95 of matrix B with `.u4`/`.s4`/`.e2m1` type.[](#sparse-mma-168128-u4s4-b3 "Permalink to this image")


  ![_images/sparse-mma-168128-u4s4-B4.png](_images/sparse-mma-168128-u4s4-B4.png)


  Figure 145 Sparse MMA .m16n8k128 fragment layout for rows 96–127 of matrix B with `.u4`/`.s4`/`.e2m1` type.[](#sparse-mma-168128-u4s4-b4 "Permalink to this image")
* Matrix fragments for accumulators C and D are the same as in case of
  [Matrix Fragments for mma.m16n8k64](#warp-level-matrix-fragment-mma-16864).
* Metadata: A `.b32` register containing 16 2-bit vectors with each pair of 2-bit vectors storing
  the indices of four non-zero elements from a 8-wide chunk of matrix A as shown in
  [Figure 146](#sparse-mma-metadata-168128-u4s4-first64col) and [Figure 147](#sparse-mma-metadata-168128-u4s4-last64col).

  > ![_images/sparse-mma-metadata-168128-u4s4-first64col.png](_images/sparse-mma-metadata-168128-u4s4-first64col.png)
  >
  >
  > Figure 146 Sparse MMA .m16n8k128 metadata layout for columns 0–63 for `.u4`/`.s4`/`.e2m1` type.[](#sparse-mma-metadata-168128-u4s4-first64col "Permalink to this image")
  >
  >
  > ![_images/sparse-mma-metadata-168128-u4s4-last64col.png](_images/sparse-mma-metadata-168128-u4s4-last64col.png)
  >
  >
  > Figure 147 Sparse MMA .m16n8k128 metadata layout for columns 64–127 for `.u4`/`.s4`/`.e2m1` type.[](#sparse-mma-metadata-168128-u4s4-last64col "Permalink to this image")

##### 9.7.14.6.3. [Multiply-and-Accumulate Instruction: `mma.sp` / `mma.sp::ordered_metadata`](#warp-level-matrix-instructions-sparse-mma)[](#warp-level-matrix-instructions-sparse-mma "Permalink to this headline")

`mma.sp`, `mma.sp::ordered_metadata`

Perform matrix multiply-and-accumulate operation with sparse matrix A

Syntax

Half precision floating point type:

```
mma.spvariant.sync.aligned.m16n8k16.row.col.dtype.f16.f16.ctype  d, a, b, c, e, f;

mma.spvariant.sync.aligned.m16n8k32.row.col.dtype.f16.f16.ctype  d, a, b, c, e, f;



.ctype     = {.f16, .f32};

.dtype     = {.f16, .f32};

.spvariant = {.sp, .sp::ordered_metadata};
```

Alternate floating point type:

```
mma.spvariant.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32     d, a, b, c, e, f;

mma.spvariant.sync.aligned.m16n8k32.row.col.f32.bf16.bf16.f32     d, a, b, c, e, f;

mma.spvariant.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32      d, a, b, c, e, f;

mma.spvariant.sync.aligned.m16n8k16.row.col.f32.tf32.tf32.f32     d, a, b, c, e, f;

mma.spvariant.sync.aligned.m16n8k64.row.col.f32.f8type.f8type.f32 d, a, b, c, e, f;

mma.sp::ordered_metadata.sync.aligned.m16n8k64.row.col.kind.dtype.f8f6f4type.f8f6f4type.ctype d, a, b, c, e, f;



.f8type     = {.e4m3, .e5m2};

.spvariant  = {.sp, .sp::ordered_metadata};

.f8f6f4type = {.e4m3, .e5m2, .e3m2, .e2m3, .e2m1};

.kind       = {kind::f8f6f4};

.ctype      = {.f16, .f32};

.dtype      = {.f16, .f32};
```

Alternate floating point type with block scaling:

```
mma.spvariant.sync.aligned.m16n8k128.row.col.kind.block_scale{.scale_vec_size}.f32.e2m1.e2m1.f32.stype d, a, b, c, e, f, scale-a-data, {byte-id-a, thread-id-a}, scale-b-data, {byte-id-b, thread-id-b};



.spvariant      = {.sp::ordered_metadata};

.kind           = {.kind::mxf4};

.scale_vec_size = {.scale_vec::2X};

.stype          = {.ue8m0};



mma.spvariant.sync.aligned.m16n8k128.row.col.kind.block_scale.scale_vec_size.f32.e2m1.e2m1.f32.stype d, a, b, c, e, f, scale-a-data, {byte-id-a, thread-id-a}, scale-b-data, {byte-id-b, thread-id-b};



.spvariant      = {.sp::ordered_metadata};

.kind           = {.kind::mxf4nvf4};

.scale_vec_size = {.scale_vec::2X, .scale_vec::4X};

.stype          = {.ue8m0, .ue4m3};



mma.spvariant.sync.aligned.m16n8k64.row.col.kind.block_scale{.scale_vec_size}.f32.f8f6f4type.f8f6f4type.f32.stype d, a, b, c, e, f, scale-a-data, {byte-id-a, thread-id-a}, scale-b-data, {byte-id-b, thread-id-b};



.spvariant      = {.sp::ordered_metadata};

.kind           = {.kind::mxf8f6f4};

.scale_vec_size = {.scale_vec::1X};

.f8f6f4type     = {.e4m3, .e5m2, .e3m2, .e2m3, .e2m1};

.stype          = {.ue8m0};
```

Integer type:

```
mma.spvariant.sync.aligned.shape.row.col{.satfinite}.s32.atype.btype.s32 d, a, b, c, e, f;



.shape     = {.m16n8k32, .m16n8k64}

.atype     = {.u8, .s8};

.btype     = {.u8, .s8};

.spvariant = {.sp, .sp::ordered_metadata};



mma.spvariant.sync.aligned.shape.row.col{.satfinite}.s32.atype.btype.s32 d, a, b, c, e, f;



.shape     = {.m16n8k64, .m16n8k128}

.atype     = {.u4, .s4};

.btype     = {.u4, .s4};

.spvariant = {.sp, .sp::ordered_metadata};
```

Description

Perform a `MxNxK` matrix multiply and accumulate operation, `D = A*B+C`, where the A matrix is
`MxK`, the B matrix is `KxN`, and the C and D matrices are `MxN`.

A warp executing `mma.sp.sync/mma.sp::ordered_metadata.sync` instruction compute a single matrix
multiply and accumulate operation.

Qualifier `.block_scale` specifies that the matrices `A` and `B` are scaled with `scale_A`
and `scale_B` matrices respectively before performing the matrix multiply and accumulate operation
as specified in the section [Block Scaling](#warp-level-block-scaling). The data type corresponding
to each of the element within `scale_A` and `scale_B` matrices is specified by `.stype`.
Qualifier `.scale_vec_size` specifies the number of columns of `scale_A` matrix and number of
rows in the matrix `scale_B`.

The valid combinations of `.kind`, `.stype` and `.scale_vec_size` are described in
[Table 36](#mma-scaling-kind-type-valid-combination). For `mma` with `.kind::mxf4` when the
qualifier `.scale_vec_size` is not specified, then it defaults to `2X`. In contrast,
when `.kind` is specified as `.kind::mxf8f6f4` then the qualifier `.scale_vec_size`
defaults to `1X`. However, for `.kind::mxf4nvf4`, it is mandatory to provide valid
`.scale_vec_size`.

Operands `a` and `b` represent two multiplicand matrices A and B, while `c` and `d`
represent the accumulator and destination matrices, distributed across the threads in warp. Matrix A
is structured sparse as described in [Sparse matrix storage](#warp-level-sparse-matrix-storage) Operands `e` and `f` represent sparsity
metadata and sparsity selector respectively. Operand `e` is a 32-bit integer and operand `f` is
a 32-bit integer constant with values in the range 0..3.
When `.block_scale` qualifier is specified, operand `scale-a-data`, `scale-b-data` represents
the scale matrix metadata corresponding to `scale_A` and `scale_B` matrices respectively.
The tuple `{byte-id-a, thread-id-a}` and `{byte-id-b, thread-id-b}` represent selectors for
matrices `scale_A` and `scale_B` respectively from their corresponding metadata arguments
`scale-a-data`, `scale-b-data`. The operands `scale-a-data`, `scale-b-data` are of type
`.b32`. The operands `byte-id-a`, `thread-id-a`, `byte-id-b`, `thread-id-b` are unsigned
16-bit integer values. For more details on selector arguments refer
[Block Scaling](#warp-level-block-scaling) section.

Instruction `mma.sp::ordered_metadata` requires the indices in the sparsity metadata to be sorted
in an increasing order starting from LSB, otherwise behavior is undefined.

The registers in each thread hold a fragment of matrix as described in
[Matrix fragments for multiply-accumulate operation with sparse matrix A](#warp-level-matrix-fragments-for-sparse-mma).

The qualifiers `.dtype`, `.atype`, `.btype` and `.ctype` indicate the data-type of the
elements in the matrices D, A, B and C respectively. The qualifier `.stype` indicate the
data-type of the elements in the matrices `scale_A` and `scale_B`. In case of shapes
`.m16n8k16` and `.m16n8k32`, `.dtype` must be the same as `.ctype`.

When `.kind` is either of `.kind::mxf8f6f4` or `.kind::f8f6f4`, the individual 4-bit and
the 6-bit floating point type elements must be packed in an 8-bit container. The matrix element
of type `.e2m1` resides in central 4 bits of the 8-bit container with padding in the upper 2
bits and lower 2 bits of the container. When the matrix element is of type `.e3m2` or `.e2m3`,
the matrix element resides in the lower 6 bits of the 8-bit container with padding in the upper
2 bits of the container. In contrast, note that when using `mma` with `.kind::mxf4` or
`.kind::mxf4nvf4`, no explicit padding is necessary even though matrix elements are of type
`.e2m1`.

Precision and rounding :
:   * `.f16` floating point operations :

      Element-wise multiplication of matrix A and B is performed with at least single
      precision. When `.ctype` or `.dtype` is `.f32`, accumulation of the intermediate values
      is performed with at least single precision. When both `.ctype` and `.dtype` are specified
      as `.f16`, the accumulation is performed with at least half precision.

      The accumulation order, rounding and handling of subnormal inputs are unspecified.
    * `.e4m3`, `.e5m2`, `.e3m2`, `.e2m3`, `.e2m1` floating point operations :

      Element-wise multiplication of matrix A and B is performed with specified precision. Accumulation
      of the intermediate values is performed with at least single precision.

      The accumulation order, rounding, and handling of subnormal inputs are unspecified.
    * `.bf16` and `.tf32` floating point operations :

      Element-wise multiplication of matrix A and B is performed with specified
      precision. Accumulation of the intermediate values is performed with at least single
      precision.

      The accumulation order, rounding, and handling of subnormal inputs are unspecified.
    * Integer operations :

      The integer `mma.sp/mma.sp::ordered_metadata` operation is performed with `.s32` accumulators.
      The `.satfinite` qualifier indicates that on overflow, the accumulated value is limited to the range
      *MIN\_INT32*.. *MAX\_INT32* (where the bounds are defined as the minimum negative signed 32-bit
      integer and the maximum positive signed 32-bit integer respectively).

      If `.satfinite` is not specified, the accumulated value is wrapped instead.

The mandatory `.sync` qualifier indicates that `mma.sp/mma.sp::ordered_metadata` instruction causes
the executing thread to wait until all threads in the warp execute the same `mma.sp/mma.sp::ordered_metadata`
instruction before resuming execution.

The mandatory `.aligned` qualifier indicates that all threads in the warp must execute the same
`mma.sp/mma.sp::ordered_metadata` instruction. In conditionally executed code, a `mma.sp/mma.sp::ordered_metadata`
instruction should only be used if it is known that all threads in the warp evaluate the condition identically,
otherwise behavior is undefined.

The behavior of `mma.sp/mma.sp::ordered_metadata` instruction is undefined if all threads in the same warp
do not use the same qualifiers, or if any thread in the warp has exited.

Notes

`mma.sp` instruction may have substantially reduced performance on some target architectures.
Hence, it is advised to use `mma.sp::ordered_metadata` instruction.

PTX ISA Notes

Introduced in PTX ISA version 7.1.

Support for `.e4m3` and `.e5m2` alternate floating point type `mma` operation introduced in
PTX ISA version 8.4.

`mma.sp::ordered_metadata` introduced in PTX ISA version 8.5.

Support for shape `.m16n8k32` and `.f16` dtype/ctype with `.e4m3`/`.e5m2` alternate floating
point type `mma` operation introduced in PTX ISA version 8.7.

Support for `.e3m2`, `.e2m3`, `.e2m1` alternate floating point type `mma` operation introduced
in PTX ISA version 8.7.

Support for `.kind`, `.block_scale`, `.scale_vec_size` qualifier introduced in PTX ISA version 8.7.

Target ISA Notes

Requires `sm_80` or higher.

`.e4m3` and `.e5m2` alternate floating point type `mma` operation requires `sm_89` or higher.

`mma.sp::ordered_metadata` requires `sm_80` or higher.

Support for shape `.m16n8k32` and `.f16` dtype/ctype with `.e4m3`/`.e5m2` alternate floating
point type `mma` operation requires `sm_120`.

`.e3m2`, `.e2m3` and `.e2m1` alternate floating point type `mma` operation requires
`sm_120a` and are supported on `sm_120f` or higher in the same family from PTX ISA version 8.8.

Support for `.kind`, `.block_scale`, `.scale_vec_size` qualifier requires `sm_120a` and are
supported on `sm_120f` and later generation targets in the same family from PTX ISA version 8.8 except for `.kind::mxf4nvf4`/`.kind::mxf4`.

Qualifiers `.kind::mxf4nvf4` and `.kind::mxf4` are supported on following architectures:

* `sm_120a`
* `sm_121a`

Examples of half precision floating point type

```
// f16 elements in C and D matrix

.reg .f16x2 %Ra<2> %Rb<2> %Rc<2> %Rd<2>

.reg .b32 %Re;

mma.sp.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16

  {%Rd0, %Rd1},

  {%Ra0, %Ra1},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1}, %Re, 0x1;



.reg .f16x2 %Ra<2> %Rb<2> %Rc<2> %Rd<2>

.reg .b32 %Re;



mma.sp::ordered_metadata.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16

  {%Rd0, %Rd1},

  {%Ra0, %Ra1},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1}, %Re, 0x1;
```

Examples of alternate floating point type

```
.reg .b32 %Ra<2>, %Rb<2>;

.reg .f32 %Rc<4>, %Rd<4>;

.reg .b32 %Re;

mma.sp.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1, %Rc2, %Rc3}, %Re, 0x1;



.reg .b32 %Ra<2>, %Rb<2>;

.reg .f32 %Rc<4>, %Rd<4>;

.reg .b32 %Re;

mma.sp.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1, %Rc2, %Rc3}, %Re, 0x1;



.reg .b32 %Ra<4>, %Rb<4>;

.reg .f32 %Rc<4>, %Rd<4>;

.reg .b32 %Re;

mma.sp.sync.aligned.m16n8k32.row.col.f32.bf16.bf16.f32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1, %Rb2, %Rb3},

  {%Rc0, %Rc1, %Rc2, %Rc3}, %Re, 0x1;



.reg .b32 %Ra<4>, %Rb<4>;

.reg .f32 %Rc<4>, %Rd<4>;

.reg .b32 %Re;

mma.sp.sync.aligned.m16n8k64.row.col.f32.e5m2.e4m3.f32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1, %Rb2, %Rb3},

  {%Rc0, %Rc1, %Rc2, %Rc3}, %Re, 0;



.reg .b32 %Ra<2>, %Rb<2>;

.reg .f32 %Rc<4>, %Rd<4>;

.reg .b32 %Re;

mma.sp::ordered_metadata.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1, %Rc2, %Rc3}, %Re, 0x1;



.reg .b32 %Ra<4>, %Rb<4>;

.reg .f32 %Rc<4>, %Rd<4>;

.reg .b32 %Re;

mma.sp::ordered_metadata.sync.aligned.m16n8k64.row.col.kind::f8f6f4.f32.e3m2.e2m3.f32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1, %Rb2, %Rb3},

  {%Rc0, %Rc1, %Rc2, %Rc3}, %Re, 0;



.reg .b32 %Ra<4>, %Rb<4>;

.reg .b32 %Rc<4>, %Rd<4>;

.reg .b32 %Re;

mma.sp::ordered_metadata.sync.aligned.m16n8k64.row.col.kind::f8f6f4.f16.e2m3.e2m1.f16

  {%Rd0, %Rd1},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1, %Rb2, %Rb3},

  {%Rc0, %Rc1}, %Re, 0;
```

Examples of integer type

```
.reg .b32 %Ra<4>, %Rb<4>, %Rc<4>, %Rd<4>;

.reg .u32 %Re;



// u8 elements in A and B matrix

mma.sp.sync.aligned.m16n8k32.row.col.satfinite.s32.u8.u8.s32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1, %Rc2, %Rc3}, %Re, 0x1;



// s8 elements in A and B matrix

mma.sp.sync.aligned.m16n8k64.row.col.satfinite.s32.s8.s8.s32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1, %Rb2, %Rb3},

  {%Rc0, %Rc1, %Rc2, %Rc3}, %Re, 0x0;



// s8 elements in A and B matrix with ordered metadata

mma.sp::ordered_metadata.sync.aligned.m16n8k64.row.col.satfinite.s32.s8.s8.s32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1, %Rb2, %Rb3},

  {%Rc0, %Rc1, %Rc2, %Rc3}, %Re, 0x0;



// u4 elements in A and B matrix

mma.sp.sync.aligned.m16n8k64.row.col.s32.s4.s4.s32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1},

  {%Rb0, %Rb1},

  {%Rc0, %Rc1, %Rc2, %Rc3}, %Re, 0x1;



// u4 elements in A and B matrix

mma.sp.sync.aligned.m16n8k128.row.col.satfinite.s32.u4.u4.s32

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1, %Rb2, %Rb3},

  {%Rc0, %Rc1, %Rc2, %Rc3}, %Re, 0x0;
```

Examples of mma with block scale

```
.reg .b32 %Ra<4>, %Rb<4>;

.reg .f32 %Rc<4>, %Rd<4>;

.reg .b32 scaleAData, scaleBData;

.reg .b32 %Re;

mma.sp::ordered_metadata.sync.aligned.m16n8k128.row.col.kind::mxf4.block_scale.f32.e2m1.e2m1.f32.ue8m0

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1, %Rb2, %Rb3},

  {%Rc0, %Rc1, %Rc2, %Rc3},

  %Re, 0,

  scaleAData, {2, 1}, scaleBData, {2, 3};



.reg .b32 %Ra<4>, %Rb<4>;

.reg .f32 %Rc<4>, %Rd<4>;

.reg .b32 scaleAData, scaleBData;

.reg .u16 bidA, bidB, tidA, tidB;

.reg .b32 %Re;

mma.sp::ordered_metadata.sync.aligned.m16n8k128.row.col.kind::mxf4nvf4.block_scale.scale_vec::4X.f32.e2m1.e2m1.f32.ue4m3

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1, %Rb2, %Rb3},

  {%Rc0, %Rc1, %Rc2, %Rc3},

  %Re, 0,

  scaleAData, {bidA, tidA}, scaleBData, {bidB, tidB};



.reg .b32 %Ra<4>, %Rb<4>;

.reg .f32 %Rc<4>, %Rd<4>;

.reg .b32 scaleAData, scaleBData;

.reg .b32 %Re;

mma.sp::ordered_metadata.sync.aligned.m16n8k64.row.col.kind::mxf8f6f4.block_scale.scale_vec::1X.f32.e3m2.e2m1.f32.ue8m0

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2, %Ra3},

  {%Rb0, %Rb1, %Rb2, %Rb3},

  {%Rc0, %Rc1, %Rc2, %Rc3},

  %Re, 0,

  scaleAData, {0, 1}, scaleBData, {0, 1};



.reg .b32 %Ra<4>, %Rb<4>;

.reg .f32 %Rc<4>, %Rd<4>;

.reg .b32 scaleAData, scaleBData;

.reg .b32 %Re;

mma.sp::ordered_metadata.sync.aligned.m16n8k64.row.col.kind::mxf8f6f4.block_scale.scale_vec::1X.f32.e4m3.e5m2.f32.ue8m0

  {%Rd0, %Rd1, %Rd2, %Rd3},

  {%Ra0, %Ra1, %Ra2,  %Ra3},

  {%Rb0, %Rb1, %Rb2, %Rb3},

  {%Rc0, %Rc1, %Rc2, %Rc3},

  %Re, 0,

  scaleAData, {0, 1}, scaleBData, {0, 0};
```