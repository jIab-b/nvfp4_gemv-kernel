"**NVIDIA on GitHub ✅ success**
> Workflow [19388840870](<https://github.com/gpu-mode/discord-cluster-manager/actions/runs/19388840870>) completed
> Downloading artifacts... done
> ❌ Running benchmarks failed (internal error 1)

Running on:
* GPU: `NVIDIA B200`
* CPU: `INTEL(R) XEON(R) PLATINUM 8570`
* Runtime: `CUDA`
* Platform: `Linux-6.8.0-51-generic-x86_64-with-glibc2.35`
* Torch: `2.9.0+cu130`
# Running failed
Command ```bash
python3 eval.py benchmark /tmp/tmp2nj2wlnz```
exited with error code **1** after 16.37 seconds.

## Program stderr:
```
multiprocessing.pool.RemoteTraceback: 
\"\"\"
Traceback (most recent call last):
  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 2597, in _run_ninja_build
    subprocess.run(
  File \"/usr/lib/python3.10/subprocess.py\", line 526, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 2.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker
    result = (True, func(*args, **kwds))
  File \"/home/runner/_work/discord-cluster-manager/discord-cluster-manager/eval.py\", line 208, in _run_single_benchmark
    from submission import custom_kernel
  File \"/home/runner/_work/discord-cluster-manager/discord-cluster-manager/submission.py\", line 143, in <module>
    module = load_inline(
  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 2051, in load_inline
    return _jit_compile(
  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 2134, in _jit_compile
    _write_ninja_file_and_build_library(
  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 2286, in _write_ninja_file_and_build_library
    _run_ninja_build(
  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 2614, in _run_ninja_build
    raise RuntimeError(message) from e
RuntimeError: Error building extension 'batched_scaled_gemv_cutlass': [1/2] /usr/local/cuda-13.0/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda.cuda.o.d -DTORCH_EXTENSION_NAME=batched_scaled_gemv_cutlass -DTORCH_API_INCLUDE_EXTENSION_H -isystem /usr/local/lib/python3.10/dist-packages/torch/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/cuda-13.0/include -isystem /usr/include/python3.10 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -I/usr/local/cuda/include -I/opt/cutlass/4.3.0/include -gencode=arch=compute_100a,code=sm_100a -gencode=arch=compute_110,code=sm_110 -c /home/runner/.cache/torch_extensions/py310_cu130/batched_scaled_gemv_cutlass/cuda.cu -o cuda.cuda.o 
FAILED: [code=2] cuda.cuda.o 
/usr/local/cuda-13.0/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda.cuda.o.d -DTORCH_EXTENSION_NAME=batched_scaled_gemv_cutlass -DTORCH_API_INCLUDE_EXTENSION_H -isystem /usr/local/lib/python3.10/dist-packages/torch/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/cuda-13.0/include -isystem /usr/include/python3.10 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -I/usr/local/cuda/include -I/opt/cutlass/4.3.0/include -gencode=arch=compute_100a,code=sm_100a -gencode=arch=compute_110,code=sm_110 -c /home/runner/.cache/torch_extensions/py310_cu130/batched_scaled_gemv_cutlass/cuda.cu -o cuda.cuda.o 
/home/runner/.cache/torch_extensions/py310_cu130/batched_scaled_gemv_cutlass/cuda.cu(73): error: class \"cutlass::gemm::collective::CollectiveMma<cutlass::gemm::MainloopSm100TmaUmmaWarpSpecializedBlockScaled<28, 2, 2, ClusterShape>, MmaTileShape, cute::tuple<cutlass::float_e2m1_t, cutlass::float_ue4m3_t>, cute::tuple<cute::tuple<int64_t, cute::C<1>, int64_t>, cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_32, cute::_4>, int>, cute::tuple<cute::tuple<cute::_16, cute::_4>, int>, cute::tuple<cute::_1, int>>, cute::tuple<cute::tuple<cute::tuple<cute::_16, cute::_4>, int>, cute::tuple<cute::tuple<cute::C<0>, cute::C<1>>, cute::_512>, cute::tuple<cute::_0, int32_t>>>>, cute::tuple<cutlass::float_e2m1_t, cutlass::float_ue4m3_t>, cute::tuple<cute::tuple<int64_t, cute::C<1>, int64_t>, cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_32, cute::_4>, int>, cute::tuple<cute::tuple<cute::_16, cute::_4>, int>, cute::tuple<cute::_1, int>>, cute::tuple<cute::tuple<cute::tuple<cute::_16, cute::_4>, int>, cute::tuple<cute::tuple<cute::C<0>, cute::C<1>>, cute::_512>, cute::tuple<cute::_0, int32_t>>>>, cute::TiledMMA<cute::MMA_Atom<cute::SM100_MMA_MXF4_SS<cutlass::float_e2m1_t, cutlass::float_e2m1_t, ElementAccumulator, cutlass::float_ue4m3_t, 128, 64, 16, cute::UMMA::Major::K, cute::UMMA::Major::K, cute::UMMA::ScaleIn::One, cute::UMMA::ScaleIn::One>>, cute::Layout<cute::tuple<cute::_1, cute::_1, cute::_1>, cute::tuple<cute::_0, cute::_0, cute::C<0>>>, cute::tuple<cute::Underscore, cute::Underscore, cute::Underscore>>, cute::tuple<cute::SM90_TMA_LOAD, cute::SM90_TMA_LOAD>, cute::tuple<cute::ComposedLayout<cute::Swizzle<1, 4, 3>, cute::smem_ptr_flag_bits<4>, cute::Layout<cute::tuple<cute::_8, cute::_64>, cute::tuple<cute::_64, cute::_1>>>, cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::C<1>>, cute::tuple<cute::_16, cute::_4>>, cute::_1, cute::tuple<cute::_1, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_16, cute::_4>, cute::C<512>>, cute::tuple<cute::C<0>, cute::C<1>>>, cute::_0, cute::tuple<cute::_4, cute::C<512>>>>>, void, cute::identity, cute::tuple<cute::SM90_TMA_LOAD, cute::SM90_TMA_LOAD>, cute::tuple<cute::ComposedLayout<cute::Swizzle<1, 4, 3>, cute::smem_ptr_flag_bits<4>, cute::Layout<cute::tuple<cute::_8, cute::_64>, cute::tuple<cute::_64, cute::_1>>>, cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::C<1>>, cute::tuple<cute::_16, cute::_4>>, cute::_1, cute::tuple<cute::_1, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_16, cute::_4>, cute::C<512>>, cute::tuple<cute::C<0>, cute::C<1>>>, cute::_0, cute::tuple<cute::_4, cute::C<512>>>>>, void, cute::identity>\" has no member \"Sm100BlkScaledConfig\"
  using Sm100BlkScaledConfig = typename Gemm::GemmKernel::CollectiveMainloop::Sm100BlkScaledConfig;
                                                                              ^

/home/runner/.cache/torch_extensions/py310_cu130/batched_scaled_gemv_cutlass/cuda.cu(105): error: name followed by \"::\" must be a class or namespace name
      LayoutSFA layout_SFA = Sm100BlkScaledConfig::tile_atom_to_shape_SFA(
                             ^

/home/runner/.cache/torch_extensions/py310_cu130/batched_scaled_gemv_cutlass/cuda.cu(107): error: name followed by \"::\" must be a class or namespace name
      LayoutSFB layout_SFB = Sm100BlkScaledConfig::tile_atom_to_shape_SFB(
                             ^

3 errors detected in the compilation of \"/home/runner/.cache/torch_extensions/py310_cu130/batched_scaled_gemv_cutlass/cuda.cu\".
ninja: build stopped: subcommand failed.

\"\"\"

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File \"/home/runner/_work/discord-cluster-manager/discord-cluster-manager/eval.py\", line 485, in <module>
    sys.exit(main())
  File \"/home/runner/_work/discord-cluster-manager/discord-cluster-manager/eval.py\", line 453, in main
    return run_benchmarking(logger, pool, tests)
  File \"/home/runner/_work/discord-cluster-manager/discord-cluster-manager/eval.py\", line 306, in run_benchmarking
    run_single_benchmark(pool, tests[0], False, 200, 10e7)
  File \"/home/runner/_work/discord-cluster-manager/discord-cluster-manager/eval.py\", line 291, in run_single_benchmark
    return pool.apply(_run_single_benchmark, (test, recheck, max_repeats, max_time_ns))
  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 360, in apply
    return self.apply_async(func, args, kwds).get()
  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 774, in get
    raise self._value
RuntimeError: Error building extension 'batched_scaled_gemv_cutlass': [1/2] /usr/local/cuda-13.0/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda.cuda.o.d -DTORCH_EXTENSION_NAME=batched_scaled_gemv_cutlass -DTORCH_API_INCLUDE_EXTENSION_H -isystem /usr/local/lib/python3.10/dist-packages/torch/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/cuda-13.0/include -isystem /usr/include/python3.10 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -I/usr/local/cuda/include -I/opt/cutlass/4.3.0/include -gencode=arch=compute_100a,code=sm_100a -gencode=arch=compute_110,code=sm_110 -c /home/runner/.cache/torch_extensions/py310_cu130/batched_scaled_gemv_cutlass/cuda.cu -o cuda.cuda.o 
FAILED: [code=2] cuda.cuda.o 
/usr/local/cuda-13.0/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda.cuda.o.d -DTORCH_EXTENSION_NAME=batched_scaled_gemv_cutlass -DTORCH_API_INCLUDE_EXTENSION_H -isystem /usr/local/lib/python3.10/dist-packages/torch/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/cuda-13.0/include -isystem /usr/include/python3.10 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -I/usr/local/cuda/include -I/opt/cutlass/4.3.0/include -gencode=arch=compute_100a,code=sm_100a -gencode=arch=compute_110,code=sm_110 -c /home/runner/.cache/torch_extensions/py310_cu130/batched_scaled_gemv_cutlass/cuda.cu -o cuda.cuda.o 
/home/runner/.cache/torch_extensions/py310_cu130/batched_scaled_gemv_cutlass/cuda.cu(73): error: class \"cutlass::gemm::collective::CollectiveMma<cutlass::gemm::MainloopSm100TmaUmmaWarpSpecializedBlockScaled<28, 2, 2, ClusterShape>, MmaTileShape, cute::tuple<cutlass::float_e2m1_t, cutlass::float_ue4m3_t>, cute::tuple<cute::tuple<int64_t, cute::C<1>, int64_t>, cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_32, cute::_4>, int>, cute::tuple<cute::tuple<cute::_16, cute::_4>, int>, cute::tuple<cute::_1, int>>, cute::tuple<cute::tuple<cute::tuple<cute::_16, cute::_4>, int>, cute::tuple<cute::tuple<cute::C<0>, cute::C<1>>, cute::_512>, cute::tuple<cute::_0, int32_t>>>>, cute::tuple<cutlass::float_e2m1_t, cutlass::float_ue4m3_t>, cute::tuple<cute::tuple<int64_t, cute::C<1>, int64_t>, cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::_32, cute::_4>, int>, cute::tuple<cute::tuple<cute::_16, cute::_4>, int>, cute::tuple<cute::_1, int>>, cute::tuple<cute::tuple<cute::tuple<cute::_16, cute::_4>, int>, cute::tuple<cute::tuple<cute::C<0>, cute::C<1>>, cute::_512>, cute::tuple<cute::_0, int32_t>>>>, cute::TiledMMA<cute::MMA_Atom<cute::SM100_MMA_MXF4_SS<cutlass::float_e2m1_t, cutlass::float_e2m1_t, ElementAccumulator, cutlass::float_ue4m3_t, 128, 64, 16, cute::UMMA::Major::K, cute::UMMA::Major::K, cute::UMMA::ScaleIn::One, cute::UMMA::ScaleIn::One>>, cute::Layout<cute::tuple<cute::_1, cute::_1, cute::_1>, cute::tuple<cute::_0, cute::_0, cute::C<0>>>, cute::tuple<cute::Underscore, cute::Underscore, cute::Underscore>>, cute::tuple<cute::SM90_TMA_LOAD, cute::SM90_TMA_LOAD>, cute::tuple<cute::ComposedLayout<cute::Swizzle<1, 4, 3>, cute::smem_ptr_flag_bits<4>, cute::Layout<cute::tuple<cute::_8, cute::_64>, cute::tuple<cute::_64, cute::_1>>>, cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::C<1>>, cute::tuple<cute::_16, cute::_4>>, cute::_1, cute::tuple<cute::_1, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_16, cute::_4>, cute::C<512>>, cute::tuple<cute::C<0>, cute::C<1>>>, cute::_0, cute::tuple<cute::_4, cute::C<512>>>>>, void, cute::identity, cute::tuple<cute::SM90_TMA_LOAD, cute::SM90_TMA_LOAD>, cute::tuple<cute::ComposedLayout<cute::Swizzle<1, 4, 3>, cute::smem_ptr_flag_bits<4>, cute::Layout<cute::tuple<cute::_8, cute::_64>, cute::tuple<cute::_64, cute::_1>>>, cute::Layout<cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_32, cute::_4>, cute::C<1>>, cute::tuple<cute::_16, cute::_4>>, cute::_1, cute::tuple<cute::_1, cute::_1>>, cute::tuple<cute::tuple<cute::tuple<cute::tuple<cute::_16, cute::_4>, cute::C<512>>, cute::tuple<cute::C<0>, cute::C<1>>>, cute::_0, cute::tuple<cute::_4, cute::C<512>>>>>, void, cute::identity>\" has no member \"Sm100BlkScaledConfig\"
  using Sm100BlkScaledConfig = typename Gemm::GemmKernel::CollectiveMainloop::Sm100BlkScaledConfig;
                                                                              ^

/home/runner/.cache/torch_extensions/py310_cu130/batched_scaled_gemv_cutlass/cuda.cu(105): error: name followed by \"::\" must be a class or namespace name
      LayoutSFA layout_SFA = Sm100BlkScaledConfig::tile_atom_to_shape_SFA(
                             ^

/home/runner/.cache/torch_extensions/py310_cu130/batched_scaled_gemv_cutlass/cuda.cu(107): error: name followed by \"::\" must be a class or namespace name
      LayoutSFB layout_SFB = Sm100BlkScaledConfig::tile_atom_to_shape_SFB(
                             ^

3 errors detected in the compilation of \"/home/runner/.cache/torch_extensions/py310_cu130/batched_scaled_gemv_cutlass/cuda.cu\".
ninja: build stopped: subcommand failed.```"