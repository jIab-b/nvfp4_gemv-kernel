# Stage D2/D3 PTX Unknowns

1. tcgen05.cp.cta_group::<X>.shape::<Y>{.dst_fmt.src_fmt}
   - Needed for Stage D2 TMEM copy verification.
   - Unknowns + viable guesses:
     * `.cta_group`: plan is to start with `.cta_group::1` (single CTA TMEM) per instructions before potentially expanding to CTA pairs.
     * `.shape`: PTX allows {.128x256b, .128x128b, .64x128b, .32x128b, .4x256b}. For a 128×64 tile the obvious candidates are `.128x256b` (copy 128 rows × 256B columns per op) or `.64x128b` (two launches to cover 128 rows). Need confirmation which aligns with nvfp4 block-scaling layout.
     * `.dst_fmt/.src_fmt`: nvfp4 data likely needs `.b8x16.b4x16_p64` (decompress 4-bit to 8-bit) while scale vectors (UE8) might need no conversion or `.b8x16`. Unsure if mixing SFA and data in same op changes modifiers.
     * SMEM descriptors `gdescA/gdescB`: must encode start addr, leading dim (K-half = 32 bytes per row), stride (tile_M spacing), swizzle bits. Candidate layout: start = smem pointer to row 0, LBO = 32, SBO = tile_M*32 (4096). Need exact bit packing, swizzle selection (likely 128B), and base offset.
     * TMEM taddr + column count: cp consumes 32-column quanta. For 128 rows × 64 K we might need 64 columns for accumulators and 4 columns for block-scale vectors. Need actual counts/offsets so Stage D3 mma sees expected layout.

2. tcgen05.mma.cta_group::<X>.kind::mxf4nvf4.block_scale.scale_vec_size::2X (Stage D3 target)
   - Unknowns + guesses:
     * `.cta_group`: start with `.cta_group::1` to match single CTA TMEM copy path.
     * `.kind`: docs show `mxf4nvf4.block_scale.scale_vec_size::[2X|4X]`; we need the exact mnemonic and instruction descriptor bits for nvfp4×nvfp4 with UE8 scale vectors.
     * Instruction descriptor (`idesc`): must set scale_vec size, block_size (block32), transpose flags (TN for GEMV), disable_output_lane mask, input enable bits. Need actual bit fields (Table 44 only hints). Candidates might be base pattern from CUTLASS UTComMa.2CTA.4X but we lack literal values.
     * gdesc increments: per PTX, A/B descriptors might advance every 16 elements (K16 subtiles). Need to know whether to add 16-byte offsets each `tcgen05.mma` iteration or keep same descriptor and rely on `tcgen05.cp` to feed collector.

3. tcgen05.ld.sync.aligned.<shape>.x<num>.b32
   - Unknowns + guesses:
     * `<shape>`/`xN`: choices include `.32x32b.x2`, `.16x128b.x4`, `.32x32b.x4`. Need whichever matches the TMEM slab written by cp (scale tiles vs. accum tile). For 128-row scale vector, `.32x32b.x2` seems plausible (each warp loads 32 lanes × 32 bytes), but we need confirmation.
     * Register mapping: must know how returned `{r0,r1,...}` map to TMEM rows/columns to compare against SMEM bytes. ISA figures show general lane assignments but not the offsets for our nvfp4 layout.
     * Synchronization: need exact usage of `tcgen05.wait::ld` or `tcgen05.fence::after_thread_sync` plus any dependency requirements so we don’t deadlock when verifying data.
